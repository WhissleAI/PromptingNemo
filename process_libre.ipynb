{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing English LibreSpeech Corpus into Manfests for Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from pathlib import PurePath\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from nemo_text_processing.text_normalization.normalize import Normalizer\n",
    "from nemo.collections import nlp as nemo_nlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intitiate text normalizer and puctuator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      " NeMo-text-processing :: DEBUG    :: cardinal:  0.42s -- 6247 nodes\n",
      " NeMo-text-processing :: DEBUG    :: ordinal:  1.04s -- 1478 nodes\n",
      " NeMo-text-processing :: DEBUG    :: decimal:  0.20s -- 3151 nodes\n",
      " NeMo-text-processing :: DEBUG    :: fraction:  0.19s -- 4254 nodes\n",
      " NeMo-text-processing :: DEBUG    :: measure:  9.44s -- 49430 nodes\n",
      " NeMo-text-processing :: DEBUG    :: date:  0.53s -- 4456 nodes\n",
      " NeMo-text-processing :: DEBUG    :: time:  0.12s -- 418 nodes\n",
      " NeMo-text-processing :: DEBUG    :: telephone:  0.46s -- 3467 nodes\n",
      " NeMo-text-processing :: DEBUG    :: electronic:  0.14s -- 902 nodes\n",
      " NeMo-text-processing :: DEBUG    :: money:  7.76s -- 13153 nodes\n",
      " NeMo-text-processing :: DEBUG    :: whitelist:  1.19s -- 16688 nodes\n",
      " NeMo-text-processing :: DEBUG    :: punct:  2.21s -- 259 nodes\n",
      " NeMo-text-processing :: DEBUG    :: word:  4.78s -- 1295 nodes\n",
      " NeMo-text-processing :: DEBUG    :: serial:  7.76s -- 10772 nodes\n",
      " NeMo-text-processing :: DEBUG    :: range:  1.57s -- 14116 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:23:32 cloud:58] Found existing object /home/ubuntu/.cache/torch/NeMo/NeMo_1.21.0rc0/punctuation_en_distilbert/6bdea9786c4395fbbe02e4143d2e1cee/punctuation_en_distilbert.nemo.\n",
      "[NeMo I 2023-11-12 08:23:32 cloud:64] Re-using file from: /home/ubuntu/.cache/torch/NeMo/NeMo_1.21.0rc0/punctuation_en_distilbert/6bdea9786c4395fbbe02e4143d2e1cee/punctuation_en_distilbert.nemo\n",
      "[NeMo I 2023-11-12 08:23:32 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-11-12 08:23:34 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: distilbert-base-uncased, vocab_file: /tmp/tmpb7mnbbwt/tokenizer.vocab_file, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-12 08:23:35 modelPT:258] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2023-11-12 08:23:35 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2023-11-12 08:23:35 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2023-11-12 08:23:35 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2023-11-12 08:23:35 nlp_overrides:438] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "[NeMo W 2023-11-12 08:23:35 nlp_overrides:446] megatron-core was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/NeMo#megatron-gpt.\n",
      "[NeMo W 2023-11-12 08:23:37 punctuation_capitalization_model:719] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2023-11-12 08:23:37 punctuation_capitalization_model:741] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:23:38 save_restore_connector:249] Model PunctuationCapitalizationModel was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.21.0rc0/punctuation_en_distilbert/6bdea9786c4395fbbe02e4143d2e1cee/punctuation_en_distilbert.nemo.\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(input_case='lower_cased', lang=\"en\")\n",
    "punctuator = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(\"punctuation_en_distilbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Hugging Face NLP systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-11-12 08:23:50 nemo_logging:349] /home/ubuntu/anaconda3/envs/nemo/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "entity_tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "entity_model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "\n",
    "hf_nlp = pipeline(\"ner\", model=entity_model, tokenizer=entity_tokenizer, grouped_entities=True)\n",
    "\n",
    "\n",
    "def tag_entities(text):\n",
    "\n",
    "    ner_results = hf_nlp(text)\n",
    "    print(ner_results)\n",
    "\n",
    "    # example: [{'entity_group': 'PER', 'score': 0.8913538, 'word': 'Min', 'start': 0, 'end': 3}, {'entity_group': 'LOC', 'score': 0.9983326, 'word': 'West Van Buren Street', 'start': 93, 'end': 114}]\n",
    "    for ner_dict in ner_results:\n",
    "\n",
    "        entity_group = ner_dict['entity_group']\n",
    "        start = ner_dict['start']\n",
    "        end = ner_dict['end']\n",
    "        word = ner_dict['word']\n",
    "\n",
    "        text = text.replace(word, \"B-\"+entity_group+\" \"+word+\" E-\"+entity_group)\n",
    "\n",
    "    print(\"ner tagged text\", text)\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start pretrained Emotion Classification system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rajaram1996/Hubert_emotion were not used when initializing HubertForSpeechClassification: ['hubert.encoder.pos_conv_embed.conv.weight_v', 'hubert.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing HubertForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSpeechClassification were not initialized from the model checkpoint at Rajaram1996/Hubert_emotion and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from transformers import AutoConfig, Wav2Vec2FeatureExtractor\n",
    "from src.models import Wav2Vec2ForSpeechClassification, HubertForSpeechClassification\n",
    "\n",
    "emotion_model = HubertForSpeechClassification.from_pretrained(\"Rajaram1996/Hubert_emotion\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "sampling_rate=16000 # defined by the model; must convert mp3 to this rate.\n",
    "config = AutoConfig.from_pretrained(\"Rajaram1996/Hubert_emotion\")\n",
    "\n",
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate, sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "\n",
    "def predict(path, sampling_rate):\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    inputs = feature_extractor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {key: inputs[key].to(device) for key in inputs}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    outputs = [{\"Emotion\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in\n",
    "               enumerate(scores)]\n",
    "    return outputs\n",
    "\n",
    "def get_emotion_labels(audio_file, sampling_rate=16000, score=50.0):\n",
    "    sound_array = speech_file_to_array_fn(audio_file, sampling_rate)\n",
    "    \n",
    "    inputs = feature_extractor(sound_array, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {key: inputs[key].to(\"cpu\").float() for key in inputs}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "\n",
    "    outputs = [{\n",
    "        \"emo\": config.id2label[i],\n",
    "        \"score\": round(score * 100, 1)}\n",
    "        for i, score in enumerate(scores)\n",
    "    ]\n",
    "\n",
    "    #[{'emo': 'female_neutral', 'score': 73.9}, {'emo': 'female_happy', 'score': 24.8}]\n",
    "    emotion_labels = [row for row in sorted(outputs, key=lambda x:x[\"score\"], reverse=True) if row['score'] != '0.0%'][:2]\n",
    "\n",
    "    all_labels = []\n",
    "    for emotion_dict in emotion_labels:\n",
    "        label = emotion_dict['emo'].split(\"_\")[1].upper()\n",
    "        score = emotion_dict['score']\n",
    "\n",
    "        if score > 50.0:\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return all_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librespeech: Get data, un-compress it and then set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar (child): train.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n",
      "tar (child): test.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n",
      "tar (child): dev.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unzip downloaded files\n",
    "os.system(\"tar -xzvf train.tar.gz\")\n",
    "os.system(\"tar -xzvf test.tar.gz\")\n",
    "os.system(\"tar -xzvf dev.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define paths to folders created afte unzipping\n",
    "LIBRE = '/n/disk1/audio_datasets/EN_libre/'\n",
    "TRAIN_DATA = Path(LIBRE+'/LibriSpeech/train-clean-360/')\n",
    "TRAIN_DATA_WAV = str(TRAIN_DATA) + '-wav/'\n",
    "os.system('mkdir -p ' + TRAIN_DATA_WAV)\n",
    "TRAIN_DATA_WAV = Path(TRAIN_DATA_WAV)\n",
    "\n",
    "\n",
    "DEV_DATA = Path(LIBRE+'/LibriSpeech/dev-clean/')\n",
    "DEV_DATA_WAV = str(DEV_DATA) + '-wav/'\n",
    "os.system('mkdir -p ' + DEV_DATA_WAV)\n",
    "DEV_DATA_WAV = Path(DEV_DATA_WAV)\n",
    "\n",
    "TEST_DATA = Path(LIBRE+'/LibriSpeech/test-clean/')\n",
    "TEST_DATA_WAV = str(TEST_DATA) + '-wav/'\n",
    "os.system('mkdir -p ' + TEST_DATA_WAV)\n",
    "TEST_DATA_WAV = Path(TEST_DATA_WAV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"fevered\" } tokens { name: \"state\" } tokens { name: \"of\" } tokens { name: \"mind\" } tokens { name: \"owing\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"blight\" } tokens { name: \"his\" } tokens { name: \"wife's\" } tokens { name: \"action\" } tokens { name: \"threatened\" } tokens { name: \"to\" } tokens { name: \"cast\" } tokens { name: \"upon\" } tokens { name: \"his\" } tokens { name: \"entire\" } tokens { name: \"future\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean\n",
      "/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean\n",
      "['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/1988', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/777', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/84', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/1673', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/8297', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/5536', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/6345', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/6295', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/6313', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/5338', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/6319', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/1993', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2078', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/1272', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/174', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2803', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7850', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2902', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3752', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3081', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/1462', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/251', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2428', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3170', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3000', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/5895', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/5694', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2412', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3536', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3576', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/6241', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/652', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/422', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/8842', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/1919', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/3853']\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0026.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0033.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0034.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0021.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0027.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0030.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0031.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0024.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0028.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0023.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0032.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0022.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0025.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0029.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0020.flac']\n",
      "[NeMo I 2023-11-12 08:24:21 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:21 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:24:21 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:21 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:24:21 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:24:21 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.66batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"have\" } tokens { name: \"to\" } tokens { name: \"pay\" } tokens { name: \"her\" } tokens { name: \"the\" } tokens { name: \"money\" } tokens { name: \"which\" } tokens { name: \"she\" } tokens { name: \"would\" } tokens { name: \"now\" } tokens { name: \"regularly\" } tokens { name: \"demand\" } tokens { name: \"or\" } tokens { name: \"there\" } tokens { name: \"would\" } tokens { name: \"be\" } tokens { name: \"trouble\" } tokens { name: \"it\" } tokens { name: \"did\" } tokens { name: \"not\" } tokens { name: \"matter\" } tokens { name: \"what\" } tokens { name: \"he\" } tokens { name: \"did\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.02batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"hurstwood\" } tokens { name: \"walked\" } tokens { name: \"the\" } tokens { name: \"floor\" } tokens { name: \"mentally\" } tokens { name: \"arranging\" } tokens { name: \"the\" } tokens { name: \"chief\" } tokens { name: \"points\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"situation\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.61batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"also\" } tokens { name: \"thought\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"managerial\" } tokens { name: \"position\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.71batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"how\" } tokens { name: \"would\" } tokens { name: \"the\" } tokens { name: \"papers\" } tokens { name: \"talk\" } tokens { name: \"about\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.15batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"many\" } tokens { name: \"little\" } tokens { name: \"wrinkles\" } tokens { name: \"gathered\" } tokens { name: \"between\" } tokens { name: \"his\" } tokens { name: \"eyes\" } tokens { name: \"as\" } tokens { name: \"he\" } tokens { name: \"contemplated\" } tokens { name: \"this\" } tokens { name: \"and\" } tokens { name: \"his\" } tokens { name: \"brow\" } tokens { name: \"moistened\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.66batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"arrange\" } tokens { name: \"that\" } tokens { name: \"satisfactorily\" } tokens { name: \"for\" } tokens { name: \"carrie\" } tokens { name: \"would\" } tokens { name: \"be\" } tokens { name: \"glad\" } tokens { name: \"to\" } tokens { name: \"wait\" } tokens { name: \"if\" } tokens { name: \"necessary\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:22 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:24:22 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"see\" } tokens { name: \"how\" } tokens { name: \"things\" } tokens { name: \"turned\" } tokens { name: \"out\" } tokens { name: \"to\" } tokens { name: \"morrow\" } tokens { name: \"and\" } tokens { name: \"then\" } tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"talk\" } tokens { name: \"to\" } tokens { name: \"her\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"going\" } tokens { name: \"to\" } tokens { name: \"meet\" } tokens { name: \"as\" } tokens { name: \"usual\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.41batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"for\" } tokens { name: \"some\" } tokens { name: \"reason\" } tokens { name: \"he\" } tokens { name: \"felt\" } tokens { name: \"as\" } tokens { name: \"if\" } tokens { name: \"something\" } tokens { name: \"might\" } tokens { name: \"come\" } tokens { name: \"that\" } tokens { name: \"way\" } tokens { name: \"and\" } tokens { name: \"was\" } tokens { name: \"relieved\" } tokens { name: \"when\" } tokens { name: \"all\" } tokens { name: \"the\" } tokens { name: \"envelopes\" } tokens { name: \"had\" } tokens { name: \"been\" } tokens { name: \"scanned\" } tokens { name: \"and\" } tokens { name: \"nothing\" } tokens { name: \"suspicious\" } tokens { name: \"noticed\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.25batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"while\" } tokens { name: \"the\" } tokens { name: \"danger\" } tokens { name: \"had\" } tokens { name: \"not\" } tokens { name: \"lessened\" } tokens { name: \"it\" } tokens { name: \"had\" } tokens { name: \"not\" } tokens { name: \"as\" } tokens { name: \"yet\" } tokens { name: \"materialised\" } tokens { name: \"and\" } tokens { name: \"with\" } tokens { name: \"him\" } tokens { name: \"no\" } tokens { name: \"news\" } tokens { name: \"was\" } tokens { name: \"good\" } tokens { name: \"news\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_infer_dataset:127] Max length: 24\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:406] Min: 22 |                  Max: 22 |                  Mean: 22.0 |                  Median: 22.0\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:412] 75 percentile: 22.00\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:413] 99 percentile: 22.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.64batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"so\" } tokens { name: \"little\" } tokens { name: \"did\" } tokens { name: \"he\" } tokens { name: \"consider\" } tokens { name: \"drouet\" } tokens { name: \"that\" } tokens { name: \"it\" } tokens { name: \"never\" } tokens { name: \"once\" } tokens { name: \"occurred\" } tokens { name: \"to\" } tokens { name: \"him\" } tokens { name: \"to\" } tokens { name: \"worry\" } tokens { name: \"about\" } tokens { name: \"his\" } tokens { name: \"finding\" } tokens { name: \"out\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:23 punctuation_capitalization_infer_dataset:127] Max length: 23\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:406] Min: 21 |                  Max: 21 |                  Mean: 21.0 |                  Median: 21.0\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:412] 75 percentile: 21.00\n",
      "[NeMo I 2023-11-12 08:24:23 data_preprocessing:413] 99 percentile: 21.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.97batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"grew\" } tokens { name: \"restless\" } tokens { name: \"as\" } tokens { name: \"he\" } tokens { name: \"ruminated\" } tokens { name: \"and\" } tokens { name: \"then\" } tokens { name: \"decided\" } tokens { name: \"that\" } tokens { name: \"perhaps\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"nothing\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"had\" } tokens { name: \"not\" } tokens { name: \"been\" } tokens { name: \"able\" } tokens { name: \"to\" } tokens { name: \"get\" } tokens { name: \"away\" } tokens { name: \"this\" } tokens { name: \"morning\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.29batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"get\" } tokens { name: \"one\" } tokens { name: \"to\" } tokens { name: \"day\" } tokens { name: \"it\" } tokens { name: \"would\" } tokens { name: \"probably\" } tokens { name: \"be\" } tokens { name: \"on\" } tokens { name: \"his\" } tokens { name: \"desk\" } tokens { name: \"when\" } tokens { name: \"he\" } tokens { name: \"got\" } tokens { name: \"back\" } tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"look\" } tokens { name: \"for\" } tokens { name: \"it\" } tokens { name: \"at\" } tokens { name: \"once\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_infer_dataset:127] Max length: 26\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:406] Min: 24 |                  Max: 24 |                  Mean: 24.0 |                  Median: 24.0\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:412] 75 percentile: 24.00\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:413] 99 percentile: 24.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.44batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"after\" } tokens { name: \"a\" } tokens { name: \"time\" } tokens { name: \"he\" } tokens { name: \"gave\" } tokens { name: \"up\" } tokens { name: \"waiting\" } tokens { name: \"and\" } tokens { name: \"drearily\" } tokens { name: \"headed\" } tokens { name: \"for\" } tokens { name: \"the\" } tokens { name: \"madison\" } tokens { name: \"car\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.04batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"went\" } tokens { name: \"in\" } tokens { name: \"and\" } tokens { name: \"examined\" } tokens { name: \"his\" } tokens { name: \"letters\" } tokens { name: \"but\" } tokens { name: \"there\" } tokens { name: \"was\" } tokens { name: \"nothing\" } tokens { name: \"from\" } tokens { name: \"carrie\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.69batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"fortunately\" } tokens { name: \"there\" } tokens { name: \"was\" } tokens { name: \"nothing\" } tokens { name: \"from\" } tokens { name: \"his\" } tokens { name: \"wife\" } tokens { name: \"either\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:24 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:24:24 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.88batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"at\" } tokens { name: \"one\" } tokens { name: \"thirty\" } tokens { name: \"he\" } tokens { name: \"went\" } tokens { name: \"to\" } tokens { name: \"rector's\" } tokens { name: \"for\" } tokens { name: \"lunch\" } tokens { name: \"and\" } tokens { name: \"when\" } tokens { name: \"he\" } tokens { name: \"returned\" } tokens { name: \"a\" } tokens { name: \"messenger\" } tokens { name: \"was\" } tokens { name: \"waiting\" } tokens { name: \"for\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 23\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 21 |                  Max: 21 |                  Mean: 21.0 |                  Median: 21.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 21.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 21.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.76batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"his\" } tokens { name: \"first\" } tokens { name: \"impulse\" } tokens { name: \"was\" } tokens { name: \"to\" } tokens { name: \"write\" } tokens { name: \"but\" } tokens { name: \"four\" } tokens { name: \"words\" } tokens { name: \"in\" } tokens { name: \"reply\" } tokens { name: \"go\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"devil\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.28batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"but\" } tokens { name: \"he\" } tokens { name: \"compromised\" } tokens { name: \"by\" } tokens { name: \"telling\" } tokens { name: \"the\" } tokens { name: \"boy\" } tokens { name: \"that\" } tokens { name: \"there\" } tokens { name: \"would\" } tokens { name: \"be\" } tokens { name: \"no\" } tokens { name: \"reply\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.68batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"he\" } tokens { name: \"sat\" } tokens { name: \"down\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"chair\" } tokens { name: \"and\" } tokens { name: \"gazed\" } tokens { name: \"without\" } tokens { name: \"seeing\" } tokens { name: \"contemplating\" } tokens { name: \"the\" } tokens { name: \"result\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"work\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.98batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"what\" } tokens { name: \"would\" } tokens { name: \"she\" } tokens { name: \"do\" } tokens { name: \"about\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"confounded\" } tokens { name: \"wretch\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.78batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"later\" } tokens { name: \"however\" } tokens { name: \"his\" } tokens { name: \"old\" } tokens { name: \"discretion\" } tokens { name: \"asserted\" } tokens { name: \"itself\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.61batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"something\" } tokens { name: \"had\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"done\" } tokens { name: \"a\" } tokens { name: \"climax\" } tokens { name: \"was\" } tokens { name: \"near\" } tokens { name: \"and\" } tokens { name: \"she\" } tokens { name: \"would\" } tokens { name: \"not\" } tokens { name: \"sit\" } tokens { name: \"idle\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:25 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:25 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.96batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"knew\" } tokens { name: \"her\" } tokens { name: \"well\" } tokens { name: \"enough\" } tokens { name: \"to\" } tokens { name: \"know\" } tokens { name: \"that\" } tokens { name: \"when\" } tokens { name: \"she\" } tokens { name: \"had\" } tokens { name: \"decided\" } tokens { name: \"upon\" } tokens { name: \"a\" } tokens { name: \"plan\" } tokens { name: \"she\" } tokens { name: \"would\" } tokens { name: \"follow\" } tokens { name: \"it\" } tokens { name: \"up\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.52batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"arose\" } tokens { name: \"from\" } tokens { name: \"his\" } tokens { name: \"chair\" } tokens { name: \"and\" } tokens { name: \"went\" } tokens { name: \"and\" } tokens { name: \"looked\" } tokens { name: \"out\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"street\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.57batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"long\" } tokens { name: \"drizzle\" } tokens { name: \"had\" } tokens { name: \"begun\" } tokens { name: \"pedestrians\" } tokens { name: \"had\" } tokens { name: \"turned\" } tokens { name: \"up\" } tokens { name: \"collars\" } tokens { name: \"and\" } tokens { name: \"trousers\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"bottom\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.37batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"hurstwood\" } tokens { name: \"almost\" } tokens { name: \"exclaimed\" } tokens { name: \"out\" } tokens { name: \"loud\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"insistency\" } tokens { name: \"of\" } tokens { name: \"this\" } tokens { name: \"thing\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"put\" } tokens { name: \"on\" } tokens { name: \"his\" } tokens { name: \"hat\" } tokens { name: \"and\" } tokens { name: \"looked\" } tokens { name: \"around\" } tokens { name: \"for\" } tokens { name: \"his\" } tokens { name: \"umbrella\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.83batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"have\" } tokens { name: \"some\" } tokens { name: \"arrangement\" } tokens { name: \"of\" } tokens { name: \"this\" } tokens { name: \"thing\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:26 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:24:26 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.85batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"began\" } tokens { name: \"to\" } tokens { name: \"wish\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"compromised\" } tokens { name: \"in\" } tokens { name: \"some\" } tokens { name: \"way\" } tokens { name: \"or\" } tokens { name: \"other\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"sent\" } tokens { name: \"the\" } tokens { name: \"money\" } tokens { name: \"perhaps\" } tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"do\" } tokens { name: \"it\" } tokens { name: \"up\" } tokens { name: \"here\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.79batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"go\" } tokens { name: \"in\" } tokens { name: \"and\" } tokens { name: \"see\" } tokens { name: \"anyhow\" } tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"have\" } tokens { name: \"no\" } tokens { name: \"row\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.97batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"by\" } tokens { name: \"the\" } tokens { name: \"time\" } tokens { name: \"he\" } tokens { name: \"reached\" } tokens { name: \"his\" } tokens { name: \"own\" } tokens { name: \"street\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"keenly\" } tokens { name: \"alive\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"difficulties\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"situation\" } tokens { name: \"and\" } tokens { name: \"wished\" } tokens { name: \"over\" } tokens { name: \"and\" } tokens { name: \"over\" } tokens { name: \"that\" } tokens { name: \"some\" } tokens { name: \"solution\" } tokens { name: \"would\" } tokens { name: \"offer\" } tokens { name: \"itself\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"see\" } tokens { name: \"his\" } tokens { name: \"way\" } tokens { name: \"out\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_infer_dataset:127] Max length: 39\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:406] Min: 37 |                  Max: 37 |                  Mean: 37.0 |                  Median: 37.0\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:412] 75 percentile: 37.00\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:413] 99 percentile: 37.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.11batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"he\" } tokens { name: \"rang\" } tokens { name: \"the\" } tokens { name: \"bell\" } tokens { name: \"no\" } tokens { name: \"answer\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:27 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:24:27 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.23batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"rang\" } tokens { name: \"again\" } tokens { name: \"this\" } tokens { name: \"time\" } tokens { name: \"harder\" } tokens { name: \"still\" } tokens { name: \"no\" } tokens { name: \"answer\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:28 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:24:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:28 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:24:28 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:24:28 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0026.flac\n",
      "[]\n",
      "ner tagged text The long drizzle had begun, pedestrians had turned up collars and trousers at the bottom.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The long drizzle had begun, pedestrians had turned up collars and trousers at the bottom.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0005.flac\n",
      "[]\n",
      "ner tagged text Many little wrinkles gathered between his eyes as he contemplated this and his brow moistened.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Many little wrinkles gathered between his eyes as he contemplated this and his brow moistened.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0033.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.7273847, 'word': 'bell', 'start': 17, 'end': 21}]\n",
      "ner tagged text Then he rang the B-MISC bell E-MISC, no answer.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription Then he rang the B-MISC bell E-MISC, no answer.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0006.flac\n",
      "[{'entity_group': 'PER', 'score': 0.61452633, 'word': 'Carrie', 'start': 41, 'end': 47}]\n",
      "ner tagged text He could arrange that satisfactorily for B-PER Carrie E-PER would be glad to wait if necessary.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He could arrange that satisfactorily for B-PER Carrie E-PER would be glad to wait if necessary.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0018.flac\n",
      "[]\n",
      "ner tagged text His first impulse was to write, but four words in reply, go to the devil.\n",
      "Emotion Labels []\n",
      "tagged transcription His first impulse was to write, but four words in reply, go to the devil.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0034.flac\n",
      "[]\n",
      "ner tagged text He rang again this time harder, Still no answer.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He rang again this time harder, Still no answer.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0021.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.5603776, 'word': 'w', 'start': 45, 'end': 46}, {'entity_group': 'MISC', 'score': 0.50742006, 'word': '##ret', 'start': 46, 'end': 49}, {'entity_group': 'MISC', 'score': 0.44695562, 'word': '##ch', 'start': 49, 'end': 51}]\n",
      "ner tagged text What B-MISC w E-MISCould she do about that? the confounded B-MISC w E-MISCretch.\n",
      "Emotion Labels ['FEAR']\n",
      "tagged transcription What B-MISC w E-MISCould she do about that? the confounded B-MISC w E-MISCretch.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0015.flac\n",
      "[{'entity_group': 'PER', 'score': 0.87065846, 'word': 'Carrie', 'start': 64, 'end': 70}]\n",
      "ner tagged text He went in and examined his letters, but there was nothing from B-PER Carrie E-PER.\n",
      "Emotion Labels []\n",
      "tagged transcription He went in and examined his letters, but there was nothing from B-PER Carrie E-PER.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0012.flac\n",
      "[]\n",
      "ner tagged text She had not been able to get away this morning.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription She had not been able to get away this morning.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0027.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9755669, 'word': 'Hurstwood', 'start': 0, 'end': 9}]\n",
      "ner tagged text B-PER Hurstwood E-PER almost exclaimed out loud at the insistency of this thing.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription B-PER Hurstwood E-PER almost exclaimed out loud at the insistency of this thing.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0007.flac\n",
      "[]\n",
      "ner tagged text He would see how things turned out to morrow, and then he would talk to her. they were going to meet as usual.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He would see how things turned out to morrow, and then he would talk to her. they were going to meet as usual.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0030.flac\n",
      "[]\n",
      "ner tagged text He began to wish that he had compromised in some way or other that he had sent the money. Perhaps he could do it up here.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription He began to wish that he had compromised in some way or other that he had sent the money. Perhaps he could do it up here.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0011.flac\n",
      "[]\n",
      "ner tagged text He grew restless as he ruminated, and then decided that perhaps it was nothing.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription He grew restless as he ruminated, and then decided that perhaps it was nothing.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0009.flac\n",
      "[]\n",
      "ner tagged text While the danger had not lessened, it had not as yet materialised, and with him no news was good news.\n",
      "Emotion Labels []\n",
      "tagged transcription While the danger had not lessened, it had not as yet materialised, and with him no news was good news.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0003.flac\n",
      "[]\n",
      "ner tagged text He also thought of his managerial position.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He also thought of his managerial position.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0004.flac\n",
      "[]\n",
      "ner tagged text How would the papers talk about it?\n",
      "Emotion Labels ['FEAR']\n",
      "tagged transcription How would the papers talk about it?\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0017.flac\n",
      "[{'entity_group': 'PER', 'score': 0.5211497, 'word': 'Rec', 'start': 26, 'end': 29}]\n",
      "ner tagged text At one thirty, he went to B-PER Rec E-PERtor's for lunch, and when he returned, a messenger was waiting for him.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription At one thirty, he went to B-PER Rec E-PERtor's for lunch, and when he returned, a messenger was waiting for him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0031.flac\n",
      "[{'entity_group': 'PER', 'score': 0.7861824, 'word': 'He', 'start': 30, 'end': 32}]\n",
      "ner tagged text B-PER He E-PER would go in and see anyhow B-PER He E-PER would have no row.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-PER He E-PER would go in and see anyhow B-PER He E-PER would have no row.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0002.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9802131, 'word': 'Hurstwood', 'start': 0, 'end': 9}]\n",
      "ner tagged text B-PER Hurstwood E-PER walked the floor mentally arranging the chief points of his situation.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Hurstwood E-PER walked the floor mentally arranging the chief points of his situation.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0013.flac\n",
      "[]\n",
      "ner tagged text He would get one to day. It would probably be on his desk. when he got back. he would look for it at once.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He would get one to day. It would probably be on his desk. when he got back. he would look for it at once.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0024.flac\n",
      "[]\n",
      "ner tagged text He knew her well enough to know that when she had decided upon a plan, she would follow it up.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription He knew her well enough to know that when she had decided upon a plan, she would follow it up.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0028.flac\n",
      "[]\n",
      "ner tagged text He put on his hat and looked around for his umbrella.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He put on his hat and looked around for his umbrella.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0023.flac\n",
      "[]\n",
      "ner tagged text Something had to be done. A climax was near, and she would not sit idle.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Something had to be done. A climax was near, and she would not sit idle.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0000.flac\n",
      "[]\n",
      "ner tagged text He was in a fevered state of mind, owing to the blight, his wife's action threatened to cast upon his entire future.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He was in a fevered state of mind, owing to the blight, his wife's action threatened to cast upon his entire future.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0010.flac\n",
      "[{'entity_group': 'PER', 'score': 0.97774154, 'word': 'Drouet', 'start': 26, 'end': 32}]\n",
      "ner tagged text So little did he consider B-PER Drouet E-PER that it never once occurred to him to worry about his finding out.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription So little did he consider B-PER Drouet E-PER that it never once occurred to him to worry about his finding out.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0001.flac\n",
      "[]\n",
      "ner tagged text He would have to pay her the money which she would now regularly demand, or there would be trouble. It did not matter what he did.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription He would have to pay her the money which she would now regularly demand, or there would be trouble. It did not matter what he did.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0019.flac\n",
      "[]\n",
      "ner tagged text But he compromised by telling the boy that there would be no reply.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription But he compromised by telling the boy that there would be no reply.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0008.flac\n",
      "[]\n",
      "ner tagged text For some reason, he felt as if something might come that way, and was relieved when all the envelopes had been scanned and nothing suspicious noticed.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription For some reason, he felt as if something might come that way, and was relieved when all the envelopes had been scanned and nothing suspicious noticed.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0032.flac\n",
      "[]\n",
      "ner tagged text By the time he reached his own street, he was keenly alive to the difficulties of his situation and wished over and over that some solution would offer itself that he could see his way out.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription By the time he reached his own street, he was keenly alive to the difficulties of his situation and wished over and over that some solution would offer itself that he could see his way out.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0016.flac\n",
      "[]\n",
      "ner tagged text Fortunately, there was nothing from his wife either.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Fortunately, there was nothing from his wife either.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0014.flac\n",
      "[{'entity_group': 'ORG', 'score': 0.39111146, 'word': 'Madison', 'start': 61, 'end': 68}]\n",
      "ner tagged text After a time, he gave up waiting and drearily headed for the B-ORG Madison E-ORG car.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription After a time, he gave up waiting and drearily headed for the B-ORG Madison E-ORG car.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0022.flac\n",
      "[]\n",
      "ner tagged text Later, however, his old discretion asserted itself.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Later, however, his old discretion asserted itself.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0025.flac\n",
      "[]\n",
      "ner tagged text He arose from his chair and went and looked out into the street.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He arose from his chair and went and looked out into the street.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0029.flac\n",
      "[{'entity_group': 'PER', 'score': 0.7644216, 'word': 'He', 'start': 0, 'end': 2}]\n",
      "ner tagged text B-PER He E-PER would have some arrangement of this thing.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription B-PER He E-PER would have some arrangement of this thing.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149896/2277-149896-0020.flac\n",
      "[]\n",
      "ner tagged text Then he sat down in his chair and gazed without seeing contemplating the result of his work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"when\" } tokens { name: \"hurstwood\" } tokens { name: \"got\" } tokens { name: \"back\" } tokens { name: \"to\" } tokens { name: \"his\" } tokens { name: \"office\" } tokens { name: \"again\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"greater\" } tokens { name: \"quandary\" } tokens { name: \"than\" } tokens { name: \"ever\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Then he sat down in his chair and gazed without seeing contemplating the result of his work.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0021.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0031.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0025.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0034.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0036.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0026.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0028.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0037.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0027.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0029.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0023.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0030.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0032.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0022.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0035.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0033.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0024.flac']\n",
      "[NeMo I 2023-11-12 08:24:48 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:48 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.97batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"hardly\" } tokens { name: \"realise\" } tokens { name: \"how\" } tokens { name: \"it\" } tokens { name: \"had\" } tokens { name: \"all\" } tokens { name: \"come\" } tokens { name: \"about\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:48 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:48 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:24:48 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.21batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"no\" } tokens { name: \"letter\" } tokens { name: \"had\" } tokens { name: \"come\" } tokens { name: \"no\" } tokens { name: \"word\" } tokens { name: \"of\" } tokens { name: \"any\" } tokens { name: \"kind\" } tokens { name: \"and\" } tokens { name: \"yet\" } tokens { name: \"here\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"late\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"evening\" } tokens { name: \"and\" } tokens { name: \"she\" } tokens { name: \"had\" } tokens { name: \"agreed\" } tokens { name: \"to\" } tokens { name: \"meet\" } tokens { name: \"him\" } tokens { name: \"that\" } tokens { name: \"morning\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.38batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"saw\" } tokens { name: \"that\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"excitement\" } tokens { name: \"of\" } tokens { name: \"recent\" } tokens { name: \"events\" } tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"not\" } tokens { name: \"formulated\" } tokens { name: \"a\" } tokens { name: \"plan\" } tokens { name: \"upon\" } tokens { name: \"that\" } tokens { name: \"score\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.99batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"getting\" } tokens { name: \"some\" } tokens { name: \"vague\" } tokens { name: \"comfort\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"good\" } tokens { name: \"cigar\" } tokens { name: \"but\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"no\" } tokens { name: \"panacea\" } tokens { name: \"for\" } tokens { name: \"the\" } tokens { name: \"ill\" } tokens { name: \"which\" } tokens { name: \"affected\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_infer_dataset:127] Max length: 26\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:406] Min: 24 |                  Max: 24 |                  Mean: 24.0 |                  Median: 24.0\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:412] 75 percentile: 24.00\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:413] 99 percentile: 24.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.39batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"with\" } tokens { name: \"great\" } tokens { name: \"opposition\" } tokens { name: \"after\" } tokens { name: \"two\" } tokens { name: \"or\" } tokens { name: \"three\" } tokens { name: \"hours\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"most\" } tokens { name: \"urgent\" } tokens { name: \"mental\" } tokens { name: \"affirmation\" } tokens { name: \"and\" } tokens { name: \"denial\" } tokens { name: \"that\" } tokens { name: \"at\" } tokens { name: \"last\" } tokens { name: \"he\" } tokens { name: \"got\" } tokens { name: \"an\" } tokens { name: \"envelope\" } tokens { name: \"placed\" } tokens { name: \"in\" } tokens { name: \"it\" } tokens { name: \"the\" } tokens { name: \"requested\" } tokens { name: \"amount\" } tokens { name: \"and\" } tokens { name: \"slowly\" } tokens { name: \"sealed\" } tokens { name: \"it\" } tokens { name: \"up\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:49 punctuation_capitalization_infer_dataset:127] Max length: 40\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:406] Min: 38 |                  Max: 38 |                  Mean: 38.0 |                  Median: 38.0\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:412] 75 percentile: 38.00\n",
      "[NeMo I 2023-11-12 08:24:49 data_preprocessing:413] 99 percentile: 38.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.18batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"he\" } tokens { name: \"called\" } tokens { name: \"harry\" } tokens { name: \"the\" } tokens { name: \"boy\" } tokens { name: \"of\" } tokens { name: \"all\" } tokens { name: \"work\" } tokens { name: \"around\" } tokens { name: \"the\" } tokens { name: \"place\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.96batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"you\" } tokens { name: \"take\" } tokens { name: \"this\" } tokens { name: \"to\" } tokens { name: \"this\" } tokens { name: \"address\" } tokens { name: \"he\" } tokens { name: \"said\" } tokens { name: \"handing\" } tokens { name: \"him\" } tokens { name: \"the\" } tokens { name: \"envelope\" } tokens { name: \"and\" } tokens { name: \"give\" } tokens { name: \"it\" } tokens { name: \"to\" } tokens { name: \"missus\" } tokens { name: \"hurstwood\" } tokens { name: \"yes\" } tokens { name: \"sir\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"boy\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"any\" } tokens { name: \"answer\" } tokens { name: \"i\" } tokens { name: \"guess\" } tokens { name: \"not\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_infer_dataset:127] Max length: 7\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:406] Min: 5 |                  Max: 5 |                  Mean: 5.0 |                  Median: 5.0\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:412] 75 percentile: 5.00\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:413] 99 percentile: 5.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.34batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"boy\" } tokens { name: \"hastened\" } tokens { name: \"away\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"manager\" } tokens { name: \"fell\" } tokens { name: \"to\" } tokens { name: \"his\" } tokens { name: \"musings\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.35batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"beaten\" } tokens { name: \"for\" } tokens { name: \"to\" } tokens { name: \"night\" } tokens { name: \"and\" } tokens { name: \"he\" } tokens { name: \"might\" } tokens { name: \"just\" } tokens { name: \"as\" } tokens { name: \"well\" } tokens { name: \"make\" } tokens { name: \"the\" } tokens { name: \"best\" } tokens { name: \"of\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.11batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"would\" } tokens { name: \"take\" } tokens { name: \"the\" } tokens { name: \"envelope\" } tokens { name: \"and\" } tokens { name: \"know\" } tokens { name: \"that\" } tokens { name: \"she\" } tokens { name: \"had\" } tokens { name: \"triumphed\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:50 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:24:50 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.74batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"if\" } tokens { name: \"he\" } tokens { name: \"only\" } tokens { name: \"had\" } tokens { name: \"that\" } tokens { name: \"letter\" } tokens { name: \"back\" } tokens { name: \"he\" } tokens { name: \"wouldn't\" } tokens { name: \"send\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.89batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"for\" } tokens { name: \"relief\" } tokens { name: \"he\" } tokens { name: \"arose\" } tokens { name: \"and\" } tokens { name: \"joined\" } tokens { name: \"in\" } tokens { name: \"conversation\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"few\" } tokens { name: \"friends\" } tokens { name: \"who\" } tokens { name: \"were\" } tokens { name: \"drinking\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.18batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"all\" } tokens { name: \"the\" } tokens { name: \"time\" } tokens { name: \"his\" } tokens { name: \"thoughts\" } tokens { name: \"would\" } tokens { name: \"run\" } tokens { name: \"out\" } tokens { name: \"to\" } tokens { name: \"his\" } tokens { name: \"home\" } tokens { name: \"and\" } tokens { name: \"see\" } tokens { name: \"the\" } tokens { name: \"scene\" } tokens { name: \"being\" } tokens { name: \"therein\" } tokens { name: \"enacted\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.02batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"in\" } tokens { name: \"about\" } tokens { name: \"an\" } tokens { name: \"hour\" } tokens { name: \"and\" } tokens { name: \"three\" } tokens { name: \"quarters\" } tokens { name: \"the\" } tokens { name: \"boy\" } tokens { name: \"returned\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.61batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"fancied\" } tokens { name: \"as\" } tokens { name: \"he\" } tokens { name: \"sat\" } tokens { name: \"at\" } tokens { name: \"his\" } tokens { name: \"desk\" } tokens { name: \"that\" } tokens { name: \"nothing\" } tokens { name: \"would\" } tokens { name: \"be\" } tokens { name: \"done\" } tokens { name: \"for\" } tokens { name: \"a\" } tokens { name: \"week\" } tokens { name: \"or\" } tokens { name: \"two\" } tokens { name: \"meanwhile\" } tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"have\" } tokens { name: \"time\" } tokens { name: \"to\" } tokens { name: \"think\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.84batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"how\" } tokens { name: \"about\" } tokens { name: \"that\" } tokens { name: \"now\" } tokens { name: \"his\" } tokens { name: \"pain\" } tokens { name: \"at\" } tokens { name: \"her\" } tokens { name: \"failure\" } tokens { name: \"to\" } tokens { name: \"meet\" } tokens { name: \"or\" } tokens { name: \"write\" } tokens { name: \"him\" } tokens { name: \"rapidly\" } tokens { name: \"increased\" } tokens { name: \"as\" } tokens { name: \"he\" } tokens { name: \"devoted\" } tokens { name: \"himself\" } tokens { name: \"to\" } tokens { name: \"this\" } tokens { name: \"subject\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:51 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:24:51 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.95batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"decided\" } tokens { name: \"to\" } tokens { name: \"write\" } tokens { name: \"her\" } tokens { name: \"care\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"west\" } tokens { name: \"side\" } tokens { name: \"post\" } tokens { name: \"office\" } tokens { name: \"and\" } tokens { name: \"ask\" } tokens { name: \"for\" } tokens { name: \"an\" } tokens { name: \"explanation\" } tokens { name: \"as\" } tokens { name: \"well\" } tokens { name: \"as\" } tokens { name: \"to\" } tokens { name: \"have\" } tokens { name: \"her\" } tokens { name: \"meet\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.56batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"three\" } tokens { name: \"o'clock\" } tokens { name: \"came\" } tokens { name: \"four\" } tokens { name: \"five\" } tokens { name: \"six\" } tokens { name: \"and\" } tokens { name: \"no\" } tokens { name: \"letter\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.63batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"helpless\" } tokens { name: \"manager\" } tokens { name: \"paced\" } tokens { name: \"the\" } tokens { name: \"floor\" } tokens { name: \"and\" } tokens { name: \"grimly\" } tokens { name: \"endured\" } tokens { name: \"the\" } tokens { name: \"gloom\" } tokens { name: \"of\" } tokens { name: \"defeat\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.43batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"saw\" } tokens { name: \"a\" } tokens { name: \"busy\" } tokens { name: \"saturday\" } tokens { name: \"ushered\" } tokens { name: \"out\" } tokens { name: \"the\" } tokens { name: \"sabbath\" } tokens { name: \"in\" } tokens { name: \"and\" } tokens { name: \"nothing\" } tokens { name: \"done\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.29batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"all\" } tokens { name: \"day\" } tokens { name: \"the\" } tokens { name: \"bar\" } tokens { name: \"being\" } tokens { name: \"closed\" } tokens { name: \"he\" } tokens { name: \"brooded\" } tokens { name: \"alone\" } tokens { name: \"shut\" } tokens { name: \"out\" } tokens { name: \"from\" } tokens { name: \"home\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"excitement\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"resort\" } tokens { name: \"from\" } tokens { name: \"carrie\" } tokens { name: \"and\" } tokens { name: \"without\" } tokens { name: \"the\" } tokens { name: \"ability\" } tokens { name: \"to\" } tokens { name: \"alter\" } tokens { name: \"his\" } tokens { name: \"condition\" } tokens { name: \"one\" } tokens { name: \"iota\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:52 punctuation_capitalization_infer_dataset:127] Max length: 35\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:406] Min: 33 |                  Max: 33 |                  Mean: 33.0 |                  Median: 33.0\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:412] 75 percentile: 33.00\n",
      "[NeMo I 2023-11-12 08:24:52 data_preprocessing:413] 99 percentile: 33.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.47batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"the\" } tokens { name: \"worst\" } tokens { name: \"sunday\" } tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"spent\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"life\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.04batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"seemed\" } tokens { name: \"as\" } tokens { name: \"if\" } tokens { name: \"his\" } tokens { name: \"family\" } tokens { name: \"troubles\" } tokens { name: \"were\" } tokens { name: \"just\" } tokens { name: \"beginning\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"quite\" } tokens { name: \"certain\" } tokens { name: \"now\" } tokens { name: \"that\" } tokens { name: \"she\" } tokens { name: \"knew\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"married\" } tokens { name: \"and\" } tokens { name: \"was\" } tokens { name: \"angered\" } tokens { name: \"at\" } tokens { name: \"his\" } tokens { name: \"perfidy\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.26batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"loved\" } tokens { name: \"her\" } tokens { name: \"earnestly\" } tokens { name: \"enough\" } tokens { name: \"but\" } tokens { name: \"now\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"possibility\" } tokens { name: \"of\" } tokens { name: \"losing\" } tokens { name: \"her\" } tokens { name: \"stared\" } tokens { name: \"him\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"face\" } tokens { name: \"she\" } tokens { name: \"seemed\" } tokens { name: \"much\" } tokens { name: \"more\" } tokens { name: \"attractive\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"go\" } tokens { name: \"to\" } tokens { name: \"her\" } tokens { name: \"and\" } tokens { name: \"tell\" } tokens { name: \"her\" } tokens { name: \"all\" } tokens { name: \"his\" } tokens { name: \"family\" } tokens { name: \"complications\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:53 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:24:53 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.60batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"would\" } tokens { name: \"explain\" } tokens { name: \"to\" } tokens { name: \"her\" } tokens { name: \"just\" } tokens { name: \"where\" } tokens { name: \"he\" } tokens { name: \"stood\" } tokens { name: \"and\" } tokens { name: \"how\" } tokens { name: \"much\" } tokens { name: \"he\" } tokens { name: \"needed\" } tokens { name: \"her\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.73batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"did\" } tokens { name: \"manage\" } tokens { name: \"to\" } tokens { name: \"bring\" } tokens { name: \"himself\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"mood\" } tokens { name: \"to\" } tokens { name: \"go\" } tokens { name: \"out\" } tokens { name: \"to\" } tokens { name: \"carrie\" } tokens { name: \"but\" } tokens { name: \"when\" } tokens { name: \"he\" } tokens { name: \"got\" } tokens { name: \"in\" } tokens { name: \"ogden\" } tokens { name: \"place\" } tokens { name: \"he\" } tokens { name: \"thought\" } tokens { name: \"he\" } tokens { name: \"saw\" } tokens { name: \"a\" } tokens { name: \"man\" } tokens { name: \"watching\" } tokens { name: \"him\" } tokens { name: \"and\" } tokens { name: \"went\" } tokens { name: \"away\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_infer_dataset:127] Max length: 34\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:406] Min: 32 |                  Max: 32 |                  Mean: 32.0 |                  Median: 32.0\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:412] 75 percentile: 32.00\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:413] 99 percentile: 32.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.71batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"did\" } tokens { name: \"not\" } tokens { name: \"go\" } tokens { name: \"within\" } tokens { name: \"a\" } tokens { name: \"block\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"house\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.85batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"troubled\" } tokens { name: \"over\" } tokens { name: \"many\" } tokens { name: \"little\" } tokens { name: \"details\" } tokens { name: \"and\" } tokens { name: \"talked\" } tokens { name: \"perfunctorily\" } tokens { name: \"to\" } tokens { name: \"everybody\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"stayed\" } tokens { name: \"at\" } tokens { name: \"his\" } tokens { name: \"desk\" } tokens { name: \"long\" } tokens { name: \"after\" } tokens { name: \"all\" } tokens { name: \"others\" } tokens { name: \"had\" } tokens { name: \"gone\" } tokens { name: \"and\" } tokens { name: \"only\" } tokens { name: \"quitted\" } tokens { name: \"it\" } tokens { name: \"when\" } tokens { name: \"the\" } tokens { name: \"night\" } tokens { name: \"watchman\" } tokens { name: \"on\" } tokens { name: \"his\" } tokens { name: \"round\" } tokens { name: \"pulled\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"front\" } tokens { name: \"door\" } tokens { name: \"to\" } tokens { name: \"see\" } tokens { name: \"if\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"safely\" } tokens { name: \"locked\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:54 punctuation_capitalization_infer_dataset:127] Max length: 38\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:406] Min: 36 |                  Max: 36 |                  Mean: 36.0 |                  Median: 36.0\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:412] 75 percentile: 36.00\n",
      "[NeMo I 2023-11-12 08:24:54 data_preprocessing:413] 99 percentile: 36.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.45batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"on\" } tokens { name: \"wednesday\" } tokens { name: \"he\" } tokens { name: \"received\" } tokens { name: \"another\" } tokens { name: \"polite\" } tokens { name: \"note\" } tokens { name: \"from\" } tokens { name: \"mc\" } tokens { name: \"gregor\" } tokens { name: \"james\" } tokens { name: \"and\" } tokens { name: \"hay\" } tokens { name: \"it\" } tokens { name: \"read\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.03batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"dear\" } tokens { name: \"sir\" } tokens { name: \"we\" } tokens { name: \"beg\" } tokens { name: \"to\" } tokens { name: \"inform\" } tokens { name: \"you\" } tokens { name: \"that\" } tokens { name: \"we\" } tokens { name: \"are\" } tokens { name: \"instructed\" } tokens { name: \"to\" } tokens { name: \"wait\" } tokens { name: \"until\" } tokens { name: \"to\" } tokens { name: \"morrow\" } tokens { name: \"thursday\" } tokens { name: \"at\" } tokens { name: \"one\" } tokens { name: \"o'clock\" } tokens { name: \"before\" } tokens { name: \"filing\" } tokens { name: \"suit\" } tokens { name: \"against\" } tokens { name: \"you\" } tokens { name: \"on\" } tokens { name: \"behalf\" } tokens { name: \"of\" } tokens { name: \"missus\" } tokens { name: \"julia\" } tokens { name: \"hurstwood\" } tokens { name: \"for\" } tokens { name: \"divorce\" } tokens { name: \"and\" } tokens { name: \"alimony\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_infer_dataset:127] Max length: 42\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:406] Min: 40 |                  Max: 40 |                  Mean: 40.0 |                  Median: 40.0\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:412] 75 percentile: 40.00\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:413] 99 percentile: 40.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.58batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"very\" } tokens { name: \"truly\" } tokens { name: \"yours\" } tokens { name: \"et\" } tokens { name: \"cetera\" } tokens { name: \"compromise\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.69batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"so\" } tokens { name: \"here\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"spread\" } tokens { name: \"out\" } tokens { name: \"clear\" } tokens { name: \"before\" } tokens { name: \"him\" } tokens { name: \"and\" } tokens { name: \"now\" } tokens { name: \"he\" } tokens { name: \"knew\" } tokens { name: \"what\" } tokens { name: \"to\" } tokens { name: \"expect\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.09batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"if\" } tokens { name: \"he\" } tokens { name: \"didn't\" } tokens { name: \"go\" } tokens { name: \"and\" } tokens { name: \"see\" } tokens { name: \"them\" } tokens { name: \"they\" } tokens { name: \"would\" } tokens { name: \"sue\" } tokens { name: \"him\" } tokens { name: \"promptly\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:24:55 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:24:55 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0021.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.85783535, 'word': 'Saturday', 'start': 14, 'end': 22}]\n",
      "ner tagged text He saw a busy B-MISC Saturday E-MISC ushered out the sabbath in and nothing done.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He saw a busy B-MISC Saturday E-MISC ushered out the sabbath in and nothing done.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0001.flac\n",
      "[]\n",
      "ner tagged text He could hardly realise how it had all come about.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He could hardly realise how it had all come about.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0031.flac\n",
      "[]\n",
      "ner tagged text He troubled over many little details and talked perfunctorily to everybody.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He troubled over many little details and talked perfunctorily to everybody.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0017.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.72777814, 'word': 'How about', 'start': 0, 'end': 9}]\n",
      "ner tagged text B-MISC How about E-MISC that? now? his pain at her failure to meet or write him rapidly increased as he devoted himself to this subject.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC How about E-MISC that? now? his pain at her failure to meet or write him rapidly increased as he devoted himself to this subject.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0005.flac\n",
      "[]\n",
      "ner tagged text It was with great opposition after two or three hours of the most urgent mental affirmation and denial, that at last he got an envelope placed in it the requested amount and slowly sealed it up.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It was with great opposition after two or three hours of the most urgent mental affirmation and denial, that at last he got an envelope placed in it the requested amount and slowly sealed it up.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0025.flac\n",
      "[]\n",
      "ner tagged text He was quite certain now that she knew he was married and was angered at his perfidy.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He was quite certain now that she knew he was married and was angered at his perfidy.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0034.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9717849, 'word': 'Missus', 'start': 148, 'end': 154}, {'entity_group': 'PER', 'score': 0.9992012, 'word': 'Julia Hurstwood', 'start': 156, 'end': 171}]\n",
      "ner tagged text Dear, sir, we beg to inform you that we are instructed to wait until to morrow, Thursday at one o'clock before filing suit against you on behalf of B-PER Missus E-PER, B-PER Julia Hurstwood E-PER for divorce and alimony.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Dear, sir, we beg to inform you that we are instructed to wait until to morrow, Thursday at one o'clock before filing suit against you on behalf of B-PER Missus E-PER, B-PER Julia Hurstwood E-PER for divorce and alimony.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0036.flac\n",
      "[]\n",
      "ner tagged text So here it was spread out clear before him, and now he knew what to expect.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription So here it was spread out clear before him, and now he knew what to expect.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0026.flac\n",
      "[]\n",
      "ner tagged text He had loved her earnestly enough, but now that the possibility of losing her stared him in the face, she seemed much more attractive.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He had loved her earnestly enough, but now that the possibility of losing her stared him in the face, she seemed much more attractive.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0028.flac\n",
      "[]\n",
      "ner tagged text He would explain to her just where he stood and how much he needed her.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He would explain to her just where he stood and how much he needed her.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0037.flac\n",
      "[]\n",
      "ner tagged text If he didn't go and see them, they would sue him promptly.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription If he didn't go and see them, they would sue him promptly.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0007.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9812367, 'word': 'Missus', 'start': 80, 'end': 86}, {'entity_group': 'PER', 'score': 0.9666438, 'word': 'Hurstwood', 'start': 88, 'end': 97}]\n",
      "ner tagged text You take this to this address, he said, handing him the envelope and give it to B-PER Missus E-PER. B-PER Hurstwood E-PER, Yes, sir, said the boy.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription You take this to this address, he said, handing him the envelope and give it to B-PER Missus E-PER. B-PER Hurstwood E-PER, Yes, sir, said the boy.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0003.flac\n",
      "[]\n",
      "ner tagged text He saw that in the excitement of recent events, he had not formulated a plan upon that score.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He saw that in the excitement of recent events, he had not formulated a plan upon that score.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0013.flac\n",
      "[]\n",
      "ner tagged text For relief, he arose and joined in conversation with a few friends who were drinking.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription For relief, he arose and joined in conversation with a few friends who were drinking.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0004.flac\n",
      "[]\n",
      "ner tagged text He was getting some vague comfort out of a good cigar, but it was no panacea for the ill which affected him.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He was getting some vague comfort out of a good cigar, but it was no panacea for the ill which affected him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0018.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.99565077, 'word': 'West Side', 'start': 36, 'end': 45}]\n",
      "ner tagged text He decided to write her care of the B-LOC West Side E-LOC post office and ask for an explanation as well as to have her meet him.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He decided to write her care of the B-LOC West Side E-LOC post office and ask for an explanation as well as to have her meet him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0016.flac\n",
      "[]\n",
      "ner tagged text He fancied as he sat at his desk that nothing would be done for a week or two. meanwhile he would have time to think.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He fancied as he sat at his desk that nothing would be done for a week or two. meanwhile he would have time to think.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0027.flac\n",
      "[]\n",
      "ner tagged text He would go to her and tell her all his family complications.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He would go to her and tell her all his family complications.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0029.flac\n",
      "[{'entity_group': 'PER', 'score': 0.6387408, 'word': 'Carrie', 'start': 58, 'end': 64}, {'entity_group': 'PER', 'score': 0.565669, 'word': 'Ogden', 'start': 85, 'end': 90}]\n",
      "ner tagged text He did manage to bring himself into the mood to go out to B-PER Carrie E-PER, but when he got in B-PER Ogden E-PER place, he thought he saw a man watching him and went away.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He did manage to bring himself into the mood to go out to B-PER Carrie E-PER, but when he got in B-PER Ogden E-PER place, he thought he saw a man watching him and went away.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0019.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.788673, 'word': 'Three', 'start': 0, 'end': 5}, {'entity_group': 'MISC', 'score': 0.56360215, 'word': 'clock', 'start': 8, 'end': 13}]\n",
      "ner tagged text B-MISC Three E-MISC o'B-MISC clock E-MISC came, four, five, six and no letter.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-MISC Three E-MISC o'B-MISC clock E-MISC came, four, five, six and no letter.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0023.flac\n",
      "[]\n",
      "ner tagged text It was the worst Sunday he had spent in his life.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription It was the worst Sunday he had spent in his life.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0030.flac\n",
      "[]\n",
      "ner tagged text He did not go within a block of the house.\n",
      "Emotion Labels []\n",
      "tagged transcription He did not go within a block of the house.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0009.flac\n",
      "[]\n",
      "ner tagged text The boy hastened away and the manager fell to his musings.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The boy hastened away and the manager fell to his musings.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0010.flac\n",
      "[]\n",
      "ner tagged text He was beaten for to night and he might just as well make the best of it.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He was beaten for to night and he might just as well make the best of it.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0014.flac\n",
      "[]\n",
      "ner tagged text All the time, his thoughts would run out to his home and see the scene being therein enacted.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription All the time, his thoughts would run out to his home and see the scene being therein enacted.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0032.flac\n",
      "[]\n",
      "ner tagged text He stayed at his desk long after all others had gone, and only quitted it when the night watchman on his round pulled at the front door to see if it was safely locked.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He stayed at his desk long after all others had gone, and only quitted it when the night watchman on his round pulled at the front door to see if it was safely locked.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0002.flac\n",
      "[]\n",
      "ner tagged text No letter had come. no word of any kind, and yet here it was late in the evening and she had agreed to meet him that morning.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription No letter had come. no word of any kind, and yet here it was late in the evening and she had agreed to meet him that morning.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0006.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9745753, 'word': 'Harry', 'start': 15, 'end': 20}]\n",
      "ner tagged text Then he called B-PER Harry E-PER the boy of all work around the place.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Then he called B-PER Harry E-PER the boy of all work around the place.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0015.flac\n",
      "[]\n",
      "ner tagged text In about an hour and three quarters, the boy returned.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription In about an hour and three quarters, the boy returned.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0022.flac\n",
      "[{'entity_group': 'PER', 'score': 0.80944735, 'word': 'Carrie', 'start': 106, 'end': 112}]\n",
      "ner tagged text All day the bar being closed, he brooded alone, shut out from home from the excitement of his resort from B-PER Carrie E-PER, and without the ability to alter his condition, one iota.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription All day the bar being closed, he brooded alone, shut out from home from the excitement of his resort from B-PER Carrie E-PER, and without the ability to alter his condition, one iota.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0035.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.59160244, 'word': 'Very', 'start': 0, 'end': 4}]\n",
      "ner tagged text B-MISC Very E-MISC truly yours, et cetera compromise.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-MISC Very E-MISC truly yours, et cetera compromise.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0008.flac\n",
      "[]\n",
      "ner tagged text Any answer, I guess not.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Any answer, I guess not.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0012.flac\n",
      "[]\n",
      "ner tagged text If he only had that letter back, he wouldn't send it.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription If he only had that letter back, he wouldn't send it.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0000.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9922425, 'word': 'Hurstwood', 'start': 5, 'end': 14}]\n",
      "ner tagged text When B-PER Hurstwood E-PER got back to his office again, he was in a greater quandary than ever.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription When B-PER Hurstwood E-PER got back to his office again, he was in a greater quandary than ever.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0011.flac\n",
      "[]\n",
      "ner tagged text She would take the envelope and know that she had triumphed.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription She would take the envelope and know that she had triumphed.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0020.flac\n",
      "[]\n",
      "ner tagged text The helpless manager paced the floor and grimly endured the gloom of defeat.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription The helpless manager paced the floor and grimly endured the gloom of defeat.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0033.flac\n",
      "[{'entity_group': 'PER', 'score': 0.98300236, 'word': 'M', 'start': 51, 'end': 52}, {'entity_group': 'PER', 'score': 0.87165934, 'word': '##c', 'start': 52, 'end': 53}, {'entity_group': 'PER', 'score': 0.97884834, 'word': 'Gregor', 'start': 55, 'end': 61}, {'entity_group': 'PER', 'score': 0.9847424, 'word': 'James', 'start': 63, 'end': 68}, {'entity_group': 'PER', 'score': 0.9802699, 'word': 'Hay', 'start': 73, 'end': 76}]\n",
      "ner tagged text On Wednesday, he received another polite note from B-PER M E-PERc, B-PER Gregor E-PER, B-PER James E-PER and B-PER Hay E-PER, it read.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription On Wednesday, he received another polite note from B-PER M E-PERc, B-PER Gregor E-PER, B-PER James E-PER and B-PER Hay E-PER, it read.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149897/2277-149897-0024.flac\n",
      "[]\n",
      "ner tagged text It seemed as if his family troubles were just beginning.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It seemed as if his family troubles were just beginning.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0021.flac']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"minnie's\" } tokens { name: \"flat\" } tokens { name: \"as\" } tokens { name: \"the\" } tokens { name: \"one\" } tokens { name: \"floor\" } tokens { name: \"resident\" } tokens { name: \"apartments\" } tokens { name: \"were\" } tokens { name: \"then\" } tokens { name: \"being\" } tokens { name: \"called\" } tokens { name: \"was\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"part\" } tokens { name: \"of\" } tokens { name: \"west\" } tokens { name: \"van\" } tokens { name: \"buren\" } tokens { name: \"street\" } tokens { name: \"inhabited\" } tokens { name: \"by\" } tokens { name: \"families\" } tokens { name: \"of\" } tokens { name: \"labourers\" } tokens { name: \"and\" } tokens { name: \"clerks\" } tokens { name: \"men\" } tokens { name: \"who\" } tokens { name: \"had\" } tokens { name: \"come\" } tokens { name: \"and\" } tokens { name: \"were\" } tokens { name: \"still\" } tokens { name: \"coming\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"rush\" } tokens { name: \"of\" } tokens { name: \"population\" } tokens { name: \"pouring\" } tokens { name: \"in\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"rate\" } tokens { name: \"of\" } tokens { name: \"fifty\" } tokens { name: \"thousand\" } tokens { name: \"a\" } tokens { name: \"year\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_infer_dataset:127] Max length: 55\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:406] Min: 53 |                  Max: 53 |                  Mean: 53.0 |                  Median: 53.0\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:412] 75 percentile: 53.00\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:413] 99 percentile: 53.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.48batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"to\" } tokens { name: \"carrie\" } tokens { name: \"the\" } tokens { name: \"sound\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"little\" } tokens { name: \"bells\" } tokens { name: \"upon\" } tokens { name: \"the\" } tokens { name: \"horse\" } tokens { name: \"cars\" } tokens { name: \"as\" } tokens { name: \"they\" } tokens { name: \"tinkled\" } tokens { name: \"in\" } tokens { name: \"and\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"hearing\" } tokens { name: \"was\" } tokens { name: \"as\" } tokens { name: \"pleasing\" } tokens { name: \"as\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"novel\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.66batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"to\" } tokens { name: \"him\" } tokens { name: \"the\" } tokens { name: \"presence\" } tokens { name: \"or\" } tokens { name: \"absence\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"wife's\" } tokens { name: \"sister\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"matter\" } tokens { name: \"of\" } tokens { name: \"indifference\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.09batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"clean\" } tokens { name: \"saving\" } tokens { name: \"disposition\" } tokens { name: \"and\" } tokens { name: \"had\" } tokens { name: \"already\" } tokens { name: \"paid\" } tokens { name: \"a\" } tokens { name: \"number\" } tokens { name: \"of\" } tokens { name: \"monthly\" } tokens { name: \"instalments\" } tokens { name: \"on\" } tokens { name: \"two\" } tokens { name: \"lots\" } tokens { name: \"far\" } tokens { name: \"out\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"west\" } tokens { name: \"side\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.43batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"his\" } tokens { name: \"ambition\" } tokens { name: \"was\" } tokens { name: \"some\" } tokens { name: \"day\" } tokens { name: \"to\" } tokens { name: \"build\" } tokens { name: \"a\" } tokens { name: \"house\" } tokens { name: \"on\" } tokens { name: \"them\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:20 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:25:20 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.20batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"had\" } tokens { name: \"some\" } tokens { name: \"slight\" } tokens { name: \"gift\" } tokens { name: \"of\" } tokens { name: \"observation\" } tokens { name: \"and\" } tokens { name: \"that\" } tokens { name: \"sense\" } tokens { name: \"so\" } tokens { name: \"rich\" } tokens { name: \"in\" } tokens { name: \"every\" } tokens { name: \"woman\" } tokens { name: \"intuition\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.20batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"walls\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"rooms\" } tokens { name: \"were\" } tokens { name: \"discordantly\" } tokens { name: \"papered\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.50batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"floors\" } tokens { name: \"were\" } tokens { name: \"covered\" } tokens { name: \"with\" } tokens { name: \"matting\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"hall\" } tokens { name: \"laid\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"thin\" } tokens { name: \"rag\" } tokens { name: \"carpet\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.96batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"she\" } tokens { name: \"walked\" } tokens { name: \"and\" } tokens { name: \"sang\" } tokens { name: \"to\" } tokens { name: \"it\" } tokens { name: \"until\" } tokens { name: \"hanson\" } tokens { name: \"disturbed\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"reading\" } tokens { name: \"came\" } tokens { name: \"and\" } tokens { name: \"took\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.83batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"one\" } tokens { name: \"could\" } tokens { name: \"see\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"very\" } tokens { name: \"much\" } tokens { name: \"wrapped\" } tokens { name: \"up\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"offspring\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:21 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:25:21 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.28batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"now\" } tokens { name: \"now\" } tokens { name: \"he\" } tokens { name: \"said\" } tokens { name: \"walking\" } tokens { name: \"there\" } tokens { name: \"there\" } tokens { name: \"and\" } tokens { name: \"there\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"certain\" } tokens { name: \"swedish\" } tokens { name: \"accent\" } tokens { name: \"noticeable\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"voice\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.73batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"seemed\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"thinking\" } tokens { name: \"of\" } tokens { name: \"something\" } tokens { name: \"else\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.17batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"minnie\" } tokens { name: \"began\" } tokens { name: \"to\" } tokens { name: \"explain\" } tokens { name: \"but\" } tokens { name: \"her\" } tokens { name: \"husband\" } tokens { name: \"took\" } tokens { name: \"this\" } tokens { name: \"part\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"conversation\" } tokens { name: \"to\" } tokens { name: \"himself\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.60batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"you\" } tokens { name: \"could\" } tokens { name: \"get\" } tokens { name: \"home\" } tokens { name: \"easy\" } tokens { name: \"too\" } tokens { name: \"it\" } tokens { name: \"isn't\" } tokens { name: \"very\" } tokens { name: \"far\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"asked\" } tokens { name: \"minnie\" } tokens { name: \"for\" } tokens { name: \"ink\" } tokens { name: \"and\" } tokens { name: \"paper\" } tokens { name: \"which\" } tokens { name: \"were\" } tokens { name: \"upon\" } tokens { name: \"the\" } tokens { name: \"mantel\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"dining\" } tokens { name: \"room\" } tokens { name: \"and\" } tokens { name: \"when\" } tokens { name: \"the\" } tokens { name: \"latter\" } tokens { name: \"had\" } tokens { name: \"gone\" } tokens { name: \"to\" } tokens { name: \"bed\" } tokens { name: \"at\" } tokens { name: \"ten\" } tokens { name: \"got\" } tokens { name: \"out\" } tokens { name: \"drouet's\" } tokens { name: \"card\" } tokens { name: \"and\" } tokens { name: \"wrote\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_infer_dataset:127] Max length: 40\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:406] Min: 38 |                  Max: 38 |                  Mean: 38.0 |                  Median: 38.0\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:412] 75 percentile: 38.00\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:413] 99 percentile: 38.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.85batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"wanted\" } tokens { name: \"to\" } tokens { name: \"make\" } tokens { name: \"some\" } tokens { name: \"reference\" } tokens { name: \"to\" } tokens { name: \"their\" } tokens { name: \"relations\" } tokens { name: \"upon\" } tokens { name: \"the\" } tokens { name: \"train\" } tokens { name: \"but\" } tokens { name: \"was\" } tokens { name: \"too\" } tokens { name: \"timid\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:22 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:25:22 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.97batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"anything\" } tokens { name: \"was\" } tokens { name: \"good\" } tokens { name: \"enough\" } tokens { name: \"so\" } tokens { name: \"long\" } tokens { name: \"as\" } tokens { name: \"it\" } tokens { name: \"paid\" } tokens { name: \"say\" } tokens { name: \"five\" } tokens { name: \"dollars\" } tokens { name: \"a\" } tokens { name: \"week\" } tokens { name: \"to\" } tokens { name: \"begin\" } tokens { name: \"with\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.52batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"a\" } tokens { name: \"shop\" } tokens { name: \"girl\" } tokens { name: \"was\" } tokens { name: \"the\" } tokens { name: \"destiny\" } tokens { name: \"prefigured\" } tokens { name: \"for\" } tokens { name: \"the\" } tokens { name: \"newcomer\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.92batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"under\" } tokens { name: \"such\" } tokens { name: \"auspicious\" } tokens { name: \"circumstances\" } tokens { name: \"that\" } tokens { name: \"she\" } tokens { name: \"started\" } tokens { name: \"out\" } tokens { name: \"this\" } tokens { name: \"morning\" } tokens { name: \"to\" } tokens { name: \"look\" } tokens { name: \"for\" } tokens { name: \"work\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.01batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"narrow\" } tokens { name: \"board\" } tokens { name: \"walks\" } tokens { name: \"extended\" } tokens { name: \"out\" } tokens { name: \"passing\" } tokens { name: \"here\" } tokens { name: \"a\" } tokens { name: \"house\" } tokens { name: \"and\" } tokens { name: \"there\" } tokens { name: \"a\" } tokens { name: \"store\" } tokens { name: \"at\" } tokens { name: \"far\" } tokens { name: \"intervals\" } tokens { name: \"eventually\" } tokens { name: \"ending\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"open\" } tokens { name: \"prairie\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_infer_dataset:127] Max length: 24\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:406] Min: 22 |                  Max: 22 |                  Mean: 22.0 |                  Median: 22.0\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:412] 75 percentile: 22.00\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:413] 99 percentile: 22.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.32batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"gave\" } tokens { name: \"an\" } tokens { name: \"imposing\" } tokens { name: \"appearance\" } tokens { name: \"to\" } tokens { name: \"most\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"wholesale\" } tokens { name: \"houses\" } tokens { name: \"whose\" } tokens { name: \"offices\" } tokens { name: \"were\" } tokens { name: \"upon\" } tokens { name: \"the\" } tokens { name: \"ground\" } tokens { name: \"floor\" } tokens { name: \"and\" } tokens { name: \"in\" } tokens { name: \"plain\" } tokens { name: \"view\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"street\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"these\" } tokens { name: \"vast\" } tokens { name: \"buildings\" } tokens { name: \"what\" } tokens { name: \"were\" } tokens { name: \"they\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:23 punctuation_capitalization_infer_dataset:127] Max length: 8\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:406] Min: 6 |                  Max: 6 |                  Mean: 6.0 |                  Median: 6.0\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:412] 75 percentile: 6.00\n",
      "[NeMo I 2023-11-12 08:25:23 data_preprocessing:413] 99 percentile: 6.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0000.flac\n",
      "[{'entity_group': 'PER', 'score': 0.8913538, 'word': 'Min', 'start': 0, 'end': 3}, {'entity_group': 'LOC', 'score': 0.9983326, 'word': 'West Van Buren Street', 'start': 93, 'end': 114}]\n",
      "ner tagged text B-PER Min E-PERnie's flat, as the one floor resident apartments were then being called, was in a part of B-LOC West Van Buren Street E-LOC, inhabited by families of labourers and clerks, men who had come and were still coming with the rush of population pouring in at the rate of fifty thousand a year.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription B-PER Min E-PERnie's flat, as the one floor resident apartments were then being called, was in a part of B-LOC West Van Buren Street E-LOC, inhabited by families of labourers and clerks, men who had come and were still coming with the rush of population pouring in at the rate of fifty thousand a year.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0008.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99891937, 'word': 'Hanson', 'start': 37, 'end': 43}]\n",
      "ner tagged text Then she walked and sang to it until B-PER Hanson E-PER disturbed in his reading came and took it.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription Then she walked and sang to it until B-PER Hanson E-PER disturbed in his reading came and took it.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0006.flac\n",
      "[]\n",
      "ner tagged text The walls of the rooms were discordantly papered.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The walls of the rooms were discordantly papered.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0012.flac\n",
      "[{'entity_group': 'PER', 'score': 0.96683574, 'word': 'Minnie', 'start': 0, 'end': 6}]\n",
      "ner tagged text B-PER Minnie E-PER began to explain, but her husband took this part of the conversation to himself.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription B-PER Minnie E-PER began to explain, but her husband took this part of the conversation to himself.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0011.flac\n",
      "[]\n",
      "ner tagged text He seemed to be thinking of something else.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He seemed to be thinking of something else.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0015.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.30877957, 'word': 'train', 'start': 62, 'end': 67}]\n",
      "ner tagged text She wanted to make some reference to their relations upon the B-MISC train E-MISC, but was too timid.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription She wanted to make some reference to their relations upon the B-MISC train E-MISC, but was too timid.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0005.flac\n",
      "[]\n",
      "ner tagged text She had some slight gift of observation, and that sense so rich in every woman intuition.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription She had some slight gift of observation, and that sense so rich in every woman intuition.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0003.flac\n",
      "[]\n",
      "ner tagged text He was of a clean saving disposition and had already paid a number of monthly instalments on two lots far out on the west side.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He was of a clean saving disposition and had already paid a number of monthly instalments on two lots far out on the west side.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0007.flac\n",
      "[]\n",
      "ner tagged text The floors were covered with matting and the hall laid with a thin rag carpet.\n",
      "Emotion Labels []\n",
      "tagged transcription The floors were covered with matting and the hall laid with a thin rag carpet.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0004.flac\n",
      "[]\n",
      "ner tagged text His ambition was some day to build a house on them.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription His ambition was some day to build a house on them.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0009.flac\n",
      "[]\n",
      "ner tagged text One could see that he was very much wrapped up in his offspring.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription One could see that he was very much wrapped up in his offspring.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0013.flac\n",
      "[]\n",
      "ner tagged text You could get home easy, too. It isn't very far.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription You could get home easy, too. It isn't very far.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0017.flac\n",
      "[]\n",
      "ner tagged text A shop girl was the destiny prefigured for the newcomer.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription A shop girl was the destiny prefigured for the newcomer.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0019.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.6947651, 'word': 'Narrow', 'start': 0, 'end': 6}]\n",
      "ner tagged text B-LOC Narrow E-LOC board walks extended out, passing here a house, and there a store at far intervals, eventually ending on the open prairie.\n",
      "Emotion Labels []\n",
      "tagged transcription B-LOC Narrow E-LOC board walks extended out, passing here a house, and there a store at far intervals, eventually ending on the open prairie.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0002.flac\n",
      "[]\n",
      "ner tagged text To him the presence or absence of his wife's sister was a matter of indifference.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription To him the presence or absence of his wife's sister was a matter of indifference.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0020.flac\n",
      "[]\n",
      "ner tagged text It gave an imposing appearance to most of the wholesale houses whose offices were upon the ground floor and in plain view of the street.\n",
      "Emotion Labels []\n",
      "tagged transcription It gave an imposing appearance to most of the wholesale houses whose offices were upon the ground floor and in plain view of the street.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0001.flac\n",
      "[{'entity_group': 'PER', 'score': 0.7449135, 'word': 'Carrie', 'start': 3, 'end': 9}]\n",
      "ner tagged text To B-PER Carrie E-PER, the sound of the little bells upon the horse cars, as they tinkled in and out of hearing was as pleasing as it was novel.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription To B-PER Carrie E-PER, the sound of the little bells upon the horse cars, as they tinkled in and out of hearing was as pleasing as it was novel.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0014.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9838804, 'word': 'Minnie', 'start': 10, 'end': 16}, {'entity_group': 'PER', 'score': 0.9835647, 'word': 'Drouet', 'start': 134, 'end': 140}]\n",
      "ner tagged text She asked B-PER Minnie E-PER for ink and paper which were upon the mantel in the dining room, and when the latter had gone to bed at ten, got out B-PER Drouet E-PER's card and wrote him.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription She asked B-PER Minnie E-PER for ink and paper which were upon the mantel in the dining room, and when the latter had gone to bed at ten, got out B-PER Drouet E-PER's card and wrote him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0018.flac\n",
      "[]\n",
      "ner tagged text It was under such auspicious circumstances that she started out this morning to look for work.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It was under such auspicious circumstances that she started out this morning to look for work.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0010.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.9986405, 'word': 'Swedish', 'start': 61, 'end': 68}]\n",
      "ner tagged text Now now he said walking there there, and there was a certain B-MISC Swedish E-MISC accent noticeable in his voice.\n",
      "Emotion Labels []\n",
      "tagged transcription Now now he said walking there there, and there was a certain B-MISC Swedish E-MISC accent noticeable in his voice.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0016.flac\n",
      "[]\n",
      "ner tagged text Anything was good enough so long as it paid say five dollars a week to begin with.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Anything was good enough so long as it paid say five dollars a week to begin with.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2277/149874/2277-149874-0021.flac\n",
      "[]\n",
      "ner tagged text These vast buildings, what were they?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"four\" } tokens { name: \"years\" } tokens { name: \"older\" } tokens { name: \"than\" } tokens { name: \"i\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"sure\" } tokens { name: \"and\" } tokens { name: \"had\" } tokens { name: \"seen\" } tokens { name: \"more\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"world\" } tokens { name: \"but\" } tokens { name: \"i\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"boy\" } tokens { name: \"and\" } tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"girl\" } tokens { name: \"and\" } tokens { name: \"i\" } tokens { name: \"resented\" } tokens { name: \"her\" } tokens { name: \"protecting\" } tokens { name: \"manner\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription These vast buildings, what were they?\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0012.flac']\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_infer_dataset:127] Max length: 35\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:406] Min: 33 |                  Max: 33 |                  Mean: 33.0 |                  Median: 33.0\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:412] 75 percentile: 33.00\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:413] 99 percentile: 33.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.83batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"this\" } tokens { name: \"change\" } tokens { name: \"came\" } tokens { name: \"about\" } tokens { name: \"from\" } tokens { name: \"an\" } tokens { name: \"adventure\" } tokens { name: \"we\" } tokens { name: \"had\" } tokens { name: \"together\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.42batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"one\" } tokens { name: \"day\" } tokens { name: \"when\" } tokens { name: \"i\" } tokens { name: \"rode\" } tokens { name: \"over\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"shimerdas\" } tokens { name: \"i\" } tokens { name: \"found\" } tokens { name: \"antonia\" } tokens { name: \"starting\" } tokens { name: \"off\" } tokens { name: \"on\" } tokens { name: \"foot\" } tokens { name: \"for\" } tokens { name: \"russian\" } tokens { name: \"peter's\" } tokens { name: \"house\" } tokens { name: \"to\" } tokens { name: \"borrow\" } tokens { name: \"a\" } tokens { name: \"spade\" } tokens { name: \"ambrosch\" } tokens { name: \"needed\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_infer_dataset:127] Max length: 34\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:406] Min: 32 |                  Max: 32 |                  Mean: 32.0 |                  Median: 32.0\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:412] 75 percentile: 32.00\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:413] 99 percentile: 32.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.01batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"there\" } tokens { name: \"had\" } tokens { name: \"been\" } tokens { name: \"another\" } tokens { name: \"black\" } tokens { name: \"frost\" } tokens { name: \"the\" } tokens { name: \"night\" } tokens { name: \"before\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"air\" } tokens { name: \"was\" } tokens { name: \"clear\" } tokens { name: \"and\" } tokens { name: \"heady\" } tokens { name: \"as\" } tokens { name: \"wine\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.01batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"on\" } tokens { name: \"one\" } tokens { name: \"of\" } tokens { name: \"these\" } tokens { name: \"gravel\" } tokens { name: \"beds\" } tokens { name: \"that\" } tokens { name: \"i\" } tokens { name: \"met\" } tokens { name: \"my\" } tokens { name: \"adventure\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.84batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"whirled\" } tokens { name: \"round\" } tokens { name: \"and\" } tokens { name: \"there\" } tokens { name: \"on\" } tokens { name: \"one\" } tokens { name: \"of\" } tokens { name: \"those\" } tokens { name: \"dry\" } tokens { name: \"gravel\" } tokens { name: \"beds\" } tokens { name: \"was\" } tokens { name: \"the\" } tokens { name: \"biggest\" } tokens { name: \"snake\" } tokens { name: \"i\" } tokens { name: \"had\" } tokens { name: \"ever\" } tokens { name: \"seen\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:39 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:25:39 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.23batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"know\" } tokens { name: \"i\" } tokens { name: \"am\" } tokens { name: \"just\" } tokens { name: \"awful\" } tokens { name: \"jim\" } tokens { name: \"i\" } tokens { name: \"was\" } tokens { name: \"so\" } tokens { name: \"scared\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.01batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"never\" } tokens { name: \"know\" } tokens { name: \"you\" } tokens { name: \"was\" } tokens { name: \"so\" } tokens { name: \"brave\" } tokens { name: \"jim\" } tokens { name: \"she\" } tokens { name: \"went\" } tokens { name: \"on\" } tokens { name: \"comfortingly\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.51batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"a\" } tokens { name: \"faint\" } tokens { name: \"fetid\" } tokens { name: \"smell\" } tokens { name: \"came\" } tokens { name: \"from\" } tokens { name: \"him\" } tokens { name: \"and\" } tokens { name: \"a\" } tokens { name: \"thread\" } tokens { name: \"of\" } tokens { name: \"green\" } tokens { name: \"liquid\" } tokens { name: \"oozed\" } tokens { name: \"from\" } tokens { name: \"his\" } tokens { name: \"crushed\" } tokens { name: \"head\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_infer_dataset:127] Max length: 24\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:406] Min: 22 |                  Max: 22 |                  Mean: 22.0 |                  Median: 22.0\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:412] 75 percentile: 22.00\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:413] 99 percentile: 22.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.41batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"look\" } tokens { name: \"tony\" } tokens { name: \"that's\" } tokens { name: \"his\" } tokens { name: \"poison\" } tokens { name: \"i\" } tokens { name: \"said\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.18batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"explained\" } tokens { name: \"to\" } tokens { name: \"antonia\" } tokens { name: \"how\" } tokens { name: \"this\" } tokens { name: \"meant\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"twenty\" } tokens { name: \"four\" } tokens { name: \"years\" } tokens { name: \"old\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"must\" } tokens { name: \"have\" } tokens { name: \"been\" } tokens { name: \"there\" } tokens { name: \"when\" } tokens { name: \"white\" } tokens { name: \"men\" } tokens { name: \"first\" } tokens { name: \"came\" } tokens { name: \"left\" } tokens { name: \"on\" } tokens { name: \"from\" } tokens { name: \"buffalo\" } tokens { name: \"and\" } tokens { name: \"indian\" } tokens { name: \"times\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_infer_dataset:127] Max length: 34\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:406] Min: 32 |                  Max: 32 |                  Mean: 32.0 |                  Median: 32.0\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:412] 75 percentile: 32.00\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:413] 99 percentile: 32.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.00batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"we\" } tokens { name: \"decided\" } tokens { name: \"that\" } tokens { name: \"antonia\" } tokens { name: \"should\" } tokens { name: \"ride\" } tokens { name: \"dude\" } tokens { name: \"home\" } tokens { name: \"and\" } tokens { name: \"i\" } tokens { name: \"would\" } tokens { name: \"walk\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:40 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:25:40 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.87batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"followed\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"spade\" } tokens { name: \"over\" } tokens { name: \"my\" } tokens { name: \"shoulder\" } tokens { name: \"dragging\" } tokens { name: \"my\" } tokens { name: \"snake\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"otto\" } tokens { name: \"fuchs\" } tokens { name: \"was\" } tokens { name: \"the\" } tokens { name: \"first\" } tokens { name: \"one\" } tokens { name: \"we\" } tokens { name: \"met\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.02batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"stand\" } tokens { name: \"right\" } tokens { name: \"up\" } tokens { name: \"and\" } tokens { name: \"talk\" } tokens { name: \"to\" } tokens { name: \"you\" } tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"did\" } tokens { name: \"he\" } tokens { name: \"fight\" } tokens { name: \"hard\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.84batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"otto\" } tokens { name: \"winked\" } tokens { name: \"at\" } tokens { name: \"me\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_infer_dataset:127] Max length: 6\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:406] Min: 4 |                  Max: 4 |                  Mean: 4.0 |                  Median: 4.0\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:412] 75 percentile: 4.00\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:413] 99 percentile: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.07batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"a\" } tokens { name: \"snake\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"size\" } tokens { name: \"in\" } tokens { name: \"fighting\" } tokens { name: \"trim\" } tokens { name: \"would\" } tokens { name: \"be\" } tokens { name: \"more\" } tokens { name: \"than\" } tokens { name: \"any\" } tokens { name: \"boy\" } tokens { name: \"could\" } tokens { name: \"handle\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:41 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:25:41 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0013.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99992615, 'word': 'Otto Fuchs', 'start': 0, 'end': 10}]\n",
      "ner tagged text B-PER Otto Fuchs E-PER was the first one we met.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Otto Fuchs E-PER was the first one we met.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0008.flac\n",
      "[]\n",
      "ner tagged text A faint fetid smell came from him and a thread of green liquid oozed from his crushed head.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription A faint fetid smell came from him and a thread of green liquid oozed from his crushed head.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0014.flac\n",
      "[]\n",
      "ner tagged text He could stand right up and talk to you. He could, Did he fight hard?\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He could stand right up and talk to you. He could, Did he fight hard?\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0011.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9902255, 'word': 'Antonia', 'start': 16, 'end': 23}]\n",
      "ner tagged text We decided that B-PER Antonia E-PER should ride dude home and I would walk.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription We decided that B-PER Antonia E-PER should ride dude home and I would walk.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0000.flac\n",
      "[]\n",
      "ner tagged text She was four years older than I to be sure, and had seen more of the world, but I was a boy, and she was a girl, and I resented her protecting manner.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription She was four years older than I to be sure, and had seen more of the world, but I was a boy, and she was a girl, and I resented her protecting manner.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0010.flac\n",
      "[{'entity_group': 'PER', 'score': 0.94477093, 'word': 'Antonia', 'start': 15, 'end': 22}, {'entity_group': 'LOC', 'score': 0.85170794, 'word': 'Buffalo', 'start': 140, 'end': 147}, {'entity_group': 'MISC', 'score': 0.64518136, 'word': 'Indian', 'start': 152, 'end': 158}]\n",
      "ner tagged text I explained to B-PER Antonia E-PER how this meant that he was twenty four years old that he must have been there when white men first came left on from B-LOC Buffalo E-LOC and B-MISC Indian E-MISC times.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I explained to B-PER Antonia E-PER how this meant that he was twenty four years old that he must have been there when white men first came left on from B-LOC Buffalo E-LOC and B-MISC Indian E-MISC times.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0005.flac\n",
      "[]\n",
      "ner tagged text I whirled round and there on one of those dry gravel beds was the biggest snake I had ever seen.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I whirled round and there on one of those dry gravel beds was the biggest snake I had ever seen.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0001.flac\n",
      "[]\n",
      "ner tagged text This change came about from an adventure we had together.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription This change came about from an adventure we had together.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0015.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99069923, 'word': 'Otto', 'start': 0, 'end': 4}]\n",
      "ner tagged text B-PER Otto E-PER winked at me.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription B-PER Otto E-PER winked at me.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0016.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.52064997, 'word': 'snake', 'start': 2, 'end': 7}]\n",
      "ner tagged text A B-MISC snake E-MISC of his size in fighting trim would be more than any boy could handle.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription A B-MISC snake E-MISC of his size in fighting trim would be more than any boy could handle.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0003.flac\n",
      "[]\n",
      "ner tagged text There had been another black frost the night before, and the air was clear and heady as wine.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription There had been another black frost the night before, and the air was clear and heady as wine.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0002.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.93219066, 'word': 'Shimerdas', 'start': 32, 'end': 41}, {'entity_group': 'PER', 'score': 0.9870891, 'word': 'Antonia', 'start': 51, 'end': 58}, {'entity_group': 'PER', 'score': 0.5634781, 'word': 'Peter', 'start': 92, 'end': 97}, {'entity_group': 'PER', 'score': 0.95141035, 'word': 'Ambrosch', 'start': 124, 'end': 132}]\n",
      "ner tagged text One day when I rode over to the B-LOC Shimerdas E-LOC, I found B-PER Antonia E-PER starting off on foot for Russian B-PER Peter E-PER's house to borrow a spade B-PER Ambrosch E-PER needed.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription One day when I rode over to the B-LOC Shimerdas E-LOC, I found B-PER Antonia E-PER starting off on foot for Russian B-PER Peter E-PER's house to borrow a spade B-PER Ambrosch E-PER needed.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0006.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9648446, 'word': 'Jim', 'start': 24, 'end': 27}]\n",
      "ner tagged text I know I am just awful, B-PER Jim E-PER. I was so scared.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription I know I am just awful, B-PER Jim E-PER. I was so scared.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0007.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9756296, 'word': 'Jim', 'start': 31, 'end': 34}]\n",
      "ner tagged text I never know you was so brave, B-PER Jim E-PER. she went on comfortingly.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription I never know you was so brave, B-PER Jim E-PER. she went on comfortingly.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0004.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.38832688, 'word': 'I', 'start': 40, 'end': 41}]\n",
      "ner tagged text B-MISC I E-MISCt was on one of these gravel beds that B-MISC I E-MISC met my adventure.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC I E-MISCt was on one of these gravel beds that B-MISC I E-MISC met my adventure.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0009.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9431983, 'word': 'Tony', 'start': 5, 'end': 9}]\n",
      "ner tagged text Look B-PER Tony E-PER. That's his poison, I said.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Look B-PER Tony E-PER. That's his poison, I said.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147960/2035-147960-0012.flac\n",
      "[]\n",
      "ner tagged text I followed with the spade over my shoulder, dragging my snake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"throughout\" } tokens { name: \"this\" } tokens { name: \"century\" } tokens { name: \"the\" } tokens { name: \"power\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"church\" } tokens { name: \"was\" } tokens { name: \"constantly\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"increase\" } tokens { name: \"and\" } tokens { name: \"is\" } tokens { name: \"visible\" } tokens { name: \"in\" } tokens { name: \"many\" } tokens { name: \"important\" } tokens { name: \"changes\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I followed with the spade over my shoulder, dragging my snake.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0001.flac']\n",
      "[NeMo I 2023-11-12 08:25:52 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:52 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:25:52 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:52 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:25:52 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:25:52 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.28batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"ancestors\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"present\" } tokens { name: \"pretender\" } tokens { name: \"congal\" } tokens { name: \"surnamed\" } tokens { name: \"the\" } tokens { name: \"squint\" } tokens { name: \"eyed\" } tokens { name: \"had\" } tokens { name: \"twice\" } tokens { name: \"received\" } tokens { name: \"and\" } tokens { name: \"cherished\" } tokens { name: \"the\" } tokens { name: \"licentious\" } tokens { name: \"bards\" } tokens { name: \"when\" } tokens { name: \"under\" } tokens { name: \"the\" } tokens { name: \"ban\" } tokens { name: \"of\" } tokens { name: \"tara\" } tokens { name: \"and\" } tokens { name: \"his\" } tokens { name: \"popularity\" } tokens { name: \"with\" } tokens { name: \"that\" } tokens { name: \"still\" } tokens { name: \"powerful\" } tokens { name: \"order\" } tokens { name: \"was\" } tokens { name: \"one\" } tokens { name: \"prop\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"ambition\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_infer_dataset:127] Max length: 50\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:406] Min: 48 |                  Max: 48 |                  Mean: 48.0 |                  Median: 48.0\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:412] 75 percentile: 48.00\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:413] 99 percentile: 48.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.71batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"pretty\" } tokens { name: \"clear\" } tokens { name: \"also\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"last\" } tokens { name: \"rally\" } tokens { name: \"of\" } tokens { name: \"druidism\" } tokens { name: \"against\" } tokens { name: \"christianity\" } tokens { name: \"took\" } tokens { name: \"place\" } tokens { name: \"behind\" } tokens { name: \"his\" } tokens { name: \"banner\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"plain\" } tokens { name: \"of\" } tokens { name: \"moira\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.69batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"poets\" } tokens { name: \"of\" } tokens { name: \"succeeding\" } tokens { name: \"ages\" } tokens { name: \"have\" } tokens { name: \"dwelt\" } tokens { name: \"much\" } tokens { name: \"in\" } tokens { name: \"detail\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"occurrences\" } tokens { name: \"of\" } tokens { name: \"this\" } tokens { name: \"memorable\" } tokens { name: \"day\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.98batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"like\" } tokens { name: \"the\" } tokens { name: \"two\" } tokens { name: \"kings\" } tokens { name: \"of\" } tokens { name: \"sparta\" } tokens { name: \"they\" } tokens { name: \"reigned\" } tokens { name: \"jointly\" } tokens { name: \"dividing\" } tokens { name: \"between\" } tokens { name: \"them\" } tokens { name: \"the\" } tokens { name: \"labours\" } tokens { name: \"and\" } tokens { name: \"cares\" } tokens { name: \"of\" } tokens { name: \"state\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:53 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:25:53 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.07batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"the\" } tokens { name: \"season\" } tokens { name: \"when\" } tokens { name: \"the\" } tokens { name: \"ancient\" } tokens { name: \"sun\" } tokens { name: \"god\" } tokens { name: \"had\" } tokens { name: \"been\" } tokens { name: \"accustomed\" } tokens { name: \"to\" } tokens { name: \"receive\" } tokens { name: \"his\" } tokens { name: \"annual\" } tokens { name: \"oblations\" } tokens { name: \"and\" } tokens { name: \"we\" } tokens { name: \"can\" } tokens { name: \"well\" } tokens { name: \"believe\" } tokens { name: \"that\" } tokens { name: \"those\" } tokens { name: \"whose\" } tokens { name: \"hearts\" } tokens { name: \"still\" } tokens { name: \"trembled\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"name\" } tokens { name: \"of\" } tokens { name: \"bel\" } tokens { name: \"must\" } tokens { name: \"have\" } tokens { name: \"connected\" } tokens { name: \"the\" } tokens { name: \"eclipse\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"plague\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"revolution\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"national\" } tokens { name: \"worship\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"overthrow\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"ancient\" } tokens { name: \"gods\" } tokens { name: \"on\" } tokens { name: \"that\" } tokens { name: \"plain\" } tokens { name: \"of\" } tokens { name: \"prostration\" } tokens { name: \"where\" } tokens { name: \"they\" } tokens { name: \"had\" } tokens { name: \"so\" } tokens { name: \"long\" } tokens { name: \"received\" } tokens { name: \"the\" } tokens { name: \"homage\" } tokens { name: \"of\" } tokens { name: \"an\" } tokens { name: \"entire\" } tokens { name: \"people\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:54 punctuation_capitalization_infer_dataset:127] Max length: 64\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:406] Min: 76 |                  Max: 76 |                  Mean: 76.0 |                  Median: 76.0\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:412] 75 percentile: 76.00\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:413] 99 percentile: 76.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 15.63batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"lastly\" } tokens { name: \"the\" } tokens { name: \"royal\" } tokens { name: \"brothers\" } tokens { name: \"fell\" } tokens { name: \"themselves\" } tokens { name: \"victims\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"epidemic\" } tokens { name: \"which\" } tokens { name: \"so\" } tokens { name: \"sadly\" } tokens { name: \"signalizes\" } tokens { name: \"their\" } tokens { name: \"reign\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:54 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.88batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"only\" } tokens { name: \"conflicts\" } tokens { name: \"that\" } tokens { name: \"occurred\" } tokens { name: \"on\" } tokens { name: \"irish\" } tokens { name: \"soil\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"pictish\" } tokens { name: \"or\" } tokens { name: \"an\" } tokens { name: \"anglo\" } tokens { name: \"saxon\" } tokens { name: \"force\" } tokens { name: \"if\" } tokens { name: \"we\" } tokens { name: \"except\" } tokens { name: \"those\" } tokens { name: \"who\" } tokens { name: \"formed\" } tokens { name: \"a\" } tokens { name: \"contingent\" } tokens { name: \"of\" } tokens { name: \"congal's\" } tokens { name: \"army\" } tokens { name: \"at\" } tokens { name: \"moira\" } tokens { name: \"occurred\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"time\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"hospitable\" } tokens { name: \"finnacta\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:54 punctuation_capitalization_infer_dataset:127] Max length: 49\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:406] Min: 47 |                  Max: 47 |                  Mean: 47.0 |                  Median: 47.0\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:412] 75 percentile: 47.00\n",
      "[NeMo I 2023-11-12 08:25:54 data_preprocessing:413] 99 percentile: 47.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.24batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"as\" } tokens { name: \"leading\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"mention\" } tokens { name: \"of\" } tokens { name: \"other\" } tokens { name: \"interesting\" } tokens { name: \"events\" } tokens { name: \"we\" } tokens { name: \"must\" } tokens { name: \"set\" } tokens { name: \"this\" } tokens { name: \"inroad\" } tokens { name: \"clearly\" } tokens { name: \"before\" } tokens { name: \"the\" } tokens { name: \"reader\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.71batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"saxons\" } tokens { name: \"of\" } tokens { name: \"kent\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"southern\" } tokens { name: \"kingdoms\" } tokens { name: \"generally\" } tokens { name: \"were\" } tokens { name: \"converted\" } tokens { name: \"by\" } tokens { name: \"missionaries\" } tokens { name: \"from\" } tokens { name: \"france\" } tokens { name: \"or\" } tokens { name: \"rome\" } tokens { name: \"or\" } tokens { name: \"native\" } tokens { name: \"preachers\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"first\" } tokens { name: \"or\" } tokens { name: \"second\" } tokens { name: \"christian\" } tokens { name: \"generation\" } tokens { name: \"those\" } tokens { name: \"of\" } tokens { name: \"northumbria\" } tokens { name: \"recognise\" } tokens { name: \"as\" } tokens { name: \"their\" } tokens { name: \"apostles\" } tokens { name: \"saint\" } tokens { name: \"aidan\" } tokens { name: \"and\" } tokens { name: \"saint\" } tokens { name: \"cuthbert\" } tokens { name: \"two\" } tokens { name: \"fathers\" } tokens { name: \"from\" } tokens { name: \"iona\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_infer_dataset:127] Max length: 48\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:406] Min: 46 |                  Max: 46 |                  Mean: 46.0 |                  Median: 46.0\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:412] 75 percentile: 46.00\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:413] 99 percentile: 46.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.08batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"kingdom\" } tokens { name: \"of\" } tokens { name: \"northumbria\" } tokens { name: \"as\" } tokens { name: \"the\" } tokens { name: \"name\" } tokens { name: \"implies\" } tokens { name: \"embraced\" } tokens { name: \"nearly\" } tokens { name: \"all\" } tokens { name: \"the\" } tokens { name: \"country\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"humber\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"pictish\" } tokens { name: \"border\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_infer_dataset:127] Max length: 26\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:406] Min: 24 |                  Max: 24 |                  Mean: 24.0 |                  Median: 24.0\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:412] 75 percentile: 24.00\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:413] 99 percentile: 24.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.65batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"barren\" } tokens { name: \"rock\" } tokens { name: \"about\" } tokens { name: \"three\" } tokens { name: \"miles\" } tokens { name: \"in\" } tokens { name: \"length\" } tokens { name: \"was\" } tokens { name: \"covered\" } tokens { name: \"with\" } tokens { name: \"monastic\" } tokens { name: \"buildings\" } tokens { name: \"and\" } tokens { name: \"its\" } tokens { name: \"cemetery\" } tokens { name: \"was\" } tokens { name: \"already\" } tokens { name: \"adorned\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"tombs\" } tokens { name: \"of\" } tokens { name: \"saints\" } tokens { name: \"and\" } tokens { name: \"kings\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:55 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:25:55 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.23batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"now\" } tokens { name: \"every\" } tokens { name: \"missionary\" } tokens { name: \"that\" } tokens { name: \"ever\" } tokens { name: \"went\" } tokens { name: \"out\" } tokens { name: \"from\" } tokens { name: \"iona\" } tokens { name: \"had\" } tokens { name: \"taught\" } tokens { name: \"that\" } tokens { name: \"to\" } tokens { name: \"reduce\" } tokens { name: \"christians\" } tokens { name: \"to\" } tokens { name: \"slavery\" } tokens { name: \"was\" } tokens { name: \"wholly\" } tokens { name: \"inconsistent\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"belief\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"doctrines\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"gospel\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:56 punctuation_capitalization_infer_dataset:127] Max length: 31\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:406] Min: 29 |                  Max: 29 |                  Mean: 29.0 |                  Median: 29.0\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:412] 75 percentile: 29.00\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:413] 99 percentile: 29.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.35batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"while\" } tokens { name: \"the\" } tokens { name: \"liberated\" } tokens { name: \"exiles\" } tokens { name: \"rejoiced\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"plain\" } tokens { name: \"of\" } tokens { name: \"meath\" } tokens { name: \"the\" } tokens { name: \"tent\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"abbot\" } tokens { name: \"of\" } tokens { name: \"iona\" } tokens { name: \"was\" } tokens { name: \"pitched\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"rath\" } tokens { name: \"of\" } tokens { name: \"tara\" } tokens { name: \"a\" } tokens { name: \"fact\" } tokens { name: \"which\" } tokens { name: \"would\" } tokens { name: \"seem\" } tokens { name: \"to\" } tokens { name: \"indicate\" } tokens { name: \"that\" } tokens { name: \"already\" } tokens { name: \"in\" } tokens { name: \"little\" } tokens { name: \"more\" } tokens { name: \"than\" } tokens { name: \"a\" } tokens { name: \"century\" } tokens { name: \"since\" } tokens { name: \"the\" } tokens { name: \"interdict\" } tokens { name: \"had\" } tokens { name: \"fallen\" } tokens { name: \"on\" } tokens { name: \"it\" } tokens { name: \"the\" } tokens { name: \"edifices\" } tokens { name: \"which\" } tokens { name: \"made\" } tokens { name: \"so\" } tokens { name: \"fine\" } tokens { name: \"a\" } tokens { name: \"show\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"days\" } tokens { name: \"of\" } tokens { name: \"patrick\" } tokens { name: \"were\" } tokens { name: \"ruined\" } tokens { name: \"and\" } tokens { name: \"uninhabitable\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:56 punctuation_capitalization_infer_dataset:127] Max length: 64\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:406] Min: 74 |                  Max: 74 |                  Mean: 74.0 |                  Median: 74.0\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:412] 75 percentile: 74.00\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:413] 99 percentile: 74.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 16.36batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"so\" } tokens { name: \"slow\" } tokens { name: \"and\" } tokens { name: \"patient\" } tokens { name: \"is\" } tokens { name: \"the\" } tokens { name: \"process\" } tokens { name: \"by\" } tokens { name: \"which\" } tokens { name: \"christianity\" } tokens { name: \"infuses\" } tokens { name: \"itself\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"social\" } tokens { name: \"life\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"converted\" } tokens { name: \"people\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:56 punctuation_capitalization_infer_dataset:127] Max length: 24\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:406] Min: 22 |                  Max: 22 |                  Mean: 22.0 |                  Median: 22.0\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:412] 75 percentile: 22.00\n",
      "[NeMo I 2023-11-12 08:25:56 data_preprocessing:413] 99 percentile: 22.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.01batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"here\" } tokens { name: \"the\" } tokens { name: \"holy\" } tokens { name: \"prelate\" } tokens { name: \"of\" } tokens { name: \"ferns\" } tokens { name: \"met\" } tokens { name: \"him\" } tokens { name: \"and\" } tokens { name: \"related\" } tokens { name: \"a\" } tokens { name: \"vision\" } tokens { name: \"in\" } tokens { name: \"which\" } tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"been\" } tokens { name: \"instructed\" } tokens { name: \"to\" } tokens { name: \"demand\" } tokens { name: \"the\" } tokens { name: \"abolition\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"impost\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.92batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"tribute\" } tokens { name: \"was\" } tokens { name: \"at\" } tokens { name: \"this\" } tokens { name: \"period\" } tokens { name: \"enormous\" } tokens { name: \"fifteen\" } tokens { name: \"thousand\" } tokens { name: \"head\" } tokens { name: \"of\" } tokens { name: \"cattle\" } tokens { name: \"annually\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.14batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"saint\" } tokens { name: \"moling\" } tokens { name: \"survived\" } tokens { name: \"him\" } tokens { name: \"three\" } tokens { name: \"years\" } tokens { name: \"and\" } tokens { name: \"saint\" } tokens { name: \"adamnan\" } tokens { name: \"so\" } tokens { name: \"intimately\" } tokens { name: \"connected\" } tokens { name: \"with\" } tokens { name: \"his\" } tokens { name: \"reign\" } tokens { name: \"ten\" } tokens { name: \"years\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.45batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"nothing\" } tokens { name: \"could\" } tokens { name: \"be\" } tokens { name: \"more\" } tokens { name: \"natural\" } tokens { name: \"than\" } tokens { name: \"such\" } tokens { name: \"an\" } tokens { name: \"assembly\" } tokens { name: \"in\" } tokens { name: \"such\" } tokens { name: \"a\" } tokens { name: \"place\" } tokens { name: \"at\" } tokens { name: \"such\" } tokens { name: \"a\" } tokens { name: \"period\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:25:57 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:25:57 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0003.flac\n",
      "[]\n",
      "ner tagged text The poets of succeeding ages have dwelt much in detail on the occurrences of this memorable day.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The poets of succeeding ages have dwelt much in detail on the occurrences of this memorable day.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0014.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.99134505, 'word': 'Christianity', 'start': 44, 'end': 56}]\n",
      "ner tagged text So slow and patient is the process by which B-MISC Christianity E-MISC infuses itself into the social life of a converted people.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription So slow and patient is the process by which B-MISC Christianity E-MISC infuses itself into the social life of a converted people.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0005.flac\n",
      "[{'entity_group': 'PER', 'score': 0.6545115, 'word': 'God', 'start': 39, 'end': 42}, {'entity_group': 'PER', 'score': 0.95282465, 'word': 'Bel', 'start': 173, 'end': 176}]\n",
      "ner tagged text It was the season when the ancient Sun B-PER God E-PER had been accustomed to receive his annual oblations and we can well believe that those whose hearts still trembled at the name of B-PER Bel E-PER must have connected the eclipse and the plague with the revolution in the national worship and the overthrow of the ancient gods on that plain of prostration, where they had so long received the homage of an entire people.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It was the season when the ancient Sun B-PER God E-PER had been accustomed to receive his annual oblations and we can well believe that those whose hearts still trembled at the name of B-PER Bel E-PER must have connected the eclipse and the plague with the revolution in the national worship and the overthrow of the ancient gods on that plain of prostration, where they had so long received the homage of an entire people.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0006.flac\n",
      "[{'entity_group': 'PER', 'score': 0.744444, 'word': 'royal', 'start': 12, 'end': 17}]\n",
      "ner tagged text Lastly, the B-PER royal E-PER brothers fell themselves victims to the epidemic, which so sadly signalizes their reign.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Lastly, the B-PER royal E-PER brothers fell themselves victims to the epidemic, which so sadly signalizes their reign.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0002.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.8483285, 'word': 'Christianity', 'start': 64, 'end': 76}, {'entity_group': 'LOC', 'score': 0.99400955, 'word': 'Moira', 'start': 122, 'end': 127}]\n",
      "ner tagged text It is pretty clear also that the last rally of druidism against B-MISC Christianity E-MISC took place behind his banner on the plain of B-LOC Moira E-LOC.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It is pretty clear also that the last rally of druidism against B-MISC Christianity E-MISC took place behind his banner on the plain of B-LOC Moira E-LOC.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0013.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.9950166, 'word': 'Meath', 'start': 52, 'end': 57}, {'entity_group': 'LOC', 'score': 0.98621595, 'word': 'Iona', 'start': 84, 'end': 88}, {'entity_group': 'LOC', 'score': 0.9473824, 'word': 'Tara', 'start': 116, 'end': 120}, {'entity_group': 'PER', 'score': 0.9954716, 'word': 'Patrick', 'start': 292, 'end': 299}]\n",
      "ner tagged text While the liberated exiles rejoiced on the plain of B-LOC Meath E-LOC, the tent of the abbot of B-LOC Iona E-LOC was pitched on the rath of B-LOC Tara E-LOC, a fact which would seem to indicate that already in little more than a century since the interdict had fallen on it the edifices which made so fine a show in the days of B-PER Patrick E-PER were ruined and uninhabitable.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription While the liberated exiles rejoiced on the plain of B-LOC Meath E-LOC, the tent of the abbot of B-LOC Iona E-LOC was pitched on the rath of B-LOC Tara E-LOC, a fact which would seem to indicate that already in little more than a century since the interdict had fallen on it the edifices which made so fine a show in the days of B-PER Patrick E-PER were ruined and uninhabitable.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0016.flac\n",
      "[]\n",
      "ner tagged text The tribute was at this period, enormous fifteen thousand head of cattle annually.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The tribute was at this period, enormous fifteen thousand head of cattle annually.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0012.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.9915671, 'word': 'Iona', 'start': 45, 'end': 49}, {'entity_group': 'MISC', 'score': 0.79846704, 'word': 'Christians', 'start': 76, 'end': 86}, {'entity_group': 'MISC', 'score': 0.5509624, 'word': 'Gospel', 'start': 160, 'end': 166}]\n",
      "ner tagged text Now every missionary that ever went out from B-LOC Iona E-LOC had taught that to reduce B-MISC Christians E-MISC to slavery was wholly inconsistent with a belief in the doctrines of the B-MISC Gospel E-MISC.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Now every missionary that ever went out from B-LOC Iona E-LOC had taught that to reduce B-MISC Christians E-MISC to slavery was wholly inconsistent with a belief in the doctrines of the B-MISC Gospel E-MISC.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0015.flac\n",
      "[{'entity_group': 'PER', 'score': 0.62763786, 'word': 'Prelate', 'start': 14, 'end': 21}, {'entity_group': 'LOC', 'score': 0.48399064, 'word': 'Ferns', 'start': 25, 'end': 30}]\n",
      "ner tagged text Here the Holy B-PER Prelate E-PER of B-LOC Ferns E-LOC met him and related a vision in which he had been instructed to demand the abolition of the impost.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Here the Holy B-PER Prelate E-PER of B-LOC Ferns E-LOC met him and related a vision in which he had been instructed to demand the abolition of the impost.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0008.flac\n",
      "[]\n",
      "ner tagged text As leading to the mention of other interesting events, we must set this inroad clearly before the reader.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription As leading to the mention of other interesting events, we must set this inroad clearly before the reader.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0017.flac\n",
      "[{'entity_group': 'PER', 'score': 0.8921398, 'word': 'Moling', 'start': 6, 'end': 12}, {'entity_group': 'PER', 'score': 0.842087, 'word': 'Saint Adamnan', 'start': 43, 'end': 56}]\n",
      "ner tagged text Saint B-PER Moling E-PER survived him three years, and B-PER Saint Adamnan E-PER so intimately connected with his reign ten years.\n",
      "Emotion Labels []\n",
      "tagged transcription Saint B-PER Moling E-PER survived him three years, and B-PER Saint Adamnan E-PER so intimately connected with his reign ten years.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0000.flac\n",
      "[]\n",
      "ner tagged text Throughout this century the power of the church was constantly on the increase and is visible in many important changes.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Throughout this century the power of the church was constantly on the increase and is visible in many important changes.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0011.flac\n",
      "[]\n",
      "ner tagged text The barren rock about three miles in length was covered with monastic buildings, and its cemetery was already adorned with the tombs of saints and kings.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The barren rock about three miles in length was covered with monastic buildings, and its cemetery was already adorned with the tombs of saints and kings.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0010.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.9950182, 'word': 'Kingdom of Northumbria', 'start': 4, 'end': 26}, {'entity_group': 'LOC', 'score': 0.9986204, 'word': 'Humber', 'start': 89, 'end': 95}, {'entity_group': 'MISC', 'score': 0.77104956, 'word': 'Pictish', 'start': 103, 'end': 110}]\n",
      "ner tagged text The B-LOC Kingdom of Northumbria E-LOC as the name implies, embraced nearly all the country from the B-LOC Humber E-LOC to the B-MISC Pictish E-MISC border.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The B-LOC Kingdom of Northumbria E-LOC as the name implies, embraced nearly all the country from the B-LOC Humber E-LOC to the B-MISC Pictish E-MISC border.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0004.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.9993637, 'word': 'Sparta', 'start': 22, 'end': 28}]\n",
      "ner tagged text Like the two kings of B-LOC Sparta E-LOC, they reigned jointly, dividing between them, the labours and cares of state.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Like the two kings of B-LOC Sparta E-LOC, they reigned jointly, dividing between them, the labours and cares of state.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0009.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.6577297, 'word': 'Saxon', 'start': 4, 'end': 9}, {'entity_group': 'LOC', 'score': 0.99614245, 'word': 'Kent', 'start': 14, 'end': 18}, {'entity_group': 'LOC', 'score': 0.93399, 'word': 'Southern Kingdoms', 'start': 27, 'end': 44}, {'entity_group': 'LOC', 'score': 0.99818426, 'word': 'France', 'start': 91, 'end': 97}, {'entity_group': 'LOC', 'score': 0.9972356, 'word': 'Rome', 'start': 101, 'end': 105}, {'entity_group': 'MISC', 'score': 0.75746346, 'word': 'Christian', 'start': 150, 'end': 159}, {'entity_group': 'LOC', 'score': 0.99708384, 'word': 'Northumbria', 'start': 181, 'end': 192}, {'entity_group': 'PER', 'score': 0.8715226, 'word': 'Saint Aidan', 'start': 222, 'end': 233}, {'entity_group': 'PER', 'score': 0.8911744, 'word': 'Saint Cuthbert', 'start': 238, 'end': 252}, {'entity_group': 'LOC', 'score': 0.98596805, 'word': 'Iona', 'start': 271, 'end': 275}]\n",
      "ner tagged text The B-MISC Saxon E-MISCs of B-LOC Kent E-LOC and the B-LOC Southern Kingdoms E-LOC generally were converted by missionaries from B-LOC France E-LOC or B-LOC Rome E-LOC, or native preachers of the first or second B-MISC Christian E-MISC generation, those of B-LOC Northumbria E-LOC recognise as their apostles, B-PER Saint Aidan E-PER and B-PER Saint Cuthbert E-PER, two fathers from B-LOC Iona E-LOC.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The B-MISC Saxon E-MISCs of B-LOC Kent E-LOC and the B-LOC Southern Kingdoms E-LOC generally were converted by missionaries from B-LOC France E-LOC or B-LOC Rome E-LOC, or native preachers of the first or second B-MISC Christian E-MISC generation, those of B-LOC Northumbria E-LOC recognise as their apostles, B-PER Saint Aidan E-PER and B-PER Saint Cuthbert E-PER, two fathers from B-LOC Iona E-LOC.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0018.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.54918015, 'word': 'Nothing', 'start': 0, 'end': 7}]\n",
      "ner tagged text B-MISC Nothing E-MISC could be more natural than such an assembly in such a place at such a period.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC Nothing E-MISC could be more natural than such an assembly in such a place at such a period.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0007.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.8305625, 'word': 'Irish', 'start': 36, 'end': 41}, {'entity_group': 'MISC', 'score': 0.7752893, 'word': 'Pictish', 'start': 54, 'end': 61}, {'entity_group': 'MISC', 'score': 0.7165221, 'word': 'Anglo Saxon', 'start': 68, 'end': 79}, {'entity_group': 'PER', 'score': 0.9198589, 'word': 'Congal', 'start': 133, 'end': 139}, {'entity_group': 'LOC', 'score': 0.9881381, 'word': 'Moira', 'start': 150, 'end': 155}, {'entity_group': 'PER', 'score': 0.7866526, 'word': 'Finnacta', 'start': 195, 'end': 203}]\n",
      "ner tagged text The only conflicts that occurred on B-MISC Irish E-MISC soil with a B-MISC Pictish E-MISC or an B-MISC Anglo Saxon E-MISC force, if we except those who formed a contingent of B-PER Congal E-PER's army at B-LOC Moira E-LOC occurred in the time of the hospitable B-PER Finnacta E-PER.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The only conflicts that occurred on B-MISC Irish E-MISC soil with a B-MISC Pictish E-MISC or an B-MISC Anglo Saxon E-MISC force, if we except those who formed a contingent of B-PER Congal E-PER's army at B-LOC Moira E-LOC occurred in the time of the hospitable B-PER Finnacta E-PER.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/152373/2035-152373-0001.flac\n",
      "[{'entity_group': 'PER', 'score': 0.6068378, 'word': 'Tara', 'start': 150, 'end': 154}]\n",
      "ner tagged text The ancestors of the present pretender congal, surnamed the squint eyed, had twice received and cherished the licentious bards, when under the ban of B-PER Tara E-PER, and his popularity with that still powerful order was one prop of his ambition.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The ancestors of the present pretender congal, surnamed the squint eyed, had twice received and cherished the licentious bards, when under the ban of B-PER Tara E-PER, and his popularity with that still powerful order was one prop of his ambition.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0032.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0029.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0039.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0026.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0035.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0040.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0034.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0031.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0024.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0027.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0022.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0023.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0025.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0021.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0033.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0037.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0030.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0038.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0036.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0028.flac']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"peter\" } tokens { name: \"told\" } tokens { name: \"his\" } tokens { name: \"troubles\" } tokens { name: \"to\" } tokens { name: \"mister\" } tokens { name: \"shimerda\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"unable\" } tokens { name: \"to\" } tokens { name: \"meet\" } tokens { name: \"a\" } tokens { name: \"note\" } tokens { name: \"which\" } tokens { name: \"fell\" } tokens { name: \"due\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"first\" } tokens { name: \"of\" } tokens { name: \"november\" } tokens { name: \"had\" } tokens { name: \"to\" } tokens { name: \"pay\" } tokens { name: \"an\" } tokens { name: \"exorbitant\" } tokens { name: \"bonus\" } tokens { name: \"on\" } tokens { name: \"renewing\" } tokens { name: \"it\" } tokens { name: \"and\" } tokens { name: \"to\" } tokens { name: \"give\" } tokens { name: \"a\" } tokens { name: \"mortgage\" } tokens { name: \"on\" } tokens { name: \"his\" } tokens { name: \"pigs\" } tokens { name: \"and\" } tokens { name: \"horses\" } tokens { name: \"and\" } tokens { name: \"even\" } tokens { name: \"his\" } tokens { name: \"milk\" } tokens { name: \"cow\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_infer_dataset:127] Max length: 54\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:406] Min: 52 |                  Max: 52 |                  Mean: 52.0 |                  Median: 52.0\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:412] 75 percentile: 52.00\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:413] 99 percentile: 52.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.70batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"peter\" } tokens { name: \"could\" } tokens { name: \"give\" } tokens { name: \"no\" } tokens { name: \"very\" } tokens { name: \"clear\" } tokens { name: \"account\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"transactions\" } tokens { name: \"with\" } tokens { name: \"cutter\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.11batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"asked\" } tokens { name: \"peter\" } tokens { name: \"to\" } tokens { name: \"wait\" } tokens { name: \"a\" } tokens { name: \"moment\" } tokens { name: \"and\" } tokens { name: \"when\" } tokens { name: \"she\" } tokens { name: \"came\" } tokens { name: \"back\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"kitchen\" } tokens { name: \"she\" } tokens { name: \"brought\" } tokens { name: \"a\" } tokens { name: \"bag\" } tokens { name: \"of\" } tokens { name: \"sandwiches\" } tokens { name: \"and\" } tokens { name: \"doughnuts\" } tokens { name: \"for\" } tokens { name: \"us\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.69batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"we\" } tokens { name: \"lay\" } tokens { name: \"still\" } tokens { name: \"and\" } tokens { name: \"did\" } tokens { name: \"not\" } tokens { name: \"talk\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 33.35batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"little\" } tokens { name: \"house\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"hillside\" } tokens { name: \"was\" } tokens { name: \"so\" } tokens { name: \"much\" } tokens { name: \"the\" } tokens { name: \"color\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"night\" } tokens { name: \"that\" } tokens { name: \"we\" } tokens { name: \"could\" } tokens { name: \"not\" } tokens { name: \"see\" } tokens { name: \"it\" } tokens { name: \"as\" } tokens { name: \"we\" } tokens { name: \"came\" } tokens { name: \"up\" } tokens { name: \"the\" } tokens { name: \"draw\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:22 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:26:22 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.90batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"made\" } tokens { name: \"me\" } tokens { name: \"think\" } tokens { name: \"of\" } tokens { name: \"defeated\" } tokens { name: \"armies\" } tokens { name: \"retreating\" } tokens { name: \"or\" } tokens { name: \"of\" } tokens { name: \"ghosts\" } tokens { name: \"who\" } tokens { name: \"were\" } tokens { name: \"trying\" } tokens { name: \"desperately\" } tokens { name: \"to\" } tokens { name: \"get\" } tokens { name: \"in\" } tokens { name: \"for\" } tokens { name: \"shelter\" } tokens { name: \"and\" } tokens { name: \"then\" } tokens { name: \"went\" } tokens { name: \"moaning\" } tokens { name: \"on\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.10batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"could\" } tokens { name: \"not\" } tokens { name: \"take\" } tokens { name: \"my\" } tokens { name: \"eyes\" } tokens { name: \"off\" } tokens { name: \"the\" } tokens { name: \"man\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"bed\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.82batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"sharp\" } tokens { name: \"smell\" } tokens { name: \"of\" } tokens { name: \"spirits\" } tokens { name: \"went\" } tokens { name: \"through\" } tokens { name: \"the\" } tokens { name: \"room\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.70batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"seemed\" } tokens { name: \"to\" } tokens { name: \"me\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"despised\" } tokens { name: \"him\" } tokens { name: \"for\" } tokens { name: \"being\" } tokens { name: \"so\" } tokens { name: \"simple\" } tokens { name: \"and\" } tokens { name: \"docile\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.92batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"sick\" } tokens { name: \"man\" } tokens { name: \"raged\" } tokens { name: \"and\" } tokens { name: \"shook\" } tokens { name: \"his\" } tokens { name: \"fist\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.15batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"seemed\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"cursing\" } tokens { name: \"people\" } tokens { name: \"who\" } tokens { name: \"had\" } tokens { name: \"wronged\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:23 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:26:23 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.53batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"quickly\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"covered\" } tokens { name: \"with\" } tokens { name: \"bright\" } tokens { name: \"red\" } tokens { name: \"spots\" } tokens { name: \"i\" } tokens { name: \"thought\" } tokens { name: \"i\" } tokens { name: \"had\" } tokens { name: \"never\" } tokens { name: \"seen\" } tokens { name: \"any\" } tokens { name: \"blood\" } tokens { name: \"so\" } tokens { name: \"bright\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.10batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"lay\" } tokens { name: \"patiently\" } tokens { name: \"fighting\" } tokens { name: \"for\" } tokens { name: \"breath\" } tokens { name: \"like\" } tokens { name: \"a\" } tokens { name: \"child\" } tokens { name: \"with\" } tokens { name: \"croup\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.00batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"antonia's\" } tokens { name: \"father\" } tokens { name: \"uncovered\" } tokens { name: \"one\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"long\" } tokens { name: \"bony\" } tokens { name: \"legs\" } tokens { name: \"and\" } tokens { name: \"rubbed\" } tokens { name: \"it\" } tokens { name: \"rhythmically\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.17batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"from\" } tokens { name: \"our\" } tokens { name: \"bench\" } tokens { name: \"we\" } tokens { name: \"could\" } tokens { name: \"see\" } tokens { name: \"what\" } tokens { name: \"a\" } tokens { name: \"hollow\" } tokens { name: \"case\" } tokens { name: \"his\" } tokens { name: \"body\" } tokens { name: \"was\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.65batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"gradually\" } tokens { name: \"relief\" } tokens { name: \"came\" } tokens { name: \"to\" } tokens { name: \"all\" } tokens { name: \"of\" } tokens { name: \"us\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.06batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"without\" } tokens { name: \"a\" } tokens { name: \"word\" } tokens { name: \"peter\" } tokens { name: \"got\" } tokens { name: \"up\" } tokens { name: \"and\" } tokens { name: \"lit\" } tokens { name: \"his\" } tokens { name: \"lantern\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"mister\" } tokens { name: \"shimerda\" } tokens { name: \"went\" } tokens { name: \"with\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:24 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:26:24 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.64batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"after\" } tokens { name: \"the\" } tokens { name: \"ceremony\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"church\" } tokens { name: \"the\" } tokens { name: \"party\" } tokens { name: \"went\" } tokens { name: \"to\" } tokens { name: \"a\" } tokens { name: \"dinner\" } tokens { name: \"given\" } tokens { name: \"by\" } tokens { name: \"the\" } tokens { name: \"parents\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"bride\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.22batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"first\" } tokens { name: \"howls\" } tokens { name: \"were\" } tokens { name: \"taken\" } tokens { name: \"up\" } tokens { name: \"and\" } tokens { name: \"echoed\" } tokens { name: \"and\" } tokens { name: \"with\" } tokens { name: \"quickening\" } tokens { name: \"repetitions\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.91batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"a\" } tokens { name: \"black\" } tokens { name: \"drove\" } tokens { name: \"came\" } tokens { name: \"up\" } tokens { name: \"over\" } tokens { name: \"the\" } tokens { name: \"hill\" } tokens { name: \"behind\" } tokens { name: \"the\" } tokens { name: \"wedding\" } tokens { name: \"party\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.64batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"something\" } tokens { name: \"happened\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"hindmost\" } tokens { name: \"sledge\" } tokens { name: \"the\" } tokens { name: \"driver\" } tokens { name: \"lost\" } tokens { name: \"control\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"probably\" } tokens { name: \"very\" } tokens { name: \"drunk\" } tokens { name: \"the\" } tokens { name: \"horses\" } tokens { name: \"left\" } tokens { name: \"the\" } tokens { name: \"road\" } tokens { name: \"the\" } tokens { name: \"sledge\" } tokens { name: \"was\" } tokens { name: \"caught\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"clump\" } tokens { name: \"of\" } tokens { name: \"trees\" } tokens { name: \"and\" } tokens { name: \"overturned\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_infer_dataset:127] Max length: 37\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:406] Min: 35 |                  Max: 35 |                  Mean: 35.0 |                  Median: 35.0\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:412] 75 percentile: 35.00\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:413] 99 percentile: 35.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"shrieks\" } tokens { name: \"that\" } tokens { name: \"followed\" } tokens { name: \"made\" } tokens { name: \"everybody\" } tokens { name: \"sober\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.67batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"road\" } tokens { name: \"was\" } tokens { name: \"clear\" } tokens { name: \"and\" } tokens { name: \"white\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"groom's\" } tokens { name: \"three\" } tokens { name: \"blacks\" } tokens { name: \"went\" } tokens { name: \"like\" } tokens { name: \"the\" } tokens { name: \"wind\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:25 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:26:25 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.21batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"there\" } tokens { name: \"are\" } tokens { name: \"only\" } tokens { name: \"three\" } tokens { name: \"sledges\" } tokens { name: \"left\" } tokens { name: \"he\" } tokens { name: \"whispered\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.06batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"wolves\" } tokens { name: \"pavel\" } tokens { name: \"asked\" } tokens { name: \"enough\" } tokens { name: \"enough\" } tokens { name: \"for\" } tokens { name: \"all\" } tokens { name: \"of\" } tokens { name: \"us\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.44batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"within\" } tokens { name: \"a\" } tokens { name: \"few\" } tokens { name: \"miles\" } tokens { name: \"of\" } tokens { name: \"their\" } tokens { name: \"village\" } tokens { name: \"now\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.22batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"yes\" } tokens { name: \"how\" } tokens { name: \"many\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 5\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 3 |                  Max: 3 |                  Mean: 3.0 |                  Median: 3.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 3.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.22batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"twenty\" } tokens { name: \"thirty\" } tokens { name: \"enough\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 5\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 3 |                  Max: 3 |                  Mean: 3.0 |                  Median: 3.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 3.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.50batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"now\" } tokens { name: \"his\" } tokens { name: \"middle\" } tokens { name: \"horse\" } tokens { name: \"was\" } tokens { name: \"being\" } tokens { name: \"almost\" } tokens { name: \"dragged\" } tokens { name: \"by\" } tokens { name: \"the\" } tokens { name: \"other\" } tokens { name: \"two\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.79batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"pavel\" } tokens { name: \"knocked\" } tokens { name: \"him\" } tokens { name: \"over\" } tokens { name: \"the\" } tokens { name: \"side\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"sledge\" } tokens { name: \"and\" } tokens { name: \"threw\" } tokens { name: \"the\" } tokens { name: \"girl\" } tokens { name: \"after\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:26 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:26:26 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.18batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"peter\" } tokens { name: \"crouching\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"front\" } tokens { name: \"seat\" } tokens { name: \"saw\" } tokens { name: \"nothing\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.13batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"first\" } tokens { name: \"thing\" } tokens { name: \"either\" } tokens { name: \"of\" } tokens { name: \"them\" } tokens { name: \"noticed\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"new\" } tokens { name: \"sound\" } tokens { name: \"that\" } tokens { name: \"broke\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"clear\" } tokens { name: \"air\" } tokens { name: \"louder\" } tokens { name: \"than\" } tokens { name: \"they\" } tokens { name: \"had\" } tokens { name: \"ever\" } tokens { name: \"heard\" } tokens { name: \"it\" } tokens { name: \"before\" } tokens { name: \"the\" } tokens { name: \"bell\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"monastery\" } tokens { name: \"of\" } tokens { name: \"their\" } tokens { name: \"own\" } tokens { name: \"village\" } tokens { name: \"ringing\" } tokens { name: \"for\" } tokens { name: \"early\" } tokens { name: \"prayers\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_infer_dataset:127] Max length: 40\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:406] Min: 38 |                  Max: 38 |                  Mean: 38.0 |                  Median: 38.0\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:412] 75 percentile: 38.00\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:413] 99 percentile: 38.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.74batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"run\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"their\" } tokens { name: \"village\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.31batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"wherever\" } tokens { name: \"they\" } tokens { name: \"went\" } tokens { name: \"the\" } tokens { name: \"story\" } tokens { name: \"followed\" } tokens { name: \"them\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.98batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"worked\" } tokens { name: \"in\" } tokens { name: \"chicago\" } tokens { name: \"des\" } tokens { name: \"moines\" } tokens { name: \"fort\" } tokens { name: \"wayne\" } tokens { name: \"but\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"always\" } tokens { name: \"unfortunate\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.93batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"during\" } tokens { name: \"the\" } tokens { name: \"auction\" } tokens { name: \"he\" } tokens { name: \"went\" } tokens { name: \"about\" } tokens { name: \"with\" } tokens { name: \"his\" } tokens { name: \"head\" } tokens { name: \"down\" } tokens { name: \"and\" } tokens { name: \"never\" } tokens { name: \"lifted\" } tokens { name: \"his\" } tokens { name: \"eyes\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:27 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:26:27 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.51batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"every\" } tokens { name: \"one\" } tokens { name: \"said\" } tokens { name: \"peter\" } tokens { name: \"kissed\" } tokens { name: \"the\" } tokens { name: \"cow\" } tokens { name: \"before\" } tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"led\" } tokens { name: \"away\" } tokens { name: \"by\" } tokens { name: \"her\" } tokens { name: \"new\" } tokens { name: \"owner\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.38batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"loss\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"two\" } tokens { name: \"friends\" } tokens { name: \"had\" } tokens { name: \"a\" } tokens { name: \"depressing\" } tokens { name: \"effect\" } tokens { name: \"upon\" } tokens { name: \"old\" } tokens { name: \"mister\" } tokens { name: \"shimerda\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.86batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"when\" } tokens { name: \"he\" } tokens { name: \"was\" } tokens { name: \"out\" } tokens { name: \"hunting\" } tokens { name: \"he\" } tokens { name: \"used\" } tokens { name: \"to\" } tokens { name: \"go\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"empty\" } tokens { name: \"log\" } tokens { name: \"house\" } tokens { name: \"and\" } tokens { name: \"sit\" } tokens { name: \"there\" } tokens { name: \"brooding\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.05batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"this\" } tokens { name: \"cabin\" } tokens { name: \"was\" } tokens { name: \"his\" } tokens { name: \"hermitage\" } tokens { name: \"until\" } tokens { name: \"the\" } tokens { name: \"winter\" } tokens { name: \"snows\" } tokens { name: \"penned\" } tokens { name: \"him\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"cave\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:28 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:26:28 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0017.flac\n",
      "[{'entity_group': 'PER', 'score': 0.8017523, 'word': 'Shimerda', 'start': 7, 'end': 15}]\n",
      "ner tagged text Mister B-PER Shimerda E-PER went with him.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Mister B-PER Shimerda E-PER went with him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0032.flac\n",
      "[]\n",
      "ner tagged text The first thing either of them noticed was a new sound that broke into the clear air, louder than they had ever heard it before the bell of the monastery of their own village, ringing for early prayers.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The first thing either of them noticed was a new sound that broke into the clear air, louder than they had ever heard it before the bell of the monastery of their own village, ringing for early prayers.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0016.flac\n",
      "[{'entity_group': 'PER', 'score': 0.98686975, 'word': 'Peter', 'start': 16, 'end': 21}]\n",
      "ner tagged text Without a word, B-PER Peter E-PER got up and lit his lantern.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Without a word, B-PER Peter E-PER got up and lit his lantern.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0015.flac\n",
      "[{'entity_group': 'PER', 'score': 0.36150417, 'word': 'relief', 'start': 10, 'end': 16}]\n",
      "ner tagged text Gradually B-PER relief E-PER came to all of us.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Gradually B-PER relief E-PER came to all of us.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0029.flac\n",
      "[]\n",
      "ner tagged text Now his middle horse was being almost dragged by the other two.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Now his middle horse was being almost dragged by the other two.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0039.flac\n",
      "[]\n",
      "ner tagged text When he was out hunting, he used to go into the empty log house and sit there brooding.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription When he was out hunting, he used to go into the empty log house and sit there brooding.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0026.flac\n",
      "[]\n",
      "ner tagged text They were within a few miles of their village now.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription They were within a few miles of their village now.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0035.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.99976724, 'word': 'Chicago', 'start': 15, 'end': 22}, {'entity_group': 'LOC', 'score': 0.9997337, 'word': 'Des Moines', 'start': 24, 'end': 34}, {'entity_group': 'LOC', 'score': 0.99974513, 'word': 'Fort Wayne', 'start': 36, 'end': 46}]\n",
      "ner tagged text They worked in B-LOC Chicago E-LOC, B-LOC Des Moines E-LOC, B-LOC Fort Wayne E-LOC, but they were always unfortunate.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription They worked in B-LOC Chicago E-LOC, B-LOC Des Moines E-LOC, B-LOC Fort Wayne E-LOC, but they were always unfortunate.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0010.flac\n",
      "[]\n",
      "ner tagged text He seemed to be cursing people who had wronged him.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He seemed to be cursing people who had wronged him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0007.flac\n",
      "[]\n",
      "ner tagged text The sharp smell of spirits went through the room.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The sharp smell of spirits went through the room.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0040.flac\n",
      "[]\n",
      "ner tagged text This cabin was his hermitage until the winter snows penned him in his cave.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription This cabin was his hermitage until the winter snows penned him in his cave.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0005.flac\n",
      "[]\n",
      "ner tagged text They made me think of defeated armies, retreating, or of ghosts who were trying desperately to get in for shelter and then went moaning on.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription They made me think of defeated armies, retreating, or of ghosts who were trying desperately to get in for shelter and then went moaning on.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0013.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99940395, 'word': 'Antonia', 'start': 0, 'end': 7}]\n",
      "ner tagged text B-PER Antonia E-PER's father uncovered one of his long bony legs and rubbed it rhythmically.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Antonia E-PER's father uncovered one of his long bony legs and rubbed it rhythmically.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0006.flac\n",
      "[]\n",
      "ner tagged text I could not take my eyes off the man in the bed.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I could not take my eyes off the man in the bed.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0034.flac\n",
      "[]\n",
      "ner tagged text Wherever they went, the story followed them.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Wherever they went, the story followed them.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0008.flac\n",
      "[]\n",
      "ner tagged text It seemed to me that he despised him for being so simple and docile.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It seemed to me that he despised him for being so simple and docile.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0031.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9833257, 'word': 'Peter', 'start': 0, 'end': 5}]\n",
      "ner tagged text B-PER Peter E-PER crouching in the front seat saw nothing.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Peter E-PER crouching in the front seat saw nothing.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0024.flac\n",
      "[]\n",
      "ner tagged text There are only three sledges left, he whispered.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription There are only three sledges left, he whispered.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0027.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.5202583, 'word': 'Yes', 'start': 0, 'end': 3}]\n",
      "ner tagged text B-MISC Yes E-MISC, how many?\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC Yes E-MISC, how many?\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0022.flac\n",
      "[]\n",
      "ner tagged text The shrieks that followed made everybody sober.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The shrieks that followed made everybody sober.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0018.flac\n",
      "[]\n",
      "ner tagged text After the ceremony at the church, the party went to a dinner given by the parents of the bride.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription After the ceremony at the church, the party went to a dinner given by the parents of the bride.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0023.flac\n",
      "[]\n",
      "ner tagged text The road was clear and white and the groom's three blacks went like the wind.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The road was clear and white and the groom's three blacks went like the wind.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0000.flac\n",
      "[{'entity_group': 'PER', 'score': 0.80023646, 'word': 'Mister Shimerda', 'start': 27, 'end': 42}]\n",
      "ner tagged text Peter told his troubles to B-PER Mister Shimerda E-PER, He was unable to meet a note which fell due on the first of November had to pay an exorbitant bonus on renewing it, and to give a mortgage on his pigs and horses and even his milk cow.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Peter told his troubles to B-PER Mister Shimerda E-PER, He was unable to meet a note which fell due on the first of November had to pay an exorbitant bonus on renewing it, and to give a mortgage on his pigs and horses and even his milk cow.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0003.flac\n",
      "[]\n",
      "ner tagged text We lay still and did not talk.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription We lay still and did not talk.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0012.flac\n",
      "[]\n",
      "ner tagged text He lay patiently fighting for breath like a child with croup.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He lay patiently fighting for breath like a child with croup.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0025.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99218833, 'word': 'Pavel', 'start': 16, 'end': 21}]\n",
      "ner tagged text And the wolves, B-PER Pavel E-PER asked enough enough for all of us.\n",
      "Emotion Labels ['SAD']\n",
      "tagged transcription And the wolves, B-PER Pavel E-PER asked enough enough for all of us.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0011.flac\n",
      "[]\n",
      "ner tagged text Quickly it was covered with bright red spots. I thought I had never seen any blood so bright.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Quickly it was covered with bright red spots. I thought I had never seen any blood so bright.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0021.flac\n",
      "[]\n",
      "ner tagged text Something happened to the hindmost sledge. The driver lost control. He was probably very drunk. The horses left the road. The sledge was caught in a clump of trees and overturned.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Something happened to the hindmost sledge. The driver lost control. He was probably very drunk. The horses left the road. The sledge was caught in a clump of trees and overturned.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0014.flac\n",
      "[]\n",
      "ner tagged text From our bench we could see what a hollow case his body was.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription From our bench we could see what a hollow case his body was.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0019.flac\n",
      "[]\n",
      "ner tagged text The first howls were taken up and echoed and with quickening repetitions.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The first howls were taken up and echoed and with quickening repetitions.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0004.flac\n",
      "[]\n",
      "ner tagged text The little house on the hillside was so much the color of the night that we could not see it as we came up the draw.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The little house on the hillside was so much the color of the night that we could not see it as we came up the draw.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0033.flac\n",
      "[]\n",
      "ner tagged text They were run out of their village.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription They were run out of their village.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0009.flac\n",
      "[]\n",
      "ner tagged text The sick man raged and shook his fist.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The sick man raged and shook his fist.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0037.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9787677, 'word': 'Peter', 'start': 15, 'end': 20}]\n",
      "ner tagged text Every one said B-PER Peter E-PER kissed the cow before she was led away by her new owner.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Every one said B-PER Peter E-PER kissed the cow before she was led away by her new owner.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0030.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99890053, 'word': 'Pavel', 'start': 0, 'end': 5}]\n",
      "ner tagged text B-PER Pavel E-PER knocked him over the side of the sledge and threw the girl after him.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Pavel E-PER knocked him over the side of the sledge and threw the girl after him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0001.flac\n",
      "[{'entity_group': 'PER', 'score': 0.62097156, 'word': 'Peter', 'start': 0, 'end': 5}, {'entity_group': 'PER', 'score': 0.9268759, 'word': 'Cutter', 'start': 64, 'end': 70}]\n",
      "ner tagged text B-PER Peter E-PER could give no very clear account of his transactions with B-PER Cutter E-PER.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Peter E-PER could give no very clear account of his transactions with B-PER Cutter E-PER.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0002.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9747286, 'word': 'Peter', 'start': 10, 'end': 15}]\n",
      "ner tagged text She asked B-PER Peter E-PER to wait a moment, and when she came back from the kitchen, she brought a bag of sandwiches and doughnuts for us.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription She asked B-PER Peter E-PER to wait a moment, and when she came back from the kitchen, she brought a bag of sandwiches and doughnuts for us.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0020.flac\n",
      "[]\n",
      "ner tagged text A black drove came up over the hill behind the wedding party.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription A black drove came up over the hill behind the wedding party.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0038.flac\n",
      "[{'entity_group': 'PER', 'score': 0.7144919, 'word': 'Mister Shimerda', 'start': 61, 'end': 76}]\n",
      "ner tagged text The loss of his two friends had a depressing effect upon old B-PER Mister Shimerda E-PER.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The loss of his two friends had a depressing effect upon old B-PER Mister Shimerda E-PER.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0036.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.6512148, 'word': 'auction', 'start': 11, 'end': 18}]\n",
      "ner tagged text During the B-MISC auction E-MISC, he went about with his head down and never lifted his eyes.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription During the B-MISC auction E-MISC, he went about with his head down and never lifted his eyes.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2035/147961/2035-147961-0028.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.5701931, 'word': 'Twenty', 'start': 0, 'end': 6}]\n",
      "ner tagged text B-MISC Twenty E-MISC thirty enough.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC Twenty E-MISC thirty enough.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0003.flac']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"narrative\" } tokens { name: \"it\" } tokens { name: \"may\" } tokens { name: \"be\" } tokens { name: \"is\" } tokens { name: \"woven\" } tokens { name: \"of\" } tokens { name: \"so\" } tokens { name: \"humble\" } tokens { name: \"a\" } tokens { name: \"texture\" } tokens { name: \"as\" } tokens { name: \"to\" } tokens { name: \"require\" } tokens { name: \"this\" } tokens { name: \"advantage\" } tokens { name: \"and\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"same\" } tokens { name: \"time\" } tokens { name: \"to\" } tokens { name: \"render\" } tokens { name: \"it\" } tokens { name: \"the\" } tokens { name: \"more\" } tokens { name: \"difficult\" } tokens { name: \"of\" } tokens { name: \"attainment\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:54 punctuation_capitalization_infer_dataset:127] Max length: 33\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:406] Min: 31 |                  Max: 31 |                  Mean: 31.0 |                  Median: 31.0\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:412] 75 percentile: 31.00\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:413] 99 percentile: 31.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.73batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"in\" } tokens { name: \"good\" } tokens { name: \"faith\" } tokens { name: \"however\" } tokens { name: \"he\" } tokens { name: \"is\" } tokens { name: \"not\" } tokens { name: \"sufficiently\" } tokens { name: \"imaginative\" } tokens { name: \"to\" } tokens { name: \"flatter\" } tokens { name: \"himself\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"slightest\" } tokens { name: \"hope\" } tokens { name: \"of\" } tokens { name: \"this\" } tokens { name: \"kind\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:54 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.89batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"author\" } tokens { name: \"has\" } tokens { name: \"considered\" } tokens { name: \"it\" } tokens { name: \"hardly\" } tokens { name: \"worth\" } tokens { name: \"his\" } tokens { name: \"while\" } tokens { name: \"therefore\" } tokens { name: \"relentlessly\" } tokens { name: \"to\" } tokens { name: \"impale\" } tokens { name: \"the\" } tokens { name: \"story\" } tokens { name: \"with\" } tokens { name: \"its\" } tokens { name: \"moral\" } tokens { name: \"as\" } tokens { name: \"with\" } tokens { name: \"an\" } tokens { name: \"iron\" } tokens { name: \"rod\" } tokens { name: \"or\" } tokens { name: \"rather\" } tokens { name: \"as\" } tokens { name: \"by\" } tokens { name: \"sticking\" } tokens { name: \"a\" } tokens { name: \"pin\" } tokens { name: \"through\" } tokens { name: \"a\" } tokens { name: \"butterfly\" } tokens { name: \"thus\" } tokens { name: \"at\" } tokens { name: \"once\" } tokens { name: \"depriving\" } tokens { name: \"it\" } tokens { name: \"of\" } tokens { name: \"life\" } tokens { name: \"and\" } tokens { name: \"causing\" } tokens { name: \"it\" } tokens { name: \"to\" } tokens { name: \"stiffen\" } tokens { name: \"in\" } tokens { name: \"an\" } tokens { name: \"ungainly\" } tokens { name: \"and\" } tokens { name: \"unnatural\" } tokens { name: \"attitude\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:54 punctuation_capitalization_infer_dataset:127] Max length: 61\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:406] Min: 59 |                  Max: 59 |                  Mean: 59.0 |                  Median: 59.0\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:412] 75 percentile: 59.00\n",
      "[NeMo I 2023-11-12 08:26:54 data_preprocessing:413] 99 percentile: 59.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.90batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"if\" } tokens { name: \"permitted\" } tokens { name: \"by\" } tokens { name: \"the\" } tokens { name: \"historical\" } tokens { name: \"connection\" } tokens { name: \"which\" } tokens { name: \"though\" } tokens { name: \"slight\" } tokens { name: \"was\" } tokens { name: \"essential\" } tokens { name: \"to\" } tokens { name: \"his\" } tokens { name: \"plan\" } tokens { name: \"the\" } tokens { name: \"author\" } tokens { name: \"would\" } tokens { name: \"very\" } tokens { name: \"willingly\" } tokens { name: \"have\" } tokens { name: \"avoided\" } tokens { name: \"anything\" } tokens { name: \"of\" } tokens { name: \"this\" } tokens { name: \"nature\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:55 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.81batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"trusts\" } tokens { name: \"not\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"considered\" } tokens { name: \"as\" } tokens { name: \"unpardonably\" } tokens { name: \"offending\" } tokens { name: \"by\" } tokens { name: \"laying\" } tokens { name: \"out\" } tokens { name: \"a\" } tokens { name: \"street\" } tokens { name: \"that\" } tokens { name: \"infringes\" } tokens { name: \"upon\" } tokens { name: \"nobody's\" } tokens { name: \"private\" } tokens { name: \"rights\" } tokens { name: \"and\" } tokens { name: \"appropriating\" } tokens { name: \"a\" } tokens { name: \"lot\" } tokens { name: \"of\" } tokens { name: \"land\" } tokens { name: \"which\" } tokens { name: \"had\" } tokens { name: \"no\" } tokens { name: \"visible\" } tokens { name: \"owner\" } tokens { name: \"and\" } tokens { name: \"building\" } tokens { name: \"a\" } tokens { name: \"house\" } tokens { name: \"of\" } tokens { name: \"materials\" } tokens { name: \"long\" } tokens { name: \"in\" } tokens { name: \"use\" } tokens { name: \"for\" } tokens { name: \"constructing\" } tokens { name: \"castles\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"air\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:26:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:26:55 punctuation_capitalization_infer_dataset:127] Max length: 60\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:406] Min: 58 |                  Max: 58 |                  Mean: 58.0 |                  Median: 58.0\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:412] 75 percentile: 58.00\n",
      "[NeMo I 2023-11-12 08:26:55 data_preprocessing:413] 99 percentile: 58.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0001.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.7886988, 'word': 'good', 'start': 3, 'end': 7}, {'entity_group': 'MISC', 'score': 0.5454882, 'word': 'faith', 'start': 8, 'end': 13}]\n",
      "ner tagged text In B-MISC good E-MISC B-MISC faith E-MISC, however, he is not sufficiently imaginative to flatter himself with the slightest hope of this kind.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription In B-MISC good E-MISC B-MISC faith E-MISC, however, he is not sufficiently imaginative to flatter himself with the slightest hope of this kind.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0004.flac\n",
      "[]\n",
      "ner tagged text He trusts not to be considered as unpardonably offending by laying out a street that infringes upon nobody's private rights, and appropriating a lot of land which had no visible owner, and building a house of materials long in use for constructing castles in the air.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He trusts not to be considered as unpardonably offending by laying out a street that infringes upon nobody's private rights, and appropriating a lot of land which had no visible owner, and building a house of materials long in use for constructing castles in the air.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0000.flac\n",
      "[]\n",
      "ner tagged text The narrative it may be is woven of so humble a texture as to require this advantage, and at the same time to render it the more difficult of attainment.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The narrative it may be is woven of so humble a texture as to require this advantage, and at the same time to render it the more difficult of attainment.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0002.flac\n",
      "[]\n",
      "ner tagged text The author has considered it hardly worth his while, therefore relentlessly to impale the story with its moral, as with an iron rod, or rather as by sticking a pin through a butterfly, thus at once depriving it of life and causing it to stiffen in an ungainly and unnatural attitude.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription The author has considered it hardly worth his while, therefore relentlessly to impale the story with its moral, as with an iron rod, or rather as by sticking a pin through a butterfly, thus at once depriving it of life and causing it to stiffen in an ungainly and unnatural attitude.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149214/2086-149214-0003.flac\n",
      "[]\n",
      "ner tagged text If permitted by the historical connection, which, though slight was essential to his plan, the author would very willingly have avoided anything of this nature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"enclosure\" } tokens { name: \"had\" } tokens { name: \"formerly\" } tokens { name: \"been\" } tokens { name: \"very\" } tokens { name: \"extensive\" } tokens { name: \"but\" } tokens { name: \"was\" } tokens { name: \"now\" } tokens { name: \"contracted\" } tokens { name: \"within\" } tokens { name: \"small\" } tokens { name: \"compass\" } tokens { name: \"and\" } tokens { name: \"hemmed\" } tokens { name: \"about\" } tokens { name: \"partly\" } tokens { name: \"by\" } tokens { name: \"high\" } tokens { name: \"wooden\" } tokens { name: \"fences\" } tokens { name: \"and\" } tokens { name: \"partly\" } tokens { name: \"by\" } tokens { name: \"the\" } tokens { name: \"outbuildings\" } tokens { name: \"of\" } tokens { name: \"houses\" } tokens { name: \"that\" } tokens { name: \"stood\" } tokens { name: \"on\" } tokens { name: \"another\" } tokens { name: \"street\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription If permitted by the historical connection, which, though slight was essential to his plan, the author would very willingly have avoided anything of this nature.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0047.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0028.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0025.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0040.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0030.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0038.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0048.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0022.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0042.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0027.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0037.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0044.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0024.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0033.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0035.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0032.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0041.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0049.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0021.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0029.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0046.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0031.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0045.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0036.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0023.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0043.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0039.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0034.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0026.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0006.flac']\n",
      "[NeMo I 2023-11-12 08:27:02 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:02 punctuation_capitalization_infer_dataset:127] Max length: 39\n",
      "[NeMo I 2023-11-12 08:27:02 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:02 data_preprocessing:406] Min: 37 |                  Max: 37 |                  Mean: 37.0 |                  Median: 37.0\n",
      "[NeMo I 2023-11-12 08:27:02 data_preprocessing:412] 75 percentile: 37.00\n",
      "[NeMo I 2023-11-12 08:27:02 data_preprocessing:413] 99 percentile: 37.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.48batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"white\" } tokens { name: \"double\" } tokens { name: \"rosebush\" } tokens { name: \"had\" } tokens { name: \"evidently\" } tokens { name: \"been\" } tokens { name: \"propped\" } tokens { name: \"up\" } tokens { name: \"anew\" } tokens { name: \"against\" } tokens { name: \"the\" } tokens { name: \"house\" } tokens { name: \"since\" } tokens { name: \"the\" } tokens { name: \"commencement\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"season\" } tokens { name: \"and\" } tokens { name: \"a\" } tokens { name: \"pear\" } tokens { name: \"tree\" } tokens { name: \"and\" } tokens { name: \"three\" } tokens { name: \"damson\" } tokens { name: \"trees\" } tokens { name: \"which\" } tokens { name: \"except\" } tokens { name: \"a\" } tokens { name: \"row\" } tokens { name: \"of\" } tokens { name: \"currant\" } tokens { name: \"bushes\" } tokens { name: \"constituted\" } tokens { name: \"the\" } tokens { name: \"only\" } tokens { name: \"varieties\" } tokens { name: \"of\" } tokens { name: \"fruit\" } tokens { name: \"bore\" } tokens { name: \"marks\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"recent\" } tokens { name: \"amputation\" } tokens { name: \"of\" } tokens { name: \"several\" } tokens { name: \"superfluous\" } tokens { name: \"or\" } tokens { name: \"defective\" } tokens { name: \"limbs\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:03 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:03 punctuation_capitalization_infer_dataset:127] Max length: 61\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:406] Min: 59 |                  Max: 59 |                  Mean: 59.0 |                  Median: 59.0\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:412] 75 percentile: 59.00\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:413] 99 percentile: 59.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.30batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"there\" } tokens { name: \"were\" } tokens { name: \"also\" } tokens { name: \"a\" } tokens { name: \"few\" } tokens { name: \"species\" } tokens { name: \"of\" } tokens { name: \"antique\" } tokens { name: \"and\" } tokens { name: \"hereditary\" } tokens { name: \"flowers\" } tokens { name: \"in\" } tokens { name: \"no\" } tokens { name: \"very\" } tokens { name: \"flourishing\" } tokens { name: \"condition\" } tokens { name: \"but\" } tokens { name: \"scrupulously\" } tokens { name: \"weeded\" } tokens { name: \"as\" } tokens { name: \"if\" } tokens { name: \"some\" } tokens { name: \"person\" } tokens { name: \"either\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"love\" } tokens { name: \"or\" } tokens { name: \"curiosity\" } tokens { name: \"had\" } tokens { name: \"been\" } tokens { name: \"anxious\" } tokens { name: \"to\" } tokens { name: \"bring\" } tokens { name: \"them\" } tokens { name: \"to\" } tokens { name: \"such\" } tokens { name: \"perfection\" } tokens { name: \"as\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"capable\" } tokens { name: \"of\" } tokens { name: \"attaining\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:03 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:03 punctuation_capitalization_infer_dataset:127] Max length: 49\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:406] Min: 47 |                  Max: 47 |                  Mean: 47.0 |                  Median: 47.0\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:412] 75 percentile: 47.00\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:413] 99 percentile: 47.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.51batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"summer\" } tokens { name: \"squashes\" } tokens { name: \"almost\" } tokens { name: \"in\" } tokens { name: \"their\" } tokens { name: \"golden\" } tokens { name: \"blossom\" } tokens { name: \"cucumbers\" } tokens { name: \"now\" } tokens { name: \"evincing\" } tokens { name: \"a\" } tokens { name: \"tendency\" } tokens { name: \"to\" } tokens { name: \"spread\" } tokens { name: \"away\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"main\" } tokens { name: \"stock\" } tokens { name: \"and\" } tokens { name: \"ramble\" } tokens { name: \"far\" } tokens { name: \"and\" } tokens { name: \"wide\" } tokens { name: \"two\" } tokens { name: \"or\" } tokens { name: \"three\" } tokens { name: \"rows\" } tokens { name: \"of\" } tokens { name: \"string\" } tokens { name: \"beans\" } tokens { name: \"and\" } tokens { name: \"as\" } tokens { name: \"many\" } tokens { name: \"more\" } tokens { name: \"that\" } tokens { name: \"were\" } tokens { name: \"about\" } tokens { name: \"to\" } tokens { name: \"festoon\" } tokens { name: \"themselves\" } tokens { name: \"on\" } tokens { name: \"poles\" } tokens { name: \"tomatoes\" } tokens { name: \"occupying\" } tokens { name: \"a\" } tokens { name: \"site\" } tokens { name: \"so\" } tokens { name: \"sheltered\" } tokens { name: \"and\" } tokens { name: \"sunny\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"plants\" } tokens { name: \"were\" } tokens { name: \"already\" } tokens { name: \"gigantic\" } tokens { name: \"and\" } tokens { name: \"promised\" } tokens { name: \"an\" } tokens { name: \"early\" } tokens { name: \"and\" } tokens { name: \"abundant\" } tokens { name: \"harvest\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:03 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:03 punctuation_capitalization_infer_dataset:127] Max length: 64\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:406] Min: 71 |                  Max: 71 |                  Mean: 71.0 |                  Median: 71.0\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:412] 75 percentile: 71.00\n",
      "[NeMo I 2023-11-12 08:27:03 data_preprocessing:413] 99 percentile: 71.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.11batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"phoebe\" } tokens { name: \"wondered\" } tokens { name: \"whose\" } tokens { name: \"care\" } tokens { name: \"and\" } tokens { name: \"toil\" } tokens { name: \"it\" } tokens { name: \"could\" } tokens { name: \"have\" } tokens { name: \"been\" } tokens { name: \"that\" } tokens { name: \"had\" } tokens { name: \"planted\" } tokens { name: \"these\" } tokens { name: \"vegetables\" } tokens { name: \"and\" } tokens { name: \"kept\" } tokens { name: \"the\" } tokens { name: \"soil\" } tokens { name: \"so\" } tokens { name: \"clean\" } tokens { name: \"and\" } tokens { name: \"orderly\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_infer_dataset:127] Max length: 26\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:406] Min: 24 |                  Max: 24 |                  Mean: 24.0 |                  Median: 24.0\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:412] 75 percentile: 24.00\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:413] 99 percentile: 24.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.82batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"bees\" } tokens { name: \"too\" } tokens { name: \"strange\" } tokens { name: \"to\" } tokens { name: \"say\" } tokens { name: \"had\" } tokens { name: \"thought\" } tokens { name: \"it\" } tokens { name: \"worth\" } tokens { name: \"their\" } tokens { name: \"while\" } tokens { name: \"to\" } tokens { name: \"come\" } tokens { name: \"hither\" } tokens { name: \"possibly\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"range\" } tokens { name: \"of\" } tokens { name: \"hives\" } tokens { name: \"beside\" } tokens { name: \"some\" } tokens { name: \"farm\" } tokens { name: \"house\" } tokens { name: \"miles\" } tokens { name: \"away\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.94batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"this\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"fountain\" } tokens { name: \"set\" } tokens { name: \"round\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"rim\" } tokens { name: \"of\" } tokens { name: \"old\" } tokens { name: \"mossy\" } tokens { name: \"stones\" } tokens { name: \"and\" } tokens { name: \"paved\" } tokens { name: \"in\" } tokens { name: \"its\" } tokens { name: \"bed\" } tokens { name: \"with\" } tokens { name: \"what\" } tokens { name: \"appeared\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"a\" } tokens { name: \"sort\" } tokens { name: \"of\" } tokens { name: \"mosaic\" } tokens { name: \"work\" } tokens { name: \"of\" } tokens { name: \"variously\" } tokens { name: \"colored\" } tokens { name: \"pebbles\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_infer_dataset:127] Max length: 35\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:406] Min: 33 |                  Max: 33 |                  Mean: 33.0 |                  Median: 33.0\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:412] 75 percentile: 33.00\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:413] 99 percentile: 33.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.89batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"now\" } tokens { name: \"contained\" } tokens { name: \"only\" } tokens { name: \"chanticleer\" } tokens { name: \"his\" } tokens { name: \"two\" } tokens { name: \"wives\" } tokens { name: \"and\" } tokens { name: \"a\" } tokens { name: \"solitary\" } tokens { name: \"chicken\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:04 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:27:04 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.65batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"evident\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"race\" } tokens { name: \"had\" } tokens { name: \"degenerated\" } tokens { name: \"like\" } tokens { name: \"many\" } tokens { name: \"a\" } tokens { name: \"noble\" } tokens { name: \"race\" } tokens { name: \"besides\" } tokens { name: \"in\" } tokens { name: \"consequence\" } tokens { name: \"of\" } tokens { name: \"too\" } tokens { name: \"strict\" } tokens { name: \"a\" } tokens { name: \"watchfulness\" } tokens { name: \"to\" } tokens { name: \"keep\" } tokens { name: \"it\" } tokens { name: \"pure\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:05 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:05 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"these\" } tokens { name: \"feathered\" } tokens { name: \"people\" } tokens { name: \"had\" } tokens { name: \"existed\" } tokens { name: \"too\" } tokens { name: \"long\" } tokens { name: \"in\" } tokens { name: \"their\" } tokens { name: \"distinct\" } tokens { name: \"variety\" } tokens { name: \"a\" } tokens { name: \"fact\" } tokens { name: \"of\" } tokens { name: \"which\" } tokens { name: \"the\" } tokens { name: \"present\" } tokens { name: \"representatives\" } tokens { name: \"judging\" } tokens { name: \"by\" } tokens { name: \"their\" } tokens { name: \"lugubrious\" } tokens { name: \"deportment\" } tokens { name: \"seemed\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"aware\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:05 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:05 punctuation_capitalization_infer_dataset:127] Max length: 35\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:406] Min: 33 |                  Max: 33 |                  Mean: 33.0 |                  Median: 33.0\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:412] 75 percentile: 33.00\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:413] 99 percentile: 33.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.25batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"kept\" } tokens { name: \"themselves\" } tokens { name: \"alive\" } tokens { name: \"unquestionably\" } tokens { name: \"and\" } tokens { name: \"laid\" } tokens { name: \"now\" } tokens { name: \"and\" } tokens { name: \"then\" } tokens { name: \"an\" } tokens { name: \"egg\" } tokens { name: \"and\" } tokens { name: \"hatched\" } tokens { name: \"a\" } tokens { name: \"chicken\" } tokens { name: \"not\" } tokens { name: \"for\" } tokens { name: \"any\" } tokens { name: \"pleasure\" } tokens { name: \"of\" } tokens { name: \"their\" } tokens { name: \"own\" } tokens { name: \"but\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"world\" } tokens { name: \"might\" } tokens { name: \"not\" } tokens { name: \"absolutely\" } tokens { name: \"lose\" } tokens { name: \"what\" } tokens { name: \"had\" } tokens { name: \"once\" } tokens { name: \"been\" } tokens { name: \"so\" } tokens { name: \"admirable\" } tokens { name: \"a\" } tokens { name: \"breed\" } tokens { name: \"of\" } tokens { name: \"fowls\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:05 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:05 punctuation_capitalization_infer_dataset:127] Max length: 51\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:406] Min: 49 |                  Max: 49 |                  Mean: 49.0 |                  Median: 49.0\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:412] 75 percentile: 49.00\n",
      "[NeMo I 2023-11-12 08:27:05 data_preprocessing:413] 99 percentile: 49.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.18batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"distinguishing\" } tokens { name: \"mark\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"hens\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"crest\" } tokens { name: \"of\" } tokens { name: \"lamentably\" } tokens { name: \"scanty\" } tokens { name: \"growth\" } tokens { name: \"in\" } tokens { name: \"these\" } tokens { name: \"latter\" } tokens { name: \"days\" } tokens { name: \"but\" } tokens { name: \"so\" } tokens { name: \"oddly\" } tokens { name: \"and\" } tokens { name: \"wickedly\" } tokens { name: \"analogous\" } tokens { name: \"to\" } tokens { name: \"hepzibah's\" } tokens { name: \"turban\" } tokens { name: \"that\" } tokens { name: \"phoebe\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"poignant\" } tokens { name: \"distress\" } tokens { name: \"of\" } tokens { name: \"her\" } tokens { name: \"conscience\" } tokens { name: \"but\" } tokens { name: \"inevitably\" } tokens { name: \"was\" } tokens { name: \"led\" } tokens { name: \"to\" } tokens { name: \"fancy\" } tokens { name: \"a\" } tokens { name: \"general\" } tokens { name: \"resemblance\" } tokens { name: \"betwixt\" } tokens { name: \"these\" } tokens { name: \"forlorn\" } tokens { name: \"bipeds\" } tokens { name: \"and\" } tokens { name: \"her\" } tokens { name: \"respectable\" } tokens { name: \"relative\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:06 punctuation_capitalization_infer_dataset:127] Max length: 64\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:406] Min: 71 |                  Max: 71 |                  Mean: 71.0 |                  Median: 71.0\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:412] 75 percentile: 71.00\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:413] 99 percentile: 71.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 12.46batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"chicken\" } tokens { name: \"crept\" } tokens { name: \"through\" } tokens { name: \"the\" } tokens { name: \"pales\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"coop\" } tokens { name: \"and\" } tokens { name: \"ran\" } tokens { name: \"with\" } tokens { name: \"some\" } tokens { name: \"show\" } tokens { name: \"of\" } tokens { name: \"liveliness\" } tokens { name: \"to\" } tokens { name: \"her\" } tokens { name: \"feet\" } tokens { name: \"while\" } tokens { name: \"chanticleer\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"ladies\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"household\" } tokens { name: \"regarded\" } tokens { name: \"her\" } tokens { name: \"with\" } tokens { name: \"queer\" } tokens { name: \"sidelong\" } tokens { name: \"glances\" } tokens { name: \"and\" } tokens { name: \"then\" } tokens { name: \"croaked\" } tokens { name: \"one\" } tokens { name: \"to\" } tokens { name: \"another\" } tokens { name: \"as\" } tokens { name: \"if\" } tokens { name: \"communicating\" } tokens { name: \"their\" } tokens { name: \"sage\" } tokens { name: \"opinions\" } tokens { name: \"of\" } tokens { name: \"her\" } tokens { name: \"character\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:06 punctuation_capitalization_infer_dataset:127] Max length: 57\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:406] Min: 55 |                  Max: 55 |                  Mean: 55.0 |                  Median: 55.0\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:412] 75 percentile: 55.00\n",
      "[NeMo I 2023-11-12 08:27:06 data_preprocessing:413] 99 percentile: 55.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.03batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"so\" } tokens { name: \"wise\" } tokens { name: \"as\" } tokens { name: \"well\" } tokens { name: \"as\" } tokens { name: \"antique\" } tokens { name: \"was\" } tokens { name: \"their\" } tokens { name: \"aspect\" } tokens { name: \"as\" } tokens { name: \"to\" } tokens { name: \"give\" } tokens { name: \"color\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"idea\" } tokens { name: \"not\" } tokens { name: \"merely\" } tokens { name: \"that\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"the\" } tokens { name: \"descendants\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"time\" } tokens { name: \"honored\" } tokens { name: \"race\" } tokens { name: \"but\" } tokens { name: \"that\" } tokens { name: \"they\" } tokens { name: \"had\" } tokens { name: \"existed\" } tokens { name: \"in\" } tokens { name: \"their\" } tokens { name: \"individual\" } tokens { name: \"capacity\" } tokens { name: \"ever\" } tokens { name: \"since\" } tokens { name: \"the\" } tokens { name: \"house\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"seven\" } tokens { name: \"gables\" } tokens { name: \"was\" } tokens { name: \"founded\" } tokens { name: \"and\" } tokens { name: \"were\" } tokens { name: \"somehow\" } tokens { name: \"mixed\" } tokens { name: \"up\" } tokens { name: \"with\" } tokens { name: \"its\" } tokens { name: \"destiny\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_infer_dataset:127] Max length: 57\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:406] Min: 55 |                  Max: 55 |                  Mean: 55.0 |                  Median: 55.0\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:412] 75 percentile: 55.00\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:413] 99 percentile: 55.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.80batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"held\" } tokens { name: \"a\" } tokens { name: \"hoe\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"hand\" } tokens { name: \"and\" } tokens { name: \"while\" } tokens { name: \"phoebe\" } tokens { name: \"was\" } tokens { name: \"gone\" } tokens { name: \"in\" } tokens { name: \"quest\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"crumbs\" } tokens { name: \"had\" } tokens { name: \"begun\" } tokens { name: \"to\" } tokens { name: \"busy\" } tokens { name: \"himself\" } tokens { name: \"with\" } tokens { name: \"drawing\" } tokens { name: \"up\" } tokens { name: \"fresh\" } tokens { name: \"earth\" } tokens { name: \"about\" } tokens { name: \"the\" } tokens { name: \"roots\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"tomatoes\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_infer_dataset:127] Max length: 38\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:406] Min: 36 |                  Max: 36 |                  Mean: 36.0 |                  Median: 36.0\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:412] 75 percentile: 36.00\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:413] 99 percentile: 36.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.42batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"have\" } tokens { name: \"known\" } tokens { name: \"me\" } tokens { name: \"much\" } tokens { name: \"longer\" } tokens { name: \"but\" } tokens { name: \"never\" } tokens { name: \"honor\" } tokens { name: \"me\" } tokens { name: \"with\" } tokens { name: \"any\" } tokens { name: \"familiarity\" } tokens { name: \"though\" } tokens { name: \"hardly\" } tokens { name: \"a\" } tokens { name: \"day\" } tokens { name: \"passes\" } tokens { name: \"without\" } tokens { name: \"my\" } tokens { name: \"bringing\" } tokens { name: \"them\" } tokens { name: \"food\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.80batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"miss\" } tokens { name: \"hepzibah\" } tokens { name: \"i\" } tokens { name: \"suppose\" } tokens { name: \"will\" } tokens { name: \"interweave\" } tokens { name: \"the\" } tokens { name: \"fact\" } tokens { name: \"with\" } tokens { name: \"her\" } tokens { name: \"other\" } tokens { name: \"traditions\" } tokens { name: \"and\" } tokens { name: \"set\" } tokens { name: \"it\" } tokens { name: \"down\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"fowls\" } tokens { name: \"know\" } tokens { name: \"you\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"a\" } tokens { name: \"pyncheon\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:07 punctuation_capitalization_infer_dataset:127] Max length: 36\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:406] Min: 34 |                  Max: 34 |                  Mean: 34.0 |                  Median: 34.0\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:412] 75 percentile: 34.00\n",
      "[NeMo I 2023-11-12 08:27:07 data_preprocessing:413] 99 percentile: 34.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.44batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"ah\" } tokens { name: \"but\" } tokens { name: \"these\" } tokens { name: \"hens\" } tokens { name: \"answered\" } tokens { name: \"the\" } tokens { name: \"young\" } tokens { name: \"man\" } tokens { name: \"these\" } tokens { name: \"hens\" } tokens { name: \"of\" } tokens { name: \"aristocratic\" } tokens { name: \"lineage\" } tokens { name: \"would\" } tokens { name: \"scorn\" } tokens { name: \"to\" } tokens { name: \"understand\" } tokens { name: \"the\" } tokens { name: \"vulgar\" } tokens { name: \"language\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"barn\" } tokens { name: \"yard\" } tokens { name: \"fowl\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_infer_dataset:127] Max length: 32\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:406] Min: 30 |                  Max: 30 |                  Mean: 30.0 |                  Median: 30.0\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:412] 75 percentile: 30.00\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:413] 99 percentile: 30.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.58batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"prefer\" } tokens { name: \"to\" } tokens { name: \"think\" } tokens { name: \"and\" } tokens { name: \"so\" } tokens { name: \"would\" } tokens { name: \"miss\" } tokens { name: \"hepzibah\" } tokens { name: \"that\" } tokens { name: \"they\" } tokens { name: \"recognize\" } tokens { name: \"the\" } tokens { name: \"family\" } tokens { name: \"tone\" } tokens { name: \"for\" } tokens { name: \"you\" } tokens { name: \"are\" } tokens { name: \"a\" } tokens { name: \"pyncheon\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.79batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"my\" } tokens { name: \"name\" } tokens { name: \"is\" } tokens { name: \"phoebe\" } tokens { name: \"pyncheon\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"girl\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"manner\" } tokens { name: \"of\" } tokens { name: \"some\" } tokens { name: \"reserve\" } tokens { name: \"for\" } tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"aware\" } tokens { name: \"that\" } tokens { name: \"her\" } tokens { name: \"new\" } tokens { name: \"acquaintance\" } tokens { name: \"could\" } tokens { name: \"be\" } tokens { name: \"no\" } tokens { name: \"other\" } tokens { name: \"than\" } tokens { name: \"the\" } tokens { name: \"daguerreotypist\" } tokens { name: \"of\" } tokens { name: \"whose\" } tokens { name: \"lawless\" } tokens { name: \"propensities\" } tokens { name: \"the\" } tokens { name: \"old\" } tokens { name: \"maid\" } tokens { name: \"had\" } tokens { name: \"given\" } tokens { name: \"her\" } tokens { name: \"a\" } tokens { name: \"disagreeable\" } tokens { name: \"idea\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_infer_dataset:127] Max length: 55\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:406] Min: 53 |                  Max: 53 |                  Mean: 53.0 |                  Median: 53.0\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:412] 75 percentile: 53.00\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:413] 99 percentile: 53.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.58batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"turn\" } tokens { name: \"up\" } tokens { name: \"the\" } tokens { name: \"earth\" } tokens { name: \"by\" } tokens { name: \"way\" } tokens { name: \"of\" } tokens { name: \"pastime\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.20batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"like\" } tokens { name: \"a\" } tokens { name: \"bandage\" } tokens { name: \"over\" } tokens { name: \"one's\" } tokens { name: \"eyes\" } tokens { name: \"to\" } tokens { name: \"come\" } tokens { name: \"into\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:08 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:27:08 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.76batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"if\" } tokens { name: \"you\" } tokens { name: \"would\" } tokens { name: \"permit\" } tokens { name: \"me\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"artist\" } tokens { name: \"looking\" } tokens { name: \"at\" } tokens { name: \"phoebe\" } tokens { name: \"i\" } tokens { name: \"should\" } tokens { name: \"like\" } tokens { name: \"to\" } tokens { name: \"try\" } tokens { name: \"whether\" } tokens { name: \"the\" } tokens { name: \"daguerreotype\" } tokens { name: \"can\" } tokens { name: \"bring\" } tokens { name: \"out\" } tokens { name: \"disagreeable\" } tokens { name: \"traits\" } tokens { name: \"on\" } tokens { name: \"a\" } tokens { name: \"perfectly\" } tokens { name: \"amiable\" } tokens { name: \"face\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_infer_dataset:127] Max length: 36\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:406] Min: 34 |                  Max: 34 |                  Mean: 34.0 |                  Median: 34.0\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:412] 75 percentile: 34.00\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:413] 99 percentile: 34.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.12batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"most\" } tokens { name: \"of\" } tokens { name: \"my\" } tokens { name: \"likenesses\" } tokens { name: \"do\" } tokens { name: \"look\" } tokens { name: \"unamiable\" } tokens { name: \"but\" } tokens { name: \"the\" } tokens { name: \"very\" } tokens { name: \"sufficient\" } tokens { name: \"reason\" } tokens { name: \"i\" } tokens { name: \"fancy\" } tokens { name: \"is\" } tokens { name: \"because\" } tokens { name: \"the\" } tokens { name: \"originals\" } tokens { name: \"are\" } tokens { name: \"so\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.86batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"there\" } tokens { name: \"is\" } tokens { name: \"a\" } tokens { name: \"wonderful\" } tokens { name: \"insight\" } tokens { name: \"in\" } tokens { name: \"heaven's\" } tokens { name: \"broad\" } tokens { name: \"and\" } tokens { name: \"simple\" } tokens { name: \"sunshine\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.59batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"while\" } tokens { name: \"we\" } tokens { name: \"give\" } tokens { name: \"it\" } tokens { name: \"credit\" } tokens { name: \"only\" } tokens { name: \"for\" } tokens { name: \"depicting\" } tokens { name: \"the\" } tokens { name: \"merest\" } tokens { name: \"surface\" } tokens { name: \"it\" } tokens { name: \"actually\" } tokens { name: \"brings\" } tokens { name: \"out\" } tokens { name: \"the\" } tokens { name: \"secret\" } tokens { name: \"character\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"truth\" } tokens { name: \"that\" } tokens { name: \"no\" } tokens { name: \"painter\" } tokens { name: \"would\" } tokens { name: \"ever\" } tokens { name: \"venture\" } tokens { name: \"upon\" } tokens { name: \"even\" } tokens { name: \"could\" } tokens { name: \"he\" } tokens { name: \"detect\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:09 punctuation_capitalization_infer_dataset:127] Max length: 36\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:406] Min: 34 |                  Max: 34 |                  Mean: 34.0 |                  Median: 34.0\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:412] 75 percentile: 34.00\n",
      "[NeMo I 2023-11-12 08:27:09 data_preprocessing:413] 99 percentile: 34.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.04batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"yet\" } tokens { name: \"the\" } tokens { name: \"original\" } tokens { name: \"wears\" } tokens { name: \"to\" } tokens { name: \"common\" } tokens { name: \"eyes\" } tokens { name: \"a\" } tokens { name: \"very\" } tokens { name: \"different\" } tokens { name: \"expression\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.14batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"exhibited\" } tokens { name: \"a\" } tokens { name: \"daguerreotype\" } tokens { name: \"miniature\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"morocco\" } tokens { name: \"case\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.02batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"phoebe\" } tokens { name: \"merely\" } tokens { name: \"glanced\" } tokens { name: \"at\" } tokens { name: \"it\" } tokens { name: \"and\" } tokens { name: \"gave\" } tokens { name: \"it\" } tokens { name: \"back\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.32batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"can\" } tokens { name: \"assure\" } tokens { name: \"you\" } tokens { name: \"that\" } tokens { name: \"this\" } tokens { name: \"is\" } tokens { name: \"a\" } tokens { name: \"modern\" } tokens { name: \"face\" } tokens { name: \"and\" } tokens { name: \"one\" } tokens { name: \"which\" } tokens { name: \"you\" } tokens { name: \"will\" } tokens { name: \"very\" } tokens { name: \"probably\" } tokens { name: \"meet\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.57batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"sun\" } tokens { name: \"as\" } tokens { name: \"you\" } tokens { name: \"see\" } tokens { name: \"tells\" } tokens { name: \"quite\" } tokens { name: \"another\" } tokens { name: \"story\" } tokens { name: \"and\" } tokens { name: \"will\" } tokens { name: \"not\" } tokens { name: \"be\" } tokens { name: \"coaxed\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"it\" } tokens { name: \"after\" } tokens { name: \"half\" } tokens { name: \"a\" } tokens { name: \"dozen\" } tokens { name: \"patient\" } tokens { name: \"attempts\" } tokens { name: \"on\" } tokens { name: \"my\" } tokens { name: \"part\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.99batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"here\" } tokens { name: \"we\" } tokens { name: \"have\" } tokens { name: \"the\" } tokens { name: \"man\" } tokens { name: \"sly\" } tokens { name: \"subtle\" } tokens { name: \"hard\" } tokens { name: \"imperious\" } tokens { name: \"and\" } tokens { name: \"withal\" } tokens { name: \"cold\" } tokens { name: \"as\" } tokens { name: \"ice\" } tokens { name: \"look\" } tokens { name: \"at\" } tokens { name: \"that\" } tokens { name: \"eye\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:10 punctuation_capitalization_infer_dataset:127] Max length: 23\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:406] Min: 21 |                  Max: 21 |                  Mean: 21.0 |                  Median: 21.0\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:412] 75 percentile: 21.00\n",
      "[NeMo I 2023-11-12 08:27:10 data_preprocessing:413] 99 percentile: 21.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.27batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"and\" } tokens { name: \"yet\" } tokens { name: \"if\" } tokens { name: \"you\" } tokens { name: \"could\" } tokens { name: \"only\" } tokens { name: \"see\" } tokens { name: \"the\" } tokens { name: \"benign\" } tokens { name: \"smile\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"original\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.96batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"well\" } tokens { name: \"i\" } tokens { name: \"don't\" } tokens { name: \"wish\" } tokens { name: \"to\" } tokens { name: \"see\" } tokens { name: \"it\" } tokens { name: \"any\" } tokens { name: \"more\" } tokens { name: \"observed\" } tokens { name: \"phoebe\" } tokens { name: \"turning\" } tokens { name: \"away\" } tokens { name: \"her\" } tokens { name: \"eyes\" } tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"certainly\" } tokens { name: \"very\" } tokens { name: \"like\" } tokens { name: \"the\" } tokens { name: \"old\" } tokens { name: \"portrait\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.98batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"if\" } tokens { name: \"the\" } tokens { name: \"original\" } tokens { name: \"is\" } tokens { name: \"still\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"world\" } tokens { name: \"i\" } tokens { name: \"think\" } tokens { name: \"he\" } tokens { name: \"might\" } tokens { name: \"defy\" } tokens { name: \"the\" } tokens { name: \"sun\" } tokens { name: \"to\" } tokens { name: \"make\" } tokens { name: \"him\" } tokens { name: \"look\" } tokens { name: \"stern\" } tokens { name: \"and\" } tokens { name: \"hard\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.00batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"is\" } tokens { name: \"there\" } tokens { name: \"nothing\" } tokens { name: \"wild\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"eye\" } tokens { name: \"continued\" } tokens { name: \"holgrave\" } tokens { name: \"so\" } tokens { name: \"earnestly\" } tokens { name: \"that\" } tokens { name: \"it\" } tokens { name: \"embarrassed\" } tokens { name: \"phoebe\" } tokens { name: \"as\" } tokens { name: \"did\" } tokens { name: \"also\" } tokens { name: \"the\" } tokens { name: \"quiet\" } tokens { name: \"freedom\" } tokens { name: \"with\" } tokens { name: \"which\" } tokens { name: \"he\" } tokens { name: \"presumed\" } tokens { name: \"on\" } tokens { name: \"their\" } tokens { name: \"so\" } tokens { name: \"recent\" } tokens { name: \"acquaintance\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_infer_dataset:127] Max length: 35\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:406] Min: 33 |                  Max: 33 |                  Mean: 33.0 |                  Median: 33.0\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:412] 75 percentile: 33.00\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:413] 99 percentile: 33.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.10batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"nonsense\" } tokens { name: \"said\" } tokens { name: \"phoebe\" } tokens { name: \"a\" } tokens { name: \"little\" } tokens { name: \"impatiently\" } tokens { name: \"for\" } tokens { name: \"us\" } tokens { name: \"to\" } tokens { name: \"talk\" } tokens { name: \"about\" } tokens { name: \"a\" } tokens { name: \"picture\" } tokens { name: \"which\" } tokens { name: \"you\" } tokens { name: \"have\" } tokens { name: \"never\" } tokens { name: \"seen\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:11 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:27:11 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.50batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"since\" } tokens { name: \"you\" } tokens { name: \"are\" } tokens { name: \"a\" } tokens { name: \"friend\" } tokens { name: \"of\" } tokens { name: \"my\" } tokens { name: \"cousin\" } tokens { name: \"hepzibah's\" } tokens { name: \"you\" } tokens { name: \"should\" } tokens { name: \"ask\" } tokens { name: \"her\" } tokens { name: \"to\" } tokens { name: \"show\" } tokens { name: \"you\" } tokens { name: \"the\" } tokens { name: \"picture\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.37batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"so\" } tokens { name: \"we\" } tokens { name: \"will\" } tokens { name: \"be\" } tokens { name: \"fellow\" } tokens { name: \"laborers\" } tokens { name: \"somewhat\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"community\" } tokens { name: \"system\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.49batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"did\" } tokens { name: \"not\" } tokens { name: \"altogether\" } tokens { name: \"like\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_infer_dataset:127] Max length: 8\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:406] Min: 6 |                  Max: 6 |                  Mean: 6.0 |                  Median: 6.0\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:412] 75 percentile: 6.00\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:413] 99 percentile: 6.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.17batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"oh\" } tokens { name: \"rejoined\" } tokens { name: \"the\" } tokens { name: \"daguerreotypist\" } tokens { name: \"because\" } tokens { name: \"like\" } tokens { name: \"an\" } tokens { name: \"old\" } tokens { name: \"lady's\" } tokens { name: \"cup\" } tokens { name: \"of\" } tokens { name: \"tea\" } tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"water\" } tokens { name: \"bewitched\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.48batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"indistinctly\" } tokens { name: \"aware\" } tokens { name: \"however\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"gaunt\" } tokens { name: \"figure\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"old\" } tokens { name: \"gentlewoman\" } tokens { name: \"was\" } tokens { name: \"sitting\" } tokens { name: \"in\" } tokens { name: \"one\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"straight\" } tokens { name: \"backed\" } tokens { name: \"chairs\" } tokens { name: \"a\" } tokens { name: \"little\" } tokens { name: \"withdrawn\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"window\" } tokens { name: \"the\" } tokens { name: \"faint\" } tokens { name: \"gleam\" } tokens { name: \"of\" } tokens { name: \"which\" } tokens { name: \"showed\" } tokens { name: \"the\" } tokens { name: \"blanched\" } tokens { name: \"paleness\" } tokens { name: \"of\" } tokens { name: \"her\" } tokens { name: \"cheek\" } tokens { name: \"turned\" } tokens { name: \"sideways\" } tokens { name: \"towards\" } tokens { name: \"a\" } tokens { name: \"corner\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:12 punctuation_capitalization_infer_dataset:127] Max length: 54\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:406] Min: 52 |                  Max: 52 |                  Mean: 52.0 |                  Median: 52.0\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:412] 75 percentile: 52.00\n",
      "[NeMo I 2023-11-12 08:27:12 data_preprocessing:413] 99 percentile: 52.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.97batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"but\" } tokens { name: \"put\" } tokens { name: \"it\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"table\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"corner\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"passage\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.49batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"what\" } tokens { name: \"an\" } tokens { name: \"instrument\" } tokens { name: \"is\" } tokens { name: \"the\" } tokens { name: \"human\" } tokens { name: \"voice\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.93batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"how\" } tokens { name: \"wonderfully\" } tokens { name: \"responsive\" } tokens { name: \"to\" } tokens { name: \"every\" } tokens { name: \"emotion\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"human\" } tokens { name: \"soul\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.49batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"fewer\" } tokens { name: \"words\" } tokens { name: \"than\" } tokens { name: \"before\" } tokens { name: \"but\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"same\" } tokens { name: \"mysterious\" } tokens { name: \"music\" } tokens { name: \"in\" } tokens { name: \"them\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.80batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"pray\" } tokens { name: \"go\" } tokens { name: \"to\" } tokens { name: \"bed\" } tokens { name: \"for\" } tokens { name: \"i\" } tokens { name: \"am\" } tokens { name: \"sure\" } tokens { name: \"you\" } tokens { name: \"must\" } tokens { name: \"need\" } tokens { name: \"rest\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.55batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"will\" } tokens { name: \"sit\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"parlor\" } tokens { name: \"awhile\" } tokens { name: \"and\" } tokens { name: \"collect\" } tokens { name: \"my\" } tokens { name: \"thoughts\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.23batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"while\" } tokens { name: \"thus\" } tokens { name: \"dismissing\" } tokens { name: \"her\" } tokens { name: \"the\" } tokens { name: \"maiden\" } tokens { name: \"lady\" } tokens { name: \"stept\" } tokens { name: \"forward\" } tokens { name: \"kissed\" } tokens { name: \"phoebe\" } tokens { name: \"and\" } tokens { name: \"pressed\" } tokens { name: \"her\" } tokens { name: \"to\" } tokens { name: \"her\" } tokens { name: \"heart\" } tokens { name: \"which\" } tokens { name: \"beat\" } tokens { name: \"against\" } tokens { name: \"the\" } tokens { name: \"girl's\" } tokens { name: \"bosom\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"strong\" } tokens { name: \"high\" } tokens { name: \"and\" } tokens { name: \"tumultuous\" } tokens { name: \"swell\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:13 punctuation_capitalization_infer_dataset:127] Max length: 39\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:406] Min: 37 |                  Max: 37 |                  Mean: 37.0 |                  Median: 37.0\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:412] 75 percentile: 37.00\n",
      "[NeMo I 2023-11-12 08:27:13 data_preprocessing:413] 99 percentile: 37.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.24batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"at\" } tokens { name: \"some\" } tokens { name: \"uncertain\" } tokens { name: \"period\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"depths\" } tokens { name: \"of\" } tokens { name: \"night\" } tokens { name: \"and\" } tokens { name: \"as\" } tokens { name: \"it\" } tokens { name: \"were\" } tokens { name: \"through\" } tokens { name: \"the\" } tokens { name: \"thin\" } tokens { name: \"veil\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"dream\" } tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"conscious\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"footstep\" } tokens { name: \"mounting\" } tokens { name: \"the\" } tokens { name: \"stairs\" } tokens { name: \"heavily\" } tokens { name: \"but\" } tokens { name: \"not\" } tokens { name: \"with\" } tokens { name: \"force\" } tokens { name: \"and\" } tokens { name: \"decision\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:27:14 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:27:14 punctuation_capitalization_infer_dataset:127] Max length: 40\n",
      "[NeMo I 2023-11-12 08:27:14 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:27:14 data_preprocessing:406] Min: 38 |                  Max: 38 |                  Mean: 38.0 |                  Median: 38.0\n",
      "[NeMo I 2023-11-12 08:27:14 data_preprocessing:412] 75 percentile: 38.00\n",
      "[NeMo I 2023-11-12 08:27:14 data_preprocessing:413] 99 percentile: 38.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0004.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9990177, 'word': 'Phoebe', 'start': 0, 'end': 6}]\n",
      "ner tagged text B-PER Phoebe E-PER wondered whose care and toil it could have been that had planted these vegetables and kept the soil so clean and orderly.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-PER Phoebe E-PER wondered whose care and toil it could have been that had planted these vegetables and kept the soil so clean and orderly.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0013.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.59396243, 'word': 'House of the', 'start': 211, 'end': 223}, {'entity_group': 'MISC', 'score': 0.49966738, 'word': 'Seven Gables', 'start': 224, 'end': 236}]\n",
      "ner tagged text So wise as well as antique was their aspect as to give color to the idea, not merely that they were the descendants of a time honored race, but that they had existed in their individual capacity, ever since the B-LOC House of the E-LOC B-MISC Seven Gables E-MISC was founded and were somehow mixed up with its destiny.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription So wise as well as antique was their aspect as to give color to the idea, not merely that they were the descendants of a time honored race, but that they had existed in their individual capacity, ever since the B-LOC House of the E-LOC B-MISC Seven Gables E-MISC was founded and were somehow mixed up with its destiny.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0047.flac\n",
      "[]\n",
      "ner tagged text I will sit in the parlor awhile and collect my thoughts.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I will sit in the parlor awhile and collect my thoughts.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0007.flac\n",
      "[]\n",
      "ner tagged text It now contained only chanticleer, his two wives and a solitary chicken.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It now contained only chanticleer, his two wives and a solitary chicken.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0012.flac\n",
      "[{'entity_group': 'PER', 'score': 0.93596506, 'word': 'Chanticleer', 'start': 104, 'end': 115}]\n",
      "ner tagged text The chicken crept through the pales of the coop and ran with some show of liveliness to her feet, while B-PER Chanticleer E-PER and the ladies of his household regarded her with queer sidelong glances, and then croaked one to another as if communicating their sage opinions of her character.\n",
      "Emotion Labels []\n",
      "tagged transcription The chicken crept through the pales of the coop and ran with some show of liveliness to her feet, while B-PER Chanticleer E-PER and the ladies of his household regarded her with queer sidelong glances, and then croaked one to another as if communicating their sage opinions of her character.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0028.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9982741, 'word': 'Phoebe', 'start': 0, 'end': 6}]\n",
      "ner tagged text B-PER Phoebe E-PER merely glanced at it and gave it back.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-PER Phoebe E-PER merely glanced at it and gave it back.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0025.flac\n",
      "[]\n",
      "ner tagged text While we give it credit only for depicting the merest surface, it actually brings out the secret character with a truth that no painter would ever venture upon, even could he detect it?\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription While we give it credit only for depicting the merest surface, it actually brings out the secret character with a truth that no painter would ever venture upon, even could he detect it?\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0040.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.4958503, 'word': 'Dag', 'start': 17, 'end': 20}, {'entity_group': 'ORG', 'score': 0.29706737, 'word': '##uerreotyp', 'start': 20, 'end': 29}, {'entity_group': 'PER', 'score': 0.4984597, 'word': '##ist', 'start': 29, 'end': 32}]\n",
      "ner tagged text Oh, rejoined the B-MISC Dag E-MISCuerreotypist, because like an old lady's cup of tea, it is water bewitched.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Oh, rejoined the B-MISC Dag E-MISCuerreotypist, because like an old lady's cup of tea, it is water bewitched.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0030.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.5806635, 'word': 'The', 'start': 0, 'end': 3}]\n",
      "ner tagged text B-MISC The E-MISC sun as you see, tells quite another story and will not be coaxed out of it after half a dozen patient attempts on my part.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC The E-MISC sun as you see, tells quite another story and will not be coaxed out of it after half a dozen patient attempts on my part.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0003.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.77036273, 'word': 'Summer', 'start': 0, 'end': 6}]\n",
      "ner tagged text B-MISC Summer E-MISC squashes almost in their golden blossom, cucumbers, now evincing a tendency to spread away from the main stock and ramble far and wide, two or three rows of string beans, and as many more that were about to festoon themselves on poles, tomatoes, occupying a site so sheltered and sunny that the plants were already gigantic and promised an early and abundant harvest.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-MISC Summer E-MISC squashes almost in their golden blossom, cucumbers, now evincing a tendency to spread away from the main stock and ramble far and wide, two or three rows of string beans, and as many more that were about to festoon themselves on poles, tomatoes, occupying a site so sheltered and sunny that the plants were already gigantic and promised an early and abundant harvest.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0019.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99926156, 'word': 'Phoebe Pyncheon', 'start': 11, 'end': 26}]\n",
      "ner tagged text My name is B-PER Phoebe Pyncheon E-PER, said the girl with a manner of some reserve, for she was aware that her new acquaintance could be no other than the daguerreotypist of whose lawless propensities, the old maid had given her a disagreeable idea.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription My name is B-PER Phoebe Pyncheon E-PER, said the girl with a manner of some reserve, for she was aware that her new acquaintance could be no other than the daguerreotypist of whose lawless propensities, the old maid had given her a disagreeable idea.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0038.flac\n",
      "[]\n",
      "ner tagged text So we will be fellow laborers somewhat on the community system.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription So we will be fellow laborers somewhat on the community system.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0002.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.93343234, 'word': 'antique', 'start': 33, 'end': 40}]\n",
      "ner tagged text There were also a few species of B-MISC antique E-MISC and hereditary flowers in no very flourishing condition, but scrupulously weeded as if some person either out of love or curiosity had been anxious to bring them to such perfection as they were capable of attaining.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription There were also a few species of B-MISC antique E-MISC and hereditary flowers in no very flourishing condition, but scrupulously weeded as if some person either out of love or curiosity had been anxious to bring them to such perfection as they were capable of attaining.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0000.flac\n",
      "[]\n",
      "ner tagged text The enclosure had formerly been very extensive, but was now contracted within small, compass, and hemmed about partly by high wooden fences, and partly by the outbuildings of houses that stood on another street.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription The enclosure had formerly been very extensive, but was now contracted within small, compass, and hemmed about partly by high wooden fences, and partly by the outbuildings of houses that stood on another street.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0008.flac\n",
      "[]\n",
      "ner tagged text It was evident that the race had degenerated like many a noble race, besides, in consequence of too strict a watchfulness to keep it pure.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription It was evident that the race had degenerated like many a noble race, besides, in consequence of too strict a watchfulness to keep it pure.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0011.flac\n",
      "[{'entity_group': 'PER', 'score': 0.83086205, 'word': 'Hepzibah', 'start': 137, 'end': 145}]\n",
      "ner tagged text The distinguishing mark of the hens was a crest of lamentably scanty growth in these latter days, but so oddly and wickedly analogous to B-PER Hepzibah E-PER's turban that phoebe to the poignant distress of her conscience, but inevitably was led to fancy a general resemblance betwixt these forlorn bipeds and her respectable relative.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription The distinguishing mark of the hens was a crest of lamentably scanty growth in these latter days, but so oddly and wickedly analogous to B-PER Hepzibah E-PER's turban that phoebe to the poignant distress of her conscience, but inevitably was led to fancy a general resemblance betwixt these forlorn bipeds and her respectable relative.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0048.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99685246, 'word': 'Phoebe', 'start': 66, 'end': 72}]\n",
      "ner tagged text While thus dismissing her, the maiden, lady stept forward, kissed B-PER Phoebe E-PER and pressed her to her heart, which beat against the girl's bosom with a strong high and tumultuous swell.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription While thus dismissing her, the maiden, lady stept forward, kissed B-PER Phoebe E-PER and pressed her to her heart, which beat against the girl's bosom with a strong high and tumultuous swell.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0022.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9738836, 'word': 'Phoebe', 'start': 51, 'end': 57}]\n",
      "ner tagged text If you would permit me, said the artist looking at B-PER Phoebe E-PER, I should like to try whether the daguerreotype can bring out disagreeable traits on a perfectly amiable face.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription If you would permit me, said the artist looking at B-PER Phoebe E-PER, I should like to try whether the daguerreotype can bring out disagreeable traits on a perfectly amiable face.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0042.flac\n",
      "[]\n",
      "ner tagged text But put it on the table in the corner of the passage.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription But put it on the table in the corner of the passage.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0027.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.39029467, 'word': 'Dag', 'start': 15, 'end': 18}, {'entity_group': 'LOC', 'score': 0.99365646, 'word': 'Morocco', 'start': 44, 'end': 51}]\n",
      "ner tagged text He exhibited a B-MISC Dag E-MISCuerreotype miniature in a B-LOC Morocco E-LOC case.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He exhibited a B-MISC Dag E-MISCuerreotype miniature in a B-LOC Morocco E-LOC case.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0037.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9592874, 'word': 'Hepzibah', 'start': 36, 'end': 44}]\n",
      "ner tagged text Since you are a friend of my cousin B-PER Hepzibah E-PER's, you should ask her to show you the picture.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Since you are a friend of my cousin B-PER Hepzibah E-PER's, you should ask her to show you the picture.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0044.flac\n",
      "[]\n",
      "ner tagged text How wonderfully responsive to every emotion of the human soul.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription How wonderfully responsive to every emotion of the human soul.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0014.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99554837, 'word': 'Phoebe', 'start': 37, 'end': 43}]\n",
      "ner tagged text He held a hoe in his hand, and while B-PER Phoebe E-PER was gone in quest of the crumbs had begun to busy himself with drawing up fresh earth about the roots of the tomatoes.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription He held a hoe in his hand, and while B-PER Phoebe E-PER was gone in quest of the crumbs had begun to busy himself with drawing up fresh earth about the roots of the tomatoes.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0024.flac\n",
      "[{'entity_group': 'PER', 'score': 0.4149529, 'word': 'he', 'start': 32, 'end': 34}]\n",
      "ner tagged text TB-PER he E-PERre is a wonderful insight in B-PER he E-PERaven's broad and simple sunshine.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription TB-PER he E-PERre is a wonderful insight in B-PER he E-PERaven's broad and simple sunshine.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0033.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9987087, 'word': 'Phoebe', 'start': 48, 'end': 54}]\n",
      "ner tagged text Well, I don't wish to see it any more, observed B-PER Phoebe E-PER, turning away her eyes. It is certainly very like the old portrait.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Well, I don't wish to see it any more, observed B-PER Phoebe E-PER, turning away her eyes. It is certainly very like the old portrait.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0020.flac\n",
      "[]\n",
      "ner tagged text I turn up the earth by way of pastime.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I turn up the earth by way of pastime.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0035.flac\n",
      "[{'entity_group': 'PER', 'score': 0.939424, 'word': 'Holgrave', 'start': 43, 'end': 51}, {'entity_group': 'PER', 'score': 0.9945168, 'word': 'Phoebe', 'start': 85, 'end': 91}]\n",
      "ner tagged text Is there nothing wild in the eye continued B-PER Holgrave E-PER so earnestly that it embarrassed B-PER Phoebe E-PER, as did also the quiet freedom with which he presumed on their so recent acquaintance?\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Is there nothing wild in the eye continued B-PER Holgrave E-PER so earnestly that it embarrassed B-PER Phoebe E-PER, as did also the quiet freedom with which he presumed on their so recent acquaintance?\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0032.flac\n",
      "[]\n",
      "ner tagged text And yet, if you could only see the benign smile of the original.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription And yet, if you could only see the benign smile of the original.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0001.flac\n",
      "[]\n",
      "ner tagged text The white double rosebush had evidently been propped up anew against the house since the commencement of the season and a pear tree and three damson, trees, which, except a row of currant bushes, constituted the only varieties of fruit bore marks of the recent amputation of several superfluous or defective limbs.\n",
      "Emotion Labels []\n",
      "tagged transcription The white double rosebush had evidently been propped up anew against the house since the commencement of the season and a pear tree and three damson, trees, which, except a row of currant bushes, constituted the only varieties of fruit bore marks of the recent amputation of several superfluous or defective limbs.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0010.flac\n",
      "[]\n",
      "ner tagged text They kept themselves alive unquestionably and laid now and then an egg and hatched a chicken, not for any pleasure of their own, but that the world might not absolutely lose what had once been so admirable a breed of fowls.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription They kept themselves alive unquestionably and laid now and then an egg and hatched a chicken, not for any pleasure of their own, but that the world might not absolutely lose what had once been so admirable a breed of fowls.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0041.flac\n",
      "[]\n",
      "ner tagged text She was indistinctly aware, however, that the gaunt figure of the old gentlewoman was sitting in one of the straight backed chairs a little withdrawn from the window, the faint gleam of which showed the blanched paleness of her cheek turned sideways towards a corner.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription She was indistinctly aware, however, that the gaunt figure of the old gentlewoman was sitting in one of the straight backed chairs a little withdrawn from the window, the faint gleam of which showed the blanched paleness of her cheek turned sideways towards a corner.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0049.flac\n",
      "[]\n",
      "ner tagged text At some uncertain period in the depths of night, and as it were through the thin veil of a dream, she was conscious of a footstep mounting the stairs heavily, but not with force and decision.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription At some uncertain period in the depths of night, and as it were through the thin veil of a dream, she was conscious of a footstep mounting the stairs heavily, but not with force and decision.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0005.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.55185306, 'word': 'Bees', 'start': 0, 'end': 4}]\n",
      "ner tagged text B-MISC Bees E-MISC, too strange to say, had thought it worth their while to come hither possibly from the range of hives beside some farm house miles away.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription B-MISC Bees E-MISC, too strange to say, had thought it worth their while to come hither possibly from the range of hives beside some farm house miles away.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0015.flac\n",
      "[]\n",
      "ner tagged text They have known me much longer, but never honor me with any familiarity. though hardly a day passes without my bringing them food.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription They have known me much longer, but never honor me with any familiarity. though hardly a day passes without my bringing them food.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0021.flac\n",
      "[]\n",
      "ner tagged text It is like a bandage over one's eyes to come into it.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription It is like a bandage over one's eyes to come into it.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0018.flac\n",
      "[{'entity_group': 'PER', 'score': 0.8130948, 'word': 'Hepzibah', 'start': 37, 'end': 45}]\n",
      "ner tagged text I prefer to think, and so would miss B-PER Hepzibah E-PER that they recognize the family tone, for you are a pyncheon.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I prefer to think, and so would miss B-PER Hepzibah E-PER that they recognize the family tone, for you are a pyncheon.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0016.flac\n",
      "[{'entity_group': 'PER', 'score': 0.87034905, 'word': 'Hepzibah', 'start': 5, 'end': 13}]\n",
      "ner tagged text Miss B-PER Hepzibah E-PER, I suppose will interweave the fact with her other traditions and set it down that the fowls know you to be a pyncheon.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Miss B-PER Hepzibah E-PER, I suppose will interweave the fact with her other traditions and set it down that the fowls know you to be a pyncheon.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0029.flac\n",
      "[]\n",
      "ner tagged text I can assure you that this is a modern face and one which you will very probably meet.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription I can assure you that this is a modern face and one which you will very probably meet.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0046.flac\n",
      "[{'entity_group': 'PER', 'score': 0.5309571, 'word': 'Pr', 'start': 0, 'end': 2}]\n",
      "ner tagged text B-PER Pr E-PERay go to bed for I am sure you must need rest.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription B-PER Pr E-PERay go to bed for I am sure you must need rest.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0009.flac\n",
      "[]\n",
      "ner tagged text These feathered people had existed too long in their distinct variety, a fact of which the present representatives, judging by their lugubrious deportment seemed to be aware.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription These feathered people had existed too long in their distinct variety, a fact of which the present representatives, judging by their lugubrious deportment seemed to be aware.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0031.flac\n",
      "[]\n",
      "ner tagged text Here we have the man, sly, subtle, hard, imperious, and withal cold as ice, look at that eye.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Here we have the man, sly, subtle, hard, imperious, and withal cold as ice, look at that eye.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0045.flac\n",
      "[]\n",
      "ner tagged text Fewer words than before, but with the same mysterious music in them.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Fewer words than before, but with the same mysterious music in them.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0036.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99635303, 'word': 'Phoebe', 'start': 21, 'end': 27}]\n",
      "ner tagged text It is nonsense, said B-PER Phoebe E-PER a little impatiently for us to talk about a picture which you have never seen.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription It is nonsense, said B-PER Phoebe E-PER a little impatiently for us to talk about a picture which you have never seen.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0017.flac\n",
      "[]\n",
      "ner tagged text Ah, but these hens answered the young man. these hens of aristocratic lineage would scorn to understand the vulgar language of a barn yard fowl.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Ah, but these hens answered the young man. these hens of aristocratic lineage would scorn to understand the vulgar language of a barn yard fowl.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0023.flac\n",
      "[]\n",
      "ner tagged text Most of my likenesses do look unamiable, but the very sufficient reason I fancy is because the originals are so.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Most of my likenesses do look unamiable, but the very sufficient reason I fancy is because the originals are so.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0043.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.86375046, 'word': 'human', 'start': 26, 'end': 31}]\n",
      "ner tagged text What an instrument is the B-MISC human E-MISC voice.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription What an instrument is the B-MISC human E-MISC voice.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0039.flac\n",
      "[]\n",
      "ner tagged text She did not altogether like him.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription She did not altogether like him.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0034.flac\n",
      "[]\n",
      "ner tagged text If the original is still in the world, I think he might defy the sun to make him look stern and hard.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription If the original is still in the world, I think he might defy the sun to make him look stern and hard.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0026.flac\n",
      "[]\n",
      "ner tagged text Yet the original wears to common eyes, a very different expression.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Yet the original wears to common eyes, a very different expression.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/2086/149220/2086-149220-0006.flac\n",
      "[]\n",
      "ner tagged text This was a fountain set round with a rim of old mossy stones, and paved in its bed with what appeared to be a sort of mosaic work of variously colored pebbles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"long\" } tokens { name: \"ago\" } tokens { name: \"there\" } tokens { name: \"lived\" } tokens { name: \"a\" } tokens { name: \"merchant\" } tokens { name: \"who\" } tokens { name: \"had\" } tokens { name: \"three\" } tokens { name: \"daughters\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription This was a fountain set round with a rim of old mossy stones, and paved in its bed with what appeared to be a sort of mosaic work of variously colored pebbles.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0021.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0025.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0024.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0022.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0023.flac']\n",
      "[NeMo I 2023-11-12 08:28:05 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:05 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.08batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"every\" } tokens { name: \"year\" } tokens { name: \"at\" } tokens { name: \"a\" } tokens { name: \"certain\" } tokens { name: \"day\" } tokens { name: \"of\" } tokens { name: \"a\" } tokens { name: \"certain\" } tokens { name: \"month\" } tokens { name: \"he\" } tokens { name: \"went\" } tokens { name: \"away\" } tokens { name: \"to\" } tokens { name: \"a\" } tokens { name: \"distant\" } tokens { name: \"city\" } tokens { name: \"to\" } tokens { name: \"collect\" } tokens { name: \"money\" } tokens { name: \"on\" } tokens { name: \"an\" } tokens { name: \"account\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:05 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:05 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:28:05 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.39batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"how\" } tokens { name: \"do\" } tokens { name: \"you\" } tokens { name: \"know\" } tokens { name: \"asked\" } tokens { name: \"their\" } tokens { name: \"father\" } tokens { name: \"i\" } tokens { name: \"am\" } tokens { name: \"older\" } tokens { name: \"and\" } tokens { name: \"wiser\" } tokens { name: \"than\" } tokens { name: \"you\" } tokens { name: \"are\" } tokens { name: \"and\" } tokens { name: \"i\" } tokens { name: \"know\" } tokens { name: \"that\" } tokens { name: \"there\" } tokens { name: \"are\" } tokens { name: \"many\" } tokens { name: \"evils\" } tokens { name: \"which\" } tokens { name: \"might\" } tokens { name: \"come\" } tokens { name: \"upon\" } tokens { name: \"you\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_infer_dataset:127] Max length: 32\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:406] Min: 30 |                  Max: 30 |                  Mean: 30.0 |                  Median: 30.0\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:412] 75 percentile: 30.00\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:413] 99 percentile: 30.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"when\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"evening\" } tokens { name: \"he\" } tokens { name: \"led\" } tokens { name: \"his\" } tokens { name: \"band\" } tokens { name: \"into\" } tokens { name: \"a\" } tokens { name: \"nearby\" } tokens { name: \"street\" } tokens { name: \"and\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"disguise\" } tokens { name: \"approached\" } tokens { name: \"the\" } tokens { name: \"merchant's\" } tokens { name: \"house\" } tokens { name: \"he\" } tokens { name: \"knocked\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"door\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_infer_dataset:127] Max length: 29\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:406] Min: 27 |                  Max: 27 |                  Mean: 27.0 |                  Median: 27.0\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:412] 75 percentile: 27.00\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:413] 99 percentile: 27.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.24batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"have\" } tokens { name: \"pity\" } tokens { name: \"upon\" } tokens { name: \"a\" } tokens { name: \"poor\" } tokens { name: \"unfortunate\" } tokens { name: \"one\" } tokens { name: \"he\" } tokens { name: \"called\" } tokens { name: \"out\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.59batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"let\" } tokens { name: \"me\" } tokens { name: \"enter\" } tokens { name: \"i\" } tokens { name: \"pray\" } tokens { name: \"you\" } tokens { name: \"to\" } tokens { name: \"pass\" } tokens { name: \"the\" } tokens { name: \"night\" } tokens { name: \"under\" } tokens { name: \"your\" } tokens { name: \"roof\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.24batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it's\" } tokens { name: \"surely\" } tokens { name: \"a\" } tokens { name: \"terrible\" } tokens { name: \"storm\" } tokens { name: \"outside\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"merchant's\" } tokens { name: \"eldest\" } tokens { name: \"daughter\" } tokens { name: \"as\" } tokens { name: \"the\" } tokens { name: \"wind\" } tokens { name: \"rattled\" } tokens { name: \"the\" } tokens { name: \"tiles\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"roof\" } tokens { name: \"and\" } tokens { name: \"the\" } tokens { name: \"rain\" } tokens { name: \"beat\" } tokens { name: \"in\" } tokens { name: \"torrents\" } tokens { name: \"against\" } tokens { name: \"the\" } tokens { name: \"doors\" } tokens { name: \"and\" } tokens { name: \"windows\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:06 punctuation_capitalization_infer_dataset:127] Max length: 38\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:406] Min: 36 |                  Max: 36 |                  Mean: 36.0 |                  Median: 36.0\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:412] 75 percentile: 36.00\n",
      "[NeMo I 2023-11-12 08:28:06 data_preprocessing:413] 99 percentile: 36.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.31batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"is\" } tokens { name: \"old\" } tokens { name: \"as\" } tokens { name: \"well\" } tokens { name: \"as\" } tokens { name: \"poor\" } tokens { name: \"she\" } tokens { name: \"said\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.21batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"if\" } tokens { name: \"we\" } tokens { name: \"decide\" } tokens { name: \"to\" } tokens { name: \"show\" } tokens { name: \"mercy\" } tokens { name: \"to\" } tokens { name: \"this\" } tokens { name: \"poor\" } tokens { name: \"beggar\" } tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"not\" } tokens { name: \"for\" } tokens { name: \"you\" } tokens { name: \"to\" } tokens { name: \"oppose\" } tokens { name: \"it\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.14batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"bui\" } tokens { name: \"we\" } tokens { name: \"should\" } tokens { name: \"not\" } tokens { name: \"forget\" } tokens { name: \"our\" } tokens { name: \"promise\" } tokens { name: \"to\" } tokens { name: \"our\" } tokens { name: \"father\" } tokens { name: \"cried\" } tokens { name: \"the\" } tokens { name: \"youngest\" } tokens { name: \"daughter\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.08batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"however\" } tokens { name: \"in\" } tokens { name: \"spite\" } tokens { name: \"of\" } tokens { name: \"all\" } tokens { name: \"she\" } tokens { name: \"could\" } tokens { name: \"say\" } tokens { name: \"the\" } tokens { name: \"elder\" } tokens { name: \"sisters\" } tokens { name: \"opened\" } tokens { name: \"the\" } tokens { name: \"door\" } tokens { name: \"and\" } tokens { name: \"admitted\" } tokens { name: \"the\" } tokens { name: \"beggar\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"a\" } tokens { name: \"fearful\" } tokens { name: \"night\" } tokens { name: \"to\" } tokens { name: \"send\" } tokens { name: \"away\" } tokens { name: \"a\" } tokens { name: \"beggar\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"eldest\" } tokens { name: \"sister\" } tokens { name: \"while\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"eating\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:07 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:07 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.20batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"while\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"talking\" } tokens { name: \"the\" } tokens { name: \"beggar\" } tokens { name: \"had\" } tokens { name: \"taken\" } tokens { name: \"the\" } tokens { name: \"apples\" } tokens { name: \"which\" } tokens { name: \"the\" } tokens { name: \"girls\" } tokens { name: \"were\" } tokens { name: \"to\" } tokens { name: \"eat\" } tokens { name: \"for\" } tokens { name: \"dessert\" } tokens { name: \"and\" } tokens { name: \"had\" } tokens { name: \"sprinkled\" } tokens { name: \"a\" } tokens { name: \"sleeping\" } tokens { name: \"powder\" } tokens { name: \"over\" } tokens { name: \"them\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_infer_dataset:127] Max length: 31\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:406] Min: 29 |                  Max: 29 |                  Mean: 29.0 |                  Median: 29.0\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:412] 75 percentile: 29.00\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:413] 99 percentile: 29.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.40batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"two\" } tokens { name: \"eldest\" } tokens { name: \"ate\" } tokens { name: \"their\" } tokens { name: \"apples\" } tokens { name: \"but\" } tokens { name: \"the\" } tokens { name: \"youngest\" } tokens { name: \"could\" } tokens { name: \"not\" } tokens { name: \"eat\" } tokens { name: \"that\" } tokens { name: \"night\" } tokens { name: \"she\" } tokens { name: \"threw\" } tokens { name: \"the\" } tokens { name: \"apple\" } tokens { name: \"away\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.08batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"she\" } tokens { name: \"did\" } tokens { name: \"not\" } tokens { name: \"stir\" } tokens { name: \"and\" } tokens { name: \"he\" } tokens { name: \"knew\" } tokens { name: \"that\" } tokens { name: \"the\" } tokens { name: \"sleeping\" } tokens { name: \"powder\" } tokens { name: \"had\" } tokens { name: \"thoroughly\" } tokens { name: \"done\" } tokens { name: \"its\" } tokens { name: \"work\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.67batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"she\" } tokens { name: \"heard\" } tokens { name: \"him\" } tokens { name: \"go\" } tokens { name: \"down\" } tokens { name: \"the\" } tokens { name: \"stairway\" } tokens { name: \"and\" } tokens { name: \"unbolt\" } tokens { name: \"the\" } tokens { name: \"heavy\" } tokens { name: \"doors\" } tokens { name: \"which\" } tokens { name: \"led\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"store\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.70batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"the\" } tokens { name: \"youngest\" } tokens { name: \"one\" } tokens { name: \"who\" } tokens { name: \"deceived\" } tokens { name: \"me\" } tokens { name: \"cried\" } tokens { name: \"the\" } tokens { name: \"robber\" } tokens { name: \"chieftain\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:08 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:28:08 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.19batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"perhaps\" } tokens { name: \"you\" } tokens { name: \"can\" } tokens { name: \"outwit\" } tokens { name: \"her\" } tokens { name: \"yet\" } tokens { name: \"cried\" } tokens { name: \"another\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.35batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"merchant's\" } tokens { name: \"daughter\" } tokens { name: \"at\" } tokens { name: \"first\" } tokens { name: \"did\" } tokens { name: \"not\" } tokens { name: \"answer\" } tokens { name: \"but\" } tokens { name: \"as\" } tokens { name: \"he\" } tokens { name: \"kept\" } tokens { name: \"on\" } tokens { name: \"calling\" } tokens { name: \"to\" } tokens { name: \"her\" } tokens { name: \"she\" } tokens { name: \"finally\" } tokens { name: \"asked\" } tokens { name: \"him\" } tokens { name: \"what\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"that\" } tokens { name: \"he\" } tokens { name: \"wanted\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"promise\" } tokens { name: \"you\" } tokens { name: \"i\" } tokens { name: \"will\" } tokens { name: \"do\" } tokens { name: \"you\" } tokens { name: \"no\" } tokens { name: \"harm\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 11\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.36batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"you\" } tokens { name: \"shall\" } tokens { name: \"not\" } tokens { name: \"come\" } tokens { name: \"into\" } tokens { name: \"my\" } tokens { name: \"father's\" } tokens { name: \"house\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.51batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"pass\" } tokens { name: \"the\" } tokens { name: \"charm\" } tokens { name: \"out\" } tokens { name: \"to\" } tokens { name: \"me\" } tokens { name: \"then\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"robber\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.07batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"when\" } tokens { name: \"she\" } tokens { name: \"returned\" } tokens { name: \"his\" } tokens { name: \"hand\" } tokens { name: \"was\" } tokens { name: \"sticking\" } tokens { name: \"through\" } tokens { name: \"the\" } tokens { name: \"hole\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"door\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"cries\" } tokens { name: \"and\" } tokens { name: \"curses\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"robbers\" } tokens { name: \"filled\" } tokens { name: \"the\" } tokens { name: \"air\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:09 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:09 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"tried\" } tokens { name: \"in\" } tokens { name: \"vain\" } tokens { name: \"to\" } tokens { name: \"break\" } tokens { name: \"down\" } tokens { name: \"the\" } tokens { name: \"great\" } tokens { name: \"doors\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:10 punctuation_capitalization_infer_dataset:127] Max length: 12\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.06batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"all\" } tokens { name: \"my\" } tokens { name: \"worries\" } tokens { name: \"about\" } tokens { name: \"you\" } tokens { name: \"were\" } tokens { name: \"foolish\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:10 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:10 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:28:10 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0019.flac\n",
      "[]\n",
      "ner tagged text I promise you I will do you no harm.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription I promise you I will do you no harm.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0004.flac\n",
      "[]\n",
      "ner tagged text Have pity upon a poor unfortunate one he called out.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription Have pity upon a poor unfortunate one he called out.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0015.flac\n",
      "[]\n",
      "ner tagged text Then she heard him go down the stairway and unbolt the heavy doors which led into the store.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Then she heard him go down the stairway and unbolt the heavy doors which led into the store.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0016.flac\n",
      "[]\n",
      "ner tagged text It was the youngest one who deceived me, cried the robber chieftain.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription It was the youngest one who deceived me, cried the robber chieftain.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0000.flac\n",
      "[]\n",
      "ner tagged text Long ago there lived a merchant who had three daughters.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription Long ago there lived a merchant who had three daughters.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0008.flac\n",
      "[]\n",
      "ner tagged text If we decide to show mercy to this poor beggar, it is not for you to oppose it.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription If we decide to show mercy to this poor beggar, it is not for you to oppose it.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0017.flac\n",
      "[]\n",
      "ner tagged text Perhaps you can outwit her yet cried another.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription Perhaps you can outwit her yet cried another.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0021.flac\n",
      "[]\n",
      "ner tagged text Pass the charm out to me, then said the robber.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Pass the charm out to me, then said the robber.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0007.flac\n",
      "[]\n",
      "ner tagged text He is old as well as poor, she said.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He is old as well as poor, she said.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0025.flac\n",
      "[]\n",
      "ner tagged text All my worries about you were foolish.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription All my worries about you were foolish.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0020.flac\n",
      "[]\n",
      "ner tagged text You shall not come into my father's house.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription You shall not come into my father's house.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0002.flac\n",
      "[]\n",
      "ner tagged text How do you know? asked their father? I am older and wiser than you are, and I know that there are many evils which might come upon you.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription How do you know? asked their father? I am older and wiser than you are, and I know that there are many evils which might come upon you.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0001.flac\n",
      "[]\n",
      "ner tagged text Every year at a certain day of a certain month, he went away to a distant city to collect money on an account.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription Every year at a certain day of a certain month, he went away to a distant city to collect money on an account.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0005.flac\n",
      "[]\n",
      "ner tagged text Let me enter. I pray you to pass the night under your roof.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Let me enter. I pray you to pass the night under your roof.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0006.flac\n",
      "[]\n",
      "ner tagged text It's surely a terrible storm outside, said the merchant's eldest daughter, as the wind rattled the tiles of the roof and the rain beat in torrents against the doors and windows.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription It's surely a terrible storm outside, said the merchant's eldest daughter, as the wind rattled the tiles of the roof and the rain beat in torrents against the doors and windows.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0013.flac\n",
      "[]\n",
      "ner tagged text The two eldest ate their apples, but the youngest could not eat that night. she threw the apple away.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription The two eldest ate their apples, but the youngest could not eat that night. she threw the apple away.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0024.flac\n",
      "[]\n",
      "ner tagged text They tried in vain to break down the great doors.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription They tried in vain to break down the great doors.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0014.flac\n",
      "[]\n",
      "ner tagged text She did not stir and he knew that the sleeping powder had thoroughly done its work.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription She did not stir and he knew that the sleeping powder had thoroughly done its work.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0012.flac\n",
      "[]\n",
      "ner tagged text While they were talking, the beggar had taken the apples which the girls were to eat for dessert, and had sprinkled a sleeping powder over them.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription While they were talking, the beggar had taken the apples which the girls were to eat for dessert, and had sprinkled a sleeping powder over them.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0010.flac\n",
      "[]\n",
      "ner tagged text However, in spite of all, she could say, the elder sisters opened the door and admitted the beggar.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription However, in spite of all, she could say, the elder sisters opened the door and admitted the beggar.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0009.flac\n",
      "[{'entity_group': 'PER', 'score': 0.95553327, 'word': 'Bui', 'start': 0, 'end': 3}]\n",
      "ner tagged text B-PER Bui E-PER, we should not forget our promise to our father, cried the youngest daughter.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-PER Bui E-PER, we should not forget our promise to our father, cried the youngest daughter.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0011.flac\n",
      "[]\n",
      "ner tagged text It is a fearful night to send away a beggar said the eldest sister while they were eating.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription It is a fearful night to send away a beggar said the eldest sister while they were eating.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0022.flac\n",
      "[]\n",
      "ner tagged text When she returned, his hand was sticking through the hole in the door.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription When she returned, his hand was sticking through the hole in the door.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0018.flac\n",
      "[]\n",
      "ner tagged text The merchant's daughter at first did not answer, but as he kept on calling to her, she finally asked him what it was that he wanted.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription The merchant's daughter at first did not answer, but as he kept on calling to her, she finally asked him what it was that he wanted.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0003.flac\n",
      "[]\n",
      "ner tagged text When it was evening, he led his band into a nearby street, and in his disguise approached the merchant's house. he knocked at the door.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription When it was evening, he led his band into a nearby street, and in his disguise approached the merchant's house. he knocked at the door.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110124/7976-110124-0023.flac\n",
      "[]\n",
      "ner tagged text The cries and curses of the robbers filled the air.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"grant\" } tokens { name: \"was\" } tokens { name: \"only\" } tokens { name: \"a\" } tokens { name: \"few\" } tokens { name: \"miles\" } tokens { name: \"away\" } tokens { name: \"but\" } tokens { name: \"although\" } tokens { name: \"commander\" } tokens { name: \"in\" } tokens { name: \"chief\" } tokens { name: \"he\" } tokens { name: \"knew\" } tokens { name: \"nothing\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"hardest\" } tokens { name: \"fought\" } tokens { name: \"battle\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"civil\" } tokens { name: \"war\" } tokens { name: \"until\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"over\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription The cries and curses of the robbers filled the air.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575.trans.txt', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0025.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0026.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0022.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0027.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0023.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0028.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0029.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0024.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0021.flac']\n",
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.77batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"my\" } tokens { name: \"own\" } tokens { name: \"regiment\" } tokens { name: \"was\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"advance\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.18batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"our\" } tokens { name: \"brigade\" } tokens { name: \"was\" } tokens { name: \"fearfully\" } tokens { name: \"outnumbered\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_infer_dataset:127] Max length: 8\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:406] Min: 6 |                  Max: 6 |                  Mean: 6.0 |                  Median: 6.0\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:412] 75 percentile: 6.00\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:413] 99 percentile: 6.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.78batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"there\" } tokens { name: \"were\" } tokens { name: \"no\" } tokens { name: \"breastworks\" } tokens { name: \"yet\" } tokens { name: \"that\" } tokens { name: \"one\" } tokens { name: \"little\" } tokens { name: \"brigade\" } tokens { name: \"of\" } tokens { name: \"hamilton's\" } tokens { name: \"division\" } tokens { name: \"stood\" } tokens { name: \"there\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"open\" } tokens { name: \"and\" } tokens { name: \"repulsed\" } tokens { name: \"assault\" } tokens { name: \"after\" } tokens { name: \"assault\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:26 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:28:26 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.07batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"not\" } tokens { name: \"balaklava\" } tokens { name: \"nor\" } tokens { name: \"the\" } tokens { name: \"alma\" } tokens { name: \"saw\" } tokens { name: \"such\" } tokens { name: \"fighting\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"duel\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"death\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.50batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"no\" } tokens { name: \"battery\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"whole\" } tokens { name: \"four\" } tokens { name: \"years\" } tokens { name: \"war\" } tokens { name: \"lost\" } tokens { name: \"so\" } tokens { name: \"many\" } tokens { name: \"men\" } tokens { name: \"in\" } tokens { name: \"so\" } tokens { name: \"short\" } tokens { name: \"a\" } tokens { name: \"time\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_infer_dataset:127] Max length: 19\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:406] Min: 17 |                  Max: 17 |                  Mean: 17.0 |                  Median: 17.0\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:412] 75 percentile: 17.00\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:413] 99 percentile: 17.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.38batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"one\" } tokens { name: \"daring\" } tokens { name: \"rebel\" } tokens { name: \"was\" } tokens { name: \"shot\" } tokens { name: \"down\" } tokens { name: \"and\" } tokens { name: \"bayoneted\" } tokens { name: \"clear\" } tokens { name: \"behind\" } tokens { name: \"the\" } tokens { name: \"line\" } tokens { name: \"of\" } tokens { name: \"company\" } tokens { name: \"b\" } tokens { name: \"where\" } tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"broken\" } tokens { name: \"through\" } tokens { name: \"to\" } tokens { name: \"seize\" } tokens { name: \"the\" } tokens { name: \"flag\" } tokens { name: \"of\" } tokens { name: \"my\" } tokens { name: \"regiment\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_infer_dataset:127] Max length: 31\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:406] Min: 29 |                  Max: 29 |                  Mean: 29.0 |                  Median: 29.0\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:412] 75 percentile: 29.00\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:413] 99 percentile: 29.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.84batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"that\" } tokens { name: \"night\" } tokens { name: \"the\" } tokens { name: \"enemy\" } tokens { name: \"slipped\" } tokens { name: \"away\" } tokens { name: \"leaving\" } tokens { name: \"hundreds\" } tokens { name: \"and\" } tokens { name: \"hundreds\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"dead\" } tokens { name: \"and\" } tokens { name: \"wounded\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"field\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.86batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"few\" } tokens { name: \"lanterns\" } tokens { name: \"our\" } tokens { name: \"men\" } tokens { name: \"then\" } tokens { name: \"went\" } tokens { name: \"about\" } tokens { name: \"and\" } tokens { name: \"tried\" } tokens { name: \"to\" } tokens { name: \"gather\" } tokens { name: \"up\" } tokens { name: \"the\" } tokens { name: \"wounded\" } tokens { name: \"the\" } tokens { name: \"dead\" } tokens { name: \"were\" } tokens { name: \"left\" } tokens { name: \"till\" } tokens { name: \"morning\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_infer_dataset:127] Max length: 24\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:406] Min: 22 |                  Max: 22 |                  Mean: 22.0 |                  Median: 22.0\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:412] 75 percentile: 22.00\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:413] 99 percentile: 22.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.34batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"not\" } tokens { name: \"a\" } tokens { name: \"question\" } tokens { name: \"who\" } tokens { name: \"was\" } tokens { name: \"dead\" } tokens { name: \"or\" } tokens { name: \"wounded\" } tokens { name: \"but\" } tokens { name: \"who\" } tokens { name: \"was\" } tokens { name: \"not\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:27 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:28:27 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.79batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"fifteen\" } tokens { name: \"officers\" } tokens { name: \"of\" } tokens { name: \"our\" } tokens { name: \"little\" } tokens { name: \"half\" } tokens { name: \"regiment\" } tokens { name: \"were\" } tokens { name: \"dead\" } tokens { name: \"or\" } tokens { name: \"wounded\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.54batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"remained\" } tokens { name: \"awake\" } tokens { name: \"all\" } tokens { name: \"night\" } tokens { name: \"talking\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"comrade\" } tokens { name: \"who\" } tokens { name: \"shared\" } tokens { name: \"my\" } tokens { name: \"blanket\" } tokens { name: \"with\" } tokens { name: \"me\" } tokens { name: \"poor\" } tokens { name: \"jimmy\" } tokens { name: \"king\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.04batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"survived\" } tokens { name: \"the\" } tokens { name: \"war\" } tokens { name: \"only\" } tokens { name: \"to\" } tokens { name: \"be\" } tokens { name: \"murdered\" } tokens { name: \"later\" } tokens { name: \"on\" } tokens { name: \"a\" } tokens { name: \"plantation\" } tokens { name: \"in\" } tokens { name: \"mississippi\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_infer_dataset:127] Max length: 16\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.02batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"when\" } tokens { name: \"morning\" } tokens { name: \"came\" } tokens { name: \"the\" } tokens { name: \"firing\" } tokens { name: \"opened\" } tokens { name: \"and\" } tokens { name: \"for\" } tokens { name: \"all\" } tokens { name: \"that\" } tokens { name: \"day\" } tokens { name: \"the\" } tokens { name: \"battle\" } tokens { name: \"raged\" } tokens { name: \"fiercely\" } tokens { name: \"at\" } tokens { name: \"the\" } tokens { name: \"left\" } tokens { name: \"and\" } tokens { name: \"center\" } tokens { name: \"left\" } tokens { name: \"we\" } tokens { name: \"getting\" } tokens { name: \"the\" } tokens { name: \"worst\" } tokens { name: \"of\" } tokens { name: \"it\" } tokens { name: \"too\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:28 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:28:28 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.63batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"that\" } tokens { name: \"evening\" } tokens { name: \"an\" } tokens { name: \"order\" } tokens { name: \"came\" } tokens { name: \"for\" } tokens { name: \"us\" } tokens { name: \"hamilton's\" } tokens { name: \"division\" } tokens { name: \"to\" } tokens { name: \"assault\" } tokens { name: \"the\" } tokens { name: \"enemy's\" } tokens { name: \"left\" } tokens { name: \"flank\" } tokens { name: \"at\" } tokens { name: \"midnight\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 23\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 21 |                  Max: 21 |                  Mean: 21.0 |                  Median: 21.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 21.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 21.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.76batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"under\" } tokens { name: \"the\" } tokens { name: \"same\" } tokens { name: \"quiet\" } tokens { name: \"moonlight\" } tokens { name: \"and\" } tokens { name: \"only\" } tokens { name: \"six\" } tokens { name: \"hundred\" } tokens { name: \"yards\" } tokens { name: \"away\" } tokens { name: \"from\" } tokens { name: \"us\" } tokens { name: \"also\" } tokens { name: \"lay\" } tokens { name: \"the\" } tokens { name: \"victorious\" } tokens { name: \"rebel\" } tokens { name: \"army\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.59batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"once\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"night\" } tokens { name: \"i\" } tokens { name: \"slipped\" } tokens { name: \"away\" } tokens { name: \"from\" } tokens { name: \"the\" } tokens { name: \"bivouac\" } tokens { name: \"and\" } tokens { name: \"hurried\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"old\" } tokens { name: \"tishimingo\" } tokens { name: \"hotel\" } tokens { name: \"to\" } tokens { name: \"see\" } tokens { name: \"a\" } tokens { name: \"lieutenant\" } tokens { name: \"of\" } tokens { name: \"my\" } tokens { name: \"company\" } tokens { name: \"who\" } tokens { name: \"had\" } tokens { name: \"been\" } tokens { name: \"shot\" } tokens { name: \"through\" } tokens { name: \"the\" } tokens { name: \"breast\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 39\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 37 |                  Max: 37 |                  Mean: 37.0 |                  Median: 37.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 37.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 37.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.60batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"could\" } tokens { name: \"not\" } tokens { name: \"help\" } tokens { name: \"my\" } tokens { name: \"friend\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 8\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 6 |                  Max: 6 |                  Mean: 6.0 |                  Median: 6.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 6.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 6.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.66batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"go\" } tokens { name: \"back\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"regiment\" } tokens { name: \"he\" } tokens { name: \"said\" } tokens { name: \"smiling\" } tokens { name: \"all\" } tokens { name: \"will\" } tokens { name: \"be\" } tokens { name: \"needed\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.73batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"my\" } tokens { name: \"friend\" } tokens { name: \"with\" } tokens { name: \"many\" } tokens { name: \"others\" } tokens { name: \"was\" } tokens { name: \"being\" } tokens { name: \"carried\" } tokens { name: \"out\" } tokens { name: \"to\" } tokens { name: \"die\" } tokens { name: \"elsewhere\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"i\" } tokens { name: \"hastened\" } tokens { name: \"back\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"lines\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:29 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:28:29 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.70batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"cloud\" } tokens { name: \"of\" } tokens { name: \"rebels\" } tokens { name: \"we\" } tokens { name: \"had\" } tokens { name: \"seen\" } tokens { name: \"divided\" } tokens { name: \"itself\" } tokens { name: \"into\" } tokens { name: \"three\" } tokens { name: \"columns\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.79batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"a\" } tokens { name: \"perfect\" } tokens { name: \"blaze\" } tokens { name: \"of\" } tokens { name: \"close\" } tokens { name: \"range\" } tokens { name: \"musketry\" } tokens { name: \"too\" } tokens { name: \"mowed\" } tokens { name: \"them\" } tokens { name: \"down\" } tokens { name: \"like\" } tokens { name: \"grass\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.53batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"they\" } tokens { name: \"lay\" } tokens { name: \"in\" } tokens { name: \"heaps\" } tokens { name: \"of\" } tokens { name: \"dozens\" } tokens { name: \"even\" } tokens { name: \"close\" } tokens { name: \"up\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"works\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_infer_dataset:127] Max length: 15\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:406] Min: 13 |                  Max: 13 |                  Mean: 13.0 |                  Median: 13.0\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:412] 75 percentile: 13.00\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:413] 99 percentile: 13.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.43batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"that\" } tokens { name: \"night\" } tokens { name: \"i\" } tokens { name: \"stood\" } tokens { name: \"guard\" } tokens { name: \"under\" } tokens { name: \"an\" } tokens { name: \"oak\" } tokens { name: \"tree\" } tokens { name: \"on\" } tokens { name: \"the\" } tokens { name: \"battlefield\" } tokens { name: \"among\" } tokens { name: \"the\" } tokens { name: \"unburied\" } tokens { name: \"dead\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.03batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"indeed\" } tokens { name: \"we\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"rank\" } tokens { name: \"and\" } tokens { name: \"file\" } tokens { name: \"had\" } tokens { name: \"little\" } tokens { name: \"confidence\" } tokens { name: \"in\" } tokens { name: \"grant\" } tokens { name: \"in\" } tokens { name: \"those\" } tokens { name: \"days\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_infer_dataset:127] Max length: 17\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:406] Min: 15 |                  Max: 15 |                  Mean: 15.0 |                  Median: 15.0\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:412] 75 percentile: 15.00\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:413] 99 percentile: 15.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.28batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"rosecrans\" } tokens { name: \"protested\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"in\" } tokens { name: \"vain\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:30 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:28:30 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.79batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"it\" } tokens { name: \"required\" } tokens { name: \"months\" } tokens { name: \"and\" } tokens { name: \"great\" } tokens { name: \"events\" } tokens { name: \"to\" } tokens { name: \"make\" } tokens { name: \"grant\" } tokens { name: \"the\" } tokens { name: \"hero\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"army\" } tokens { name: \"which\" } tokens { name: \"he\" } tokens { name: \"afterward\" } tokens { name: \"became\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:31 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:31 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.61batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"for\" } tokens { name: \"some\" } tokens { name: \"reason\" } tokens { name: \"the\" } tokens { name: \"dead\" } tokens { name: \"at\" } tokens { name: \"hatchie\" } tokens { name: \"bridge\" } tokens { name: \"were\" } tokens { name: \"not\" } tokens { name: \"buried\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:31 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:31 punctuation_capitalization_infer_dataset:127] Max length: 14\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.22batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"a\" } tokens { name: \"week\" } tokens { name: \"after\" } tokens { name: \"the\" } tokens { name: \"battle\" } tokens { name: \"my\" } tokens { name: \"brother\" } tokens { name: \"rode\" } tokens { name: \"by\" } tokens { name: \"there\" } tokens { name: \"on\" } tokens { name: \"a\" } tokens { name: \"cavalry\" } tokens { name: \"expedition\" } tokens { name: \"and\" } tokens { name: \"made\" } tokens { name: \"the\" } tokens { name: \"horrible\" } tokens { name: \"discovery\" } tokens { name: \"that\" } tokens { name: \"hogs\" } tokens { name: \"were\" } tokens { name: \"eating\" } tokens { name: \"up\" } tokens { name: \"the\" } tokens { name: \"bodies\" } tokens { name: \"of\" } tokens { name: \"our\" } tokens { name: \"dead\" } tokens { name: \"heroes\" } tokens { name: \"that\" } tokens { name: \"too\" } tokens { name: \"was\" } tokens { name: \"war\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:31 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:31 punctuation_capitalization_infer_dataset:127] Max length: 37\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:406] Min: 35 |                  Max: 35 |                  Mean: 35.0 |                  Median: 35.0\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:412] 75 percentile: 35.00\n",
      "[NeMo I 2023-11-12 08:28:31 data_preprocessing:413] 99 percentile: 35.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0020.flac\n",
      "[{'entity_group': 'PER', 'score': 0.31028217, 'word': 'I', 'start': 0, 'end': 1}]\n",
      "ner tagged text B-PER I E-PER hastened back to the lines.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription B-PER I E-PER hastened back to the lines.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0017.flac\n",
      "[]\n",
      "ner tagged text I could not help my friend.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription I could not help my friend.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0008.flac\n",
      "[]\n",
      "ner tagged text With a few lanterns, our men then went about and tried to gather up the wounded. the dead were left till morning.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription With a few lanterns, our men then went about and tried to gather up the wounded. the dead were left till morning.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0025.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9777998, 'word': 'Grant', 'start': 57, 'end': 62}]\n",
      "ner tagged text Indeed, we of the rank and file had little confidence in B-PER Grant E-PER in those days.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Indeed, we of the rank and file had little confidence in B-PER Grant E-PER in those days.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0002.flac\n",
      "[]\n",
      "ner tagged text Our brigade was fearfully outnumbered.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Our brigade was fearfully outnumbered.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0019.flac\n",
      "[]\n",
      "ner tagged text My friend with many others was being carried out to die elsewhere.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription My friend with many others was being carried out to die elsewhere.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0013.flac\n",
      "[]\n",
      "ner tagged text When morning came, the firing opened, and for all that day, the battle raged fiercely at the left and center left we getting the worst of it, too.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription When morning came, the firing opened, and for all that day, the battle raged fiercely at the left and center left we getting the worst of it, too.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0004.flac\n",
      "[{'entity_group': 'PER', 'score': 0.94484234, 'word': 'Balaklava', 'start': 4, 'end': 13}, {'entity_group': 'PER', 'score': 0.6543235, 'word': 'Alma', 'start': 22, 'end': 26}]\n",
      "ner tagged text Not B-PER Balaklava E-PER nor the B-PER Alma E-PER saw such fighting. It was a duel to the death.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Not B-PER Balaklava E-PER nor the B-PER Alma E-PER saw such fighting. It was a duel to the death.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0007.flac\n",
      "[]\n",
      "ner tagged text That night, the enemy slipped away, leaving hundreds and hundreds of his dead and wounded on the field.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription That night, the enemy slipped away, leaving hundreds and hundreds of his dead and wounded on the field.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0010.flac\n",
      "[]\n",
      "ner tagged text Fifteen officers of our little half regiment were dead or wounded.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Fifteen officers of our little half regiment were dead or wounded.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0000.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9020807, 'word': 'Grant', 'start': 0, 'end': 5}, {'entity_group': 'MISC', 'score': 0.9902674, 'word': 'Civil War', 'start': 117, 'end': 126}]\n",
      "ner tagged text B-PER Grant E-PER was only a few miles away, but although commander in chief he knew nothing of the hardest fought battle of the B-MISC Civil War E-MISC until it was over.\n",
      "Emotion Labels []\n",
      "tagged transcription B-PER Grant E-PER was only a few miles away, but although commander in chief he knew nothing of the hardest fought battle of the B-MISC Civil War E-MISC until it was over.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0006.flac\n",
      "[{'entity_group': 'ORG', 'score': 0.9390907, 'word': 'Company B', 'start': 70, 'end': 79}]\n",
      "ner tagged text One daring rebel was shot down and bayoneted clear behind the line of B-ORG Company B E-ORG where he had broken through to seize the flag of my regiment.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription One daring rebel was shot down and bayoneted clear behind the line of B-ORG Company B E-ORG where he had broken through to seize the flag of my regiment.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0026.flac\n",
      "[{'entity_group': 'PER', 'score': 0.987488, 'word': 'Rosecrans', 'start': 0, 'end': 9}]\n",
      "ner tagged text B-PER Rosecrans E-PER protested it was in vain.\n",
      "Emotion Labels []\n",
      "tagged transcription B-PER Rosecrans E-PER protested it was in vain.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0009.flac\n",
      "[]\n",
      "ner tagged text It was not a question who was dead or wounded, but who was not.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription It was not a question who was dead or wounded, but who was not.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0003.flac\n",
      "[{'entity_group': 'ORG', 'score': 0.78091145, 'word': \"Hamilton ' s Division\", 'start': 57, 'end': 76}]\n",
      "ner tagged text There were no breastworks yet that one little brigade of Hamilton's Division stood there in the open and repulsed assault after assault.\n",
      "Emotion Labels []\n",
      "tagged transcription There were no breastworks yet that one little brigade of Hamilton's Division stood there in the open and repulsed assault after assault.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0016.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.99198526, 'word': 'Tishimingo', 'start': 74, 'end': 84}]\n",
      "ner tagged text Once in the night, I slipped away from the bivouac and hurried to the old B-LOC Tishimingo E-LOC hotel to see a lieutenant of my company who had been shot through the breast.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Once in the night, I slipped away from the bivouac and hurried to the old B-LOC Tishimingo E-LOC hotel to see a lieutenant of my company who had been shot through the breast.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0022.flac\n",
      "[{'entity_group': 'MISC', 'score': 0.4585527, 'word': 'mu', 'start': 31, 'end': 33}]\n",
      "ner tagged text A perfect blaze of close range B-MISC mu E-MISCsketry, too mowed them down like grass.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription A perfect blaze of close range B-MISC mu E-MISCsketry, too mowed them down like grass.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0012.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.9998857, 'word': 'Mississippi', 'start': 66, 'end': 77}]\n",
      "ner tagged text He survived the war, only to be murdered later on a plantation in B-LOC Mississippi E-LOC.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription He survived the war, only to be murdered later on a plantation in B-LOC Mississippi E-LOC.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0005.flac\n",
      "[]\n",
      "ner tagged text No battery in the whole four years war lost so many men in so short a time.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription No battery in the whole four years war lost so many men in so short a time.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0027.flac\n",
      "[]\n",
      "ner tagged text It required months and great events to make grant the hero of the army which he afterward became.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription It required months and great events to make grant the hero of the army which he afterward became.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0023.flac\n",
      "[]\n",
      "ner tagged text They lay in heaps of dozens, even close up to the works.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription They lay in heaps of dozens, even close up to the works.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0028.flac\n",
      "[{'entity_group': 'LOC', 'score': 0.99847144, 'word': 'Hatchie Bridge', 'start': 29, 'end': 43}]\n",
      "ner tagged text For some reason, the dead at B-LOC Hatchie Bridge E-LOC were not buried.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription For some reason, the dead at B-LOC Hatchie Bridge E-LOC were not buried.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0029.flac\n",
      "[]\n",
      "ner tagged text A week after the battle, my brother rode by there on a cavalry expedition and made the horrible discovery that hogs were eating up the bodies of our dead heroes that too was war.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription A week after the battle, my brother rode by there on a cavalry expedition and made the horrible discovery that hogs were eating up the bodies of our dead heroes that too was war.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0001.flac\n",
      "[]\n",
      "ner tagged text My own regiment was in the advance.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription My own regiment was in the advance.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0018.flac\n",
      "[]\n",
      "ner tagged text Go back to the regiment, he said, smiling, all will be needed.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Go back to the regiment, he said, smiling, all will be needed.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0015.flac\n",
      "[]\n",
      "ner tagged text Under the same quiet moonlight, and only six hundred yards away from us, also lay the victorious rebel army.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Under the same quiet moonlight, and only six hundred yards away from us, also lay the victorious rebel army.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0024.flac\n",
      "[{'entity_group': 'PER', 'score': 0.63192075, 'word': 'I', 'start': 11, 'end': 12}]\n",
      "ner tagged text That night B-PER I E-PER stood guard under an oak tree on the battlefield among the unburied dead.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription That night B-PER I E-PER stood guard under an oak tree on the battlefield among the unburied dead.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0011.flac\n",
      "[{'entity_group': 'PER', 'score': 0.99939734, 'word': 'Jimmy King', 'start': 86, 'end': 96}]\n",
      "ner tagged text I remained awake all night talking with a comrade who shared my blanket with me, poor B-PER Jimmy King E-PER.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription I remained awake all night talking with a comrade who shared my blanket with me, poor B-PER Jimmy King E-PER.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0014.flac\n",
      "[{'entity_group': 'PER', 'score': 0.7444239, 'word': 'Us. Hamilton', 'start': 31, 'end': 43}]\n",
      "ner tagged text That evening an order came for B-PER Us. Hamilton E-PER's division to assault the enemy's left flank at midnight.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription That evening an order came for B-PER Us. Hamilton E-PER's division to assault the enemy's left flank at midnight.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/105575/7976-105575-0021.flac\n",
      "[]\n",
      "ner tagged text The cloud of rebels we had seen divided itself into three columns.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription The cloud of rebels we had seen divided itself into three columns.\n",
      "ss /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523\n",
      "segments ['/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0009.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0007.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0011.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0012.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0019.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0000.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0002.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0014.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0010.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0020.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0021.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0018.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0006.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0008.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0013.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0004.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0005.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0003.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0017.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0001.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0016.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0015.flac', '/n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523.trans.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"he\" } tokens { name: \"had\" } tokens { name: \"little\" } tokens { name: \"enough\" } tokens { name: \"to\" } tokens { name: \"break\" } tokens { name: \"or\" } tokens { name: \"bite\" } tokens { name: \"and\" } tokens { name: \"once\" } tokens { name: \"when\" } tokens { name: \"there\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"great\" } tokens { name: \"famine\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"land\" } tokens { name: \"he\" } tokens { name: \"could\" } tokens { name: \"hardly\" } tokens { name: \"procure\" } tokens { name: \"even\" } tokens { name: \"his\" } tokens { name: \"daily\" } tokens { name: \"bread\" } tokens { name: \"and\" } tokens { name: \"as\" } tokens { name: \"he\" } tokens { name: \"lay\" } tokens { name: \"thinking\" } tokens { name: \"in\" } tokens { name: \"his\" } tokens { name: \"bed\" } tokens { name: \"one\" } tokens { name: \"night\" } tokens { name: \"he\" } tokens { name: \"sighed\" } tokens { name: \"and\" } tokens { name: \"said\" } tokens { name: \"to\" } tokens { name: \"his\" } tokens { name: \"wife\" } tokens { name: \"what\" } tokens { name: \"will\" } tokens { name: \"become\" } tokens { name: \"of\" } tokens { name: \"us\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_infer_dataset:127] Max length: 52\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:406] Min: 50 |                  Max: 50 |                  Mean: 50.0 |                  Median: 50.0\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:412] 75 percentile: 50.00\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:413] 99 percentile: 50.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.27batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"how\" } tokens { name: \"can\" } tokens { name: \"we\" } tokens { name: \"feed\" } tokens { name: \"our\" } tokens { name: \"children\" } tokens { name: \"when\" } tokens { name: \"we\" } tokens { name: \"have\" } tokens { name: \"no\" } tokens { name: \"more\" } tokens { name: \"than\" } tokens { name: \"we\" } tokens { name: \"can\" } tokens { name: \"eat\" } tokens { name: \"ourselves\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_infer_dataset:127] Max length: 18\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:406] Min: 16 |                  Max: 16 |                  Mean: 16.0 |                  Median: 16.0\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:412] 75 percentile: 16.00\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:413] 99 percentile: 16.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"oh\" } tokens { name: \"you\" } tokens { name: \"simpleton\" } tokens { name: \"said\" } tokens { name: \"she\" } tokens { name: \"then\" } tokens { name: \"we\" } tokens { name: \"must\" } tokens { name: \"all\" } tokens { name: \"four\" } tokens { name: \"die\" } tokens { name: \"of\" } tokens { name: \"hunger\" } tokens { name: \"you\" } tokens { name: \"had\" } tokens { name: \"better\" } tokens { name: \"plane\" } tokens { name: \"the\" } tokens { name: \"coffins\" } tokens { name: \"for\" } tokens { name: \"us\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_infer_dataset:127] Max length: 25\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:406] Min: 23 |                  Max: 23 |                  Mean: 23.0 |                  Median: 23.0\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:412] 75 percentile: 23.00\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:413] 99 percentile: 23.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.41batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"but\" } tokens { name: \"she\" } tokens { name: \"left\" } tokens { name: \"him\" } tokens { name: \"no\" } tokens { name: \"peace\" } tokens { name: \"till\" } tokens { name: \"he\" } tokens { name: \"consented\" } tokens { name: \"saying\" } tokens { name: \"ah\" } tokens { name: \"but\" } tokens { name: \"i\" } tokens { name: \"shall\" } tokens { name: \"miss\" } tokens { name: \"the\" } tokens { name: \"poor\" } tokens { name: \"children\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_infer_dataset:127] Max length: 21\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:406] Min: 19 |                  Max: 19 |                  Mean: 19.0 |                  Median: 19.0\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:412] 75 percentile: 19.00\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:413] 99 percentile: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.72batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"and\" } tokens { name: \"as\" } tokens { name: \"soon\" } tokens { name: \"as\" } tokens { name: \"their\" } tokens { name: \"parents\" } tokens { name: \"had\" } tokens { name: \"gone\" } tokens { name: \"to\" } tokens { name: \"sleep\" } tokens { name: \"he\" } tokens { name: \"got\" } tokens { name: \"up\" } tokens { name: \"put\" } tokens { name: \"on\" } tokens { name: \"his\" } tokens { name: \"coat\" } tokens { name: \"and\" } tokens { name: \"unbarring\" } tokens { name: \"the\" } tokens { name: \"back\" } tokens { name: \"door\" } tokens { name: \"went\" } tokens { name: \"out\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:53 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:28:53 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.36batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"ah\" } tokens { name: \"father\" } tokens { name: \"said\" } tokens { name: \"hansel\" } tokens { name: \"i\" } tokens { name: \"am\" } tokens { name: \"looking\" } tokens { name: \"at\" } tokens { name: \"my\" } tokens { name: \"white\" } tokens { name: \"cat\" } tokens { name: \"sitting\" } tokens { name: \"upon\" } tokens { name: \"the\" } tokens { name: \"roof\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"house\" } tokens { name: \"and\" } tokens { name: \"trying\" } tokens { name: \"to\" } tokens { name: \"say\" } tokens { name: \"good\" } tokens { name: \"bye\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.36batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"but\" } tokens { name: \"in\" } tokens { name: \"reality\" } tokens { name: \"hansel\" } tokens { name: \"was\" } tokens { name: \"not\" } tokens { name: \"looking\" } tokens { name: \"at\" } tokens { name: \"a\" } tokens { name: \"cat\" } tokens { name: \"but\" } tokens { name: \"every\" } tokens { name: \"time\" } tokens { name: \"he\" } tokens { name: \"stopped\" } tokens { name: \"he\" } tokens { name: \"dropped\" } tokens { name: \"a\" } tokens { name: \"pebble\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"his\" } tokens { name: \"pocket\" } tokens { name: \"upon\" } tokens { name: \"the\" } tokens { name: \"path\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_infer_dataset:127] Max length: 30\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:406] Min: 28 |                  Max: 28 |                  Mean: 28.0 |                  Median: 28.0\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:413] 99 percentile: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.30batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"but\" } tokens { name: \"her\" } tokens { name: \"husband\" } tokens { name: \"felt\" } tokens { name: \"heavy\" } tokens { name: \"at\" } tokens { name: \"heart\" } tokens { name: \"and\" } tokens { name: \"thought\" } tokens { name: \"it\" } tokens { name: \"were\" } tokens { name: \"better\" } tokens { name: \"to\" } tokens { name: \"share\" } tokens { name: \"the\" } tokens { name: \"last\" } tokens { name: \"crust\" } tokens { name: \"with\" } tokens { name: \"the\" } tokens { name: \"children\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_infer_dataset:127] Max length: 22\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:406] Min: 20 |                  Max: 20 |                  Mean: 20.0 |                  Median: 20.0\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:412] 75 percentile: 20.00\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:413] 99 percentile: 20.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.26batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"early\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"morning\" } tokens { name: \"the\" } tokens { name: \"stepmother\" } tokens { name: \"came\" } tokens { name: \"and\" } tokens { name: \"pulled\" } tokens { name: \"them\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"bed\" } tokens { name: \"and\" } tokens { name: \"gave\" } tokens { name: \"them\" } tokens { name: \"each\" } tokens { name: \"a\" } tokens { name: \"slice\" } tokens { name: \"of\" } tokens { name: \"bread\" } tokens { name: \"which\" } tokens { name: \"was\" } tokens { name: \"still\" } tokens { name: \"smaller\" } tokens { name: \"than\" } tokens { name: \"the\" } tokens { name: \"former\" } tokens { name: \"piece\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:54 punctuation_capitalization_infer_dataset:127] Max length: 31\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:406] Min: 29 |                  Max: 29 |                  Mean: 29.0 |                  Median: 29.0\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:412] 75 percentile: 29.00\n",
      "[NeMo I 2023-11-12 08:28:54 data_preprocessing:413] 99 percentile: 29.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.03batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"we\" } tokens { name: \"are\" } tokens { name: \"going\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"forest\" } tokens { name: \"to\" } tokens { name: \"hew\" } tokens { name: \"wood\" } tokens { name: \"and\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"evening\" } tokens { name: \"when\" } tokens { name: \"we\" } tokens { name: \"are\" } tokens { name: \"ready\" } tokens { name: \"we\" } tokens { name: \"will\" } tokens { name: \"come\" } tokens { name: \"and\" } tokens { name: \"fetch\" } tokens { name: \"you\" } tokens { name: \"again\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_infer_dataset:127] Max length: 27\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.12batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"hansel\" } tokens { name: \"thought\" } tokens { name: \"the\" } tokens { name: \"roof\" } tokens { name: \"tasted\" } tokens { name: \"very\" } tokens { name: \"nice\" } tokens { name: \"and\" } tokens { name: \"so\" } tokens { name: \"he\" } tokens { name: \"tore\" } tokens { name: \"off\" } tokens { name: \"a\" } tokens { name: \"great\" } tokens { name: \"piece\" } tokens { name: \"while\" } tokens { name: \"grethel\" } tokens { name: \"broke\" } tokens { name: \"a\" } tokens { name: \"large\" } tokens { name: \"round\" } tokens { name: \"pane\" } tokens { name: \"out\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"window\" } tokens { name: \"and\" } tokens { name: \"sat\" } tokens { name: \"down\" } tokens { name: \"quite\" } tokens { name: \"contentedly\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_infer_dataset:127] Max length: 38\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:406] Min: 36 |                  Max: 36 |                  Mean: 36.0 |                  Median: 36.0\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:412] 75 percentile: 36.00\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:413] 99 percentile: 36.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.09batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"come\" } tokens { name: \"in\" } tokens { name: \"and\" } tokens { name: \"stop\" } tokens { name: \"with\" } tokens { name: \"me\" } tokens { name: \"and\" } tokens { name: \"no\" } tokens { name: \"harm\" } tokens { name: \"shall\" } tokens { name: \"come\" } tokens { name: \"to\" } tokens { name: \"you\" } tokens { name: \"and\" } tokens { name: \"so\" } tokens { name: \"saying\" } tokens { name: \"she\" } tokens { name: \"took\" } tokens { name: \"them\" } tokens { name: \"both\" } tokens { name: \"by\" } tokens { name: \"the\" } tokens { name: \"hand\" } tokens { name: \"and\" } tokens { name: \"led\" } tokens { name: \"them\" } tokens { name: \"into\" } tokens { name: \"her\" } tokens { name: \"cottage\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_infer_dataset:127] Max length: 31\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:406] Min: 29 |                  Max: 29 |                  Mean: 29.0 |                  Median: 29.0\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:412] 75 percentile: 29.00\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:413] 99 percentile: 29.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.88batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"the\" } tokens { name: \"old\" } tokens { name: \"woman\" } tokens { name: \"behaved\" } tokens { name: \"very\" } tokens { name: \"kindly\" } tokens { name: \"to\" } tokens { name: \"them\" } tokens { name: \"but\" } tokens { name: \"in\" } tokens { name: \"reality\" } tokens { name: \"she\" } tokens { name: \"was\" } tokens { name: \"a\" } tokens { name: \"wicked\" } tokens { name: \"old\" } tokens { name: \"witch\" } tokens { name: \"who\" } tokens { name: \"way\" } tokens { name: \"laid\" } tokens { name: \"children\" } tokens { name: \"and\" } tokens { name: \"built\" } tokens { name: \"the\" } tokens { name: \"breadhouse\" } tokens { name: \"in\" } tokens { name: \"order\" } tokens { name: \"to\" } tokens { name: \"entice\" } tokens { name: \"them\" } tokens { name: \"in\" } tokens { name: \"but\" } tokens { name: \"as\" } tokens { name: \"soon\" } tokens { name: \"as\" } tokens { name: \"they\" } tokens { name: \"were\" } tokens { name: \"in\" } tokens { name: \"her\" } tokens { name: \"power\" } tokens { name: \"she\" } tokens { name: \"killed\" } tokens { name: \"them\" } tokens { name: \"cooked\" } tokens { name: \"and\" } tokens { name: \"ate\" } tokens { name: \"them\" } tokens { name: \"and\" } tokens { name: \"made\" } tokens { name: \"a\" } tokens { name: \"great\" } tokens { name: \"festival\" } tokens { name: \"of\" } tokens { name: \"the\" } tokens { name: \"day\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:55 punctuation_capitalization_infer_dataset:127] Max length: 60\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:406] Min: 58 |                  Max: 58 |                  Mean: 58.0 |                  Median: 58.0\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:412] 75 percentile: 58.00\n",
      "[NeMo I 2023-11-12 08:28:55 data_preprocessing:413] 99 percentile: 58.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.29batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"she\" } tokens { name: \"took\" } tokens { name: \"up\" } tokens { name: \"hansel\" } tokens { name: \"with\" } tokens { name: \"her\" } tokens { name: \"rough\" } tokens { name: \"hand\" } tokens { name: \"and\" } tokens { name: \"shut\" } tokens { name: \"him\" } tokens { name: \"up\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"little\" } tokens { name: \"cage\" } tokens { name: \"with\" } tokens { name: \"a\" } tokens { name: \"lattice\" } tokens { name: \"door\" } tokens { name: \"and\" } tokens { name: \"although\" } tokens { name: \"he\" } tokens { name: \"screamed\" } tokens { name: \"loudly\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"of\" } tokens { name: \"no\" } tokens { name: \"use\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_infer_dataset:127] Max length: 34\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:406] Min: 32 |                  Max: 32 |                  Mean: 32.0 |                  Median: 32.0\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:412] 75 percentile: 32.00\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:413] 99 percentile: 32.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.56batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"grethel\" } tokens { name: \"began\" } tokens { name: \"to\" } tokens { name: \"cry\" } tokens { name: \"but\" } tokens { name: \"it\" } tokens { name: \"was\" } tokens { name: \"all\" } tokens { name: \"useless\" } tokens { name: \"for\" } tokens { name: \"the\" } tokens { name: \"old\" } tokens { name: \"witch\" } tokens { name: \"made\" } tokens { name: \"her\" } tokens { name: \"do\" } tokens { name: \"as\" } tokens { name: \"she\" } tokens { name: \"wanted\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_infer_dataset:127] Max length: 23\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:406] Min: 21 |                  Max: 21 |                  Mean: 21.0 |                  Median: 21.0\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:412] 75 percentile: 21.00\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:413] 99 percentile: 21.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.20batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"grethel\" } tokens { name: \"she\" } tokens { name: \"cried\" } tokens { name: \"in\" } tokens { name: \"a\" } tokens { name: \"passion\" } tokens { name: \"get\" } tokens { name: \"some\" } tokens { name: \"water\" } tokens { name: \"quickly\" } tokens { name: \"be\" } tokens { name: \"hansel\" } tokens { name: \"fat\" } tokens { name: \"or\" } tokens { name: \"lean\" } tokens { name: \"this\" } tokens { name: \"morning\" } tokens { name: \"i\" } tokens { name: \"will\" } tokens { name: \"kill\" } tokens { name: \"and\" } tokens { name: \"cook\" } tokens { name: \"him\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_infer_dataset:127] Max length: 28\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:406] Min: 26 |                  Max: 26 |                  Mean: 26.0 |                  Median: 26.0\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:412] 75 percentile: 26.00\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:413] 99 percentile: 26.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.67batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"dear\" } tokens { name: \"good\" } tokens { name: \"god\" } tokens { name: \"help\" } tokens { name: \"us\" } tokens { name: \"now\" } tokens { name: \"she\" } tokens { name: \"prayed\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:56 punctuation_capitalization_infer_dataset:127] Max length: 10\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2023-11-12 08:28:56 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.66batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"creep\" } tokens { name: \"in\" } tokens { name: \"said\" } tokens { name: \"the\" } tokens { name: \"witch\" } tokens { name: \"and\" } tokens { name: \"see\" } tokens { name: \"if\" } tokens { name: \"it\" } tokens { name: \"is\" } tokens { name: \"hot\" } tokens { name: \"enough\" } tokens { name: \"and\" } tokens { name: \"then\" } tokens { name: \"we\" } tokens { name: \"will\" } tokens { name: \"put\" } tokens { name: \"in\" } tokens { name: \"the\" } tokens { name: \"bread\" } tokens { name: \"but\" } tokens { name: \"she\" } tokens { name: \"intended\" } tokens { name: \"when\" } tokens { name: \"grethel\" } tokens { name: \"got\" } tokens { name: \"in\" } tokens { name: \"to\" } tokens { name: \"shut\" } tokens { name: \"up\" } tokens { name: \"the\" } tokens { name: \"oven\" } tokens { name: \"and\" } tokens { name: \"let\" } tokens { name: \"her\" } tokens { name: \"bake\" } tokens { name: \"so\" } tokens { name: \"that\" } tokens { name: \"she\" } tokens { name: \"might\" } tokens { name: \"eat\" } tokens { name: \"her\" } tokens { name: \"as\" } tokens { name: \"well\" } tokens { name: \"as\" } tokens { name: \"hansel\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_infer_dataset:127] Max length: 52\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:406] Min: 50 |                  Max: 50 |                  Mean: 50.0 |                  Median: 50.0\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:412] 75 percentile: 50.00\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:413] 99 percentile: 50.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.03batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"see\" } tokens { name: \"i\" } tokens { name: \"could\" } tokens { name: \"even\" } tokens { name: \"get\" } tokens { name: \"in\" } tokens { name: \"myself\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_infer_dataset:127] Max length: 9\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:406] Min: 7 |                  Max: 7 |                  Mean: 7.0 |                  Median: 7.0\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:412] 75 percentile: 7.00\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:413] 99 percentile: 7.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.97batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"and\" } tokens { name: \"she\" } tokens { name: \"got\" } tokens { name: \"up\" } tokens { name: \"and\" } tokens { name: \"put\" } tokens { name: \"her\" } tokens { name: \"head\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"oven\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_infer_dataset:127] Max length: 13\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.92batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"and\" } tokens { name: \"now\" } tokens { name: \"as\" } tokens { name: \"there\" } tokens { name: \"was\" } tokens { name: \"nothing\" } tokens { name: \"to\" } tokens { name: \"fear\" } tokens { name: \"they\" } tokens { name: \"went\" } tokens { name: \"back\" } tokens { name: \"to\" } tokens { name: \"the\" } tokens { name: \"witch's\" } tokens { name: \"house\" } tokens { name: \"where\" } tokens { name: \"in\" } tokens { name: \"every\" } tokens { name: \"corner\" } tokens { name: \"were\" } tokens { name: \"caskets\" } tokens { name: \"full\" } tokens { name: \"of\" } tokens { name: \"pearls\" } tokens { name: \"and\" } tokens { name: \"precious\" } tokens { name: \"stones\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_infer_dataset:127] Max length: 32\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:406] Min: 30 |                  Max: 30 |                  Mean: 30.0 |                  Median: 30.0\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:412] 75 percentile: 30.00\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:413] 99 percentile: 30.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.26batch/s]\n",
      " NeMo-text-processing :: DEBUG    :: tokens { name: \"then\" } tokens { name: \"they\" } tokens { name: \"began\" } tokens { name: \"to\" } tokens { name: \"run\" } tokens { name: \"and\" } tokens { name: \"rushing\" } tokens { name: \"into\" } tokens { name: \"the\" } tokens { name: \"house\" } tokens { name: \"they\" } tokens { name: \"fell\" } tokens { name: \"upon\" } tokens { name: \"their\" } tokens { name: \"father's\" } tokens { name: \"neck\" }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_model:1167] Using batch size 1 for inference\n",
      "[NeMo I 2023-11-12 08:28:57 punctuation_capitalization_infer_dataset:127] Max length: 20\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:406] Min: 18 |                  Max: 18 |                  Mean: 18.0 |                  Median: 18.0\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:412] 75 percentile: 18.00\n",
      "[NeMo I 2023-11-12 08:28:57 data_preprocessing:413] 99 percentile: 18.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0009.flac\n",
      "[]\n",
      "ner tagged text We are going into the forest to hew wood, and in the evening when we are ready, we will come and fetch you again.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription We are going into the forest to hew wood, and in the evening when we are ready, we will come and fetch you again.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0007.flac\n",
      "[]\n",
      "ner tagged text But her husband felt heavy at heart and thought it were better to share the last crust with the children.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription But her husband felt heavy at heart and thought it were better to share the last crust with the children.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0011.flac\n",
      "[]\n",
      "ner tagged text Come in and stop with me, and no harm shall come to you, and so saying, she took them both by the hand and led them into her cottage.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Come in and stop with me, and no harm shall come to you, and so saying, she took them both by the hand and led them into her cottage.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0012.flac\n",
      "[]\n",
      "ner tagged text The old woman behaved very kindly to them, but in reality she was a wicked old witch who way laid children and built the breadhouse in order to entice them in, but as soon as they were in her power, she killed them cooked and ate them and made a great festival of the day.\n",
      "Emotion Labels []\n",
      "tagged transcription The old woman behaved very kindly to them, but in reality she was a wicked old witch who way laid children and built the breadhouse in order to entice them in, but as soon as they were in her power, she killed them cooked and ate them and made a great festival of the day.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0019.flac\n",
      "[]\n",
      "ner tagged text And she got up and put her head into the oven.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription And she got up and put her head into the oven.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0000.flac\n",
      "[]\n",
      "ner tagged text He had little enough to break or bite, and once when there was a great famine in the land, he could hardly procure even his daily bread, and as he lay thinking in his bed one night, he sighed and said to his wife what will become of us.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription He had little enough to break or bite, and once when there was a great famine in the land, he could hardly procure even his daily bread, and as he lay thinking in his bed one night, he sighed and said to his wife what will become of us.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0002.flac\n",
      "[]\n",
      "ner tagged text Oh you, simpleton, said she, then we must all four die of hunger. You had better plane the coffins for us.\n",
      "Emotion Labels ['SURPRISE']\n",
      "tagged transcription Oh you, simpleton, said she, then we must all four die of hunger. You had better plane the coffins for us.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0014.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9860298, 'word': 'G', 'start': 0, 'end': 1}, {'entity_group': 'PER', 'score': 0.7958576, 'word': '##rethel', 'start': 1, 'end': 7}]\n",
      "ner tagged text B-PER G E-PERrethel began to cry, but it was all useless for the old witch made her do as she wanted.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription B-PER G E-PERrethel began to cry, but it was all useless for the old witch made her do as she wanted.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0010.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9798926, 'word': 'Hansel', 'start': 0, 'end': 6}, {'entity_group': 'PER', 'score': 0.9362879, 'word': 'Grethel', 'start': 81, 'end': 88}]\n",
      "ner tagged text B-PER Hansel E-PER thought the roof tasted very nice, and so he tore off a great piece while B-PER Grethel E-PER broke a large round pane out of the window and sat down quite contentedly.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription B-PER Hansel E-PER thought the roof tasted very nice, and so he tore off a great piece while B-PER Grethel E-PER broke a large round pane out of the window and sat down quite contentedly.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0020.flac\n",
      "[]\n",
      "ner tagged text And now as there was nothing to fear, they went back to the witch's house, where in every corner were caskets full of pearls and precious stones.\n",
      "Emotion Labels []\n",
      "tagged transcription And now as there was nothing to fear, they went back to the witch's house, where in every corner were caskets full of pearls and precious stones.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0021.flac\n",
      "[]\n",
      "ner tagged text Then they began to run and rushing into the house, they fell upon their father's neck.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Then they began to run and rushing into the house, they fell upon their father's neck.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0018.flac\n",
      "[]\n",
      "ner tagged text See, I could even get in myself.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription See, I could even get in myself.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0006.flac\n",
      "[{'entity_group': 'PER', 'score': 0.9292349, 'word': 'Hansel', 'start': 16, 'end': 22}]\n",
      "ner tagged text But in reality, B-PER Hansel E-PER was not looking at a cat, but every time he stopped, he dropped a pebble out of his pocket upon the path.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription But in reality, B-PER Hansel E-PER was not looking at a cat, but every time he stopped, he dropped a pebble out of his pocket upon the path.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0008.flac\n",
      "[]\n",
      "ner tagged text Early in the morning, the stepmother came and pulled them out of bed and gave them each a slice of bread, which was still smaller than the former piece.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription Early in the morning, the stepmother came and pulled them out of bed and gave them each a slice of bread, which was still smaller than the former piece.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0013.flac\n",
      "[{'entity_group': 'PER', 'score': 0.97103995, 'word': 'Hansel', 'start': 17, 'end': 23}]\n",
      "ner tagged text Then she took up B-PER Hansel E-PER with her rough hand and shut him up in a little cage with a lattice door, and although he screamed loudly, it was of no use.\n",
      "Emotion Labels ['ANGRY']\n",
      "tagged transcription Then she took up B-PER Hansel E-PER with her rough hand and shut him up in a little cage with a lattice door, and although he screamed loudly, it was of no use.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0004.flac\n",
      "[]\n",
      "ner tagged text And as soon as their parents had gone to sleep, he got up, put on his coat and unbarring the back door went out.\n",
      "Emotion Labels ['NEUTRAL']\n",
      "tagged transcription And as soon as their parents had gone to sleep, he got up, put on his coat and unbarring the back door went out.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0005.flac\n",
      "[{'entity_group': 'PER', 'score': 0.97996235, 'word': 'Hansel', 'start': 17, 'end': 23}]\n",
      "ner tagged text Ah, father, said B-PER Hansel E-PER, I am looking at my white cat sitting upon the roof of the house and trying to say good bye.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Ah, father, said B-PER Hansel E-PER, I am looking at my white cat sitting upon the roof of the house and trying to say good bye.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0003.flac\n",
      "[]\n",
      "ner tagged text But she left him no peace till he consented, saying, Ah, but I shall miss the poor children.\n",
      "Emotion Labels []\n",
      "tagged transcription But she left him no peace till he consented, saying, Ah, but I shall miss the poor children.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0017.flac\n",
      "[{'entity_group': 'PER', 'score': 0.8909305, 'word': 'Grethel', 'start': 110, 'end': 117}, {'entity_group': 'PER', 'score': 0.782454, 'word': 'Hansel', 'start': 199, 'end': 205}]\n",
      "ner tagged text Creep in, said the witch and see if it is hot enough and then we will put in the bread, but she intended when B-PER Grethel E-PER got in to shut up the oven and let her bake so that she might eat her as well as B-PER Hansel E-PER.\n",
      "Emotion Labels []\n",
      "tagged transcription Creep in, said the witch and see if it is hot enough and then we will put in the bread, but she intended when B-PER Grethel E-PER got in to shut up the oven and let her bake so that she might eat her as well as B-PER Hansel E-PER.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0001.flac\n",
      "[]\n",
      "ner tagged text How can we feed our children when we have no more than we can eat ourselves?\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription How can we feed our children when we have no more than we can eat ourselves?\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0016.flac\n",
      "[{'entity_group': 'PER', 'score': 0.71640646, 'word': 'God', 'start': 12, 'end': 15}]\n",
      "ner tagged text Dear, good, B-PER God E-PER help us. now she prayed.\n",
      "Emotion Labels ['HAPPY']\n",
      "tagged transcription Dear, good, B-PER God E-PER help us. now she prayed.\n",
      "Old path /n/disk1/audio_datasets/EN_libre/LibriSpeech/dev-clean/7976/110523/7976-110523-0015.flac\n",
      "[{'entity_group': 'PER', 'score': 0.5839075, 'word': 'G', 'start': 0, 'end': 1}, {'entity_group': 'PER', 'score': 0.9529475, 'word': 'Hansel', 'start': 59, 'end': 65}]\n",
      "ner tagged text B-PER G E-PERrethel, she cried in a passion. B-PER G E-PERet some water quickly Be B-PER Hansel E-PER, fat or lean, This morning. I will kill and cook him.\n",
      "Emotion Labels ['DISGUST']\n",
      "tagged transcription B-PER G E-PERrethel, she cried in a passion. B-PER G E-PERet some water quickly Be B-PER Hansel E-PER, fat or lean, This morning. I will kill and cook him.\n"
     ]
    }
   ],
   "source": [
    "allpath = [TRAIN_DATA, DEV_DATA, TEST_DATA]\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    normalized = normalizer.normalize(text, verbose=True, punct_post_process=True)\n",
    "    normalized = [normalized]\n",
    "    norm_punctuated = punctuator.add_punctuation_capitalization(normalized)[0]\n",
    "    return norm_punctuated\n",
    "\n",
    "def read_transcription(filepath):\n",
    "\n",
    "    trans = open(filepath,'r').readlines()\n",
    "    trans_dict = {}\n",
    "    for line in trans:\n",
    "        line = line.strip().split()\n",
    "        text = ' '.join(line[1:])\n",
    "        text = normalize(text)\n",
    "\n",
    "        trans_dict[line[0]] = text\n",
    "    \n",
    "    return trans_dict\n",
    "\n",
    "def process_librispeech(datakey):\n",
    "\n",
    "    print(datakey)\n",
    "    datafolders = glob.glob(str(datakey)+'/*')\n",
    "    print(datafolders)\n",
    "\n",
    "    datakey_wav = str(datakey) + '-wav/'\n",
    "    os.system('mkdir -p ' + datakey_wav)\n",
    "    datakey_wav = Path(datakey_wav)\n",
    "\n",
    "    manifest = open(datakey_wav.name+'.json','w')\n",
    "\n",
    "    for folder in datafolders[:4]:\n",
    "        sessdirs = glob.glob(folder + '/*')\n",
    "\n",
    "        for sessdir in sessdirs:\n",
    "            print(\"ss\", sessdir)\n",
    "            segments = glob.glob(sessdir + '/*')\n",
    "            print(\"segments\", segments)\n",
    "\n",
    "            transcription = [x for x in segments if re.search(\".txt\", x)][0]\n",
    "            trans_dict = read_transcription(transcription)\n",
    "            #print(trans_dict)\n",
    "\n",
    "\n",
    "            for segment in segments:\n",
    "                #allfiles = glob.glob(segment + '/*')\n",
    "                \n",
    "                filepath = PurePath(segment)\n",
    "\n",
    "                if \".flac\" in str(filepath):\n",
    "                    \n",
    "                    sample_dict = {}\n",
    "\n",
    "                    print(\"Old path\", filepath)\n",
    "\n",
    "                    filekey = filepath.name.replace(filepath.suffix, \"\")\n",
    "                    transcription = trans_dict[filekey]\n",
    "                    wav_filepath = str(datakey_wav) + \"/\" + filekey + \".wav\"\n",
    "                    sample_dict['audiofilepath'] = wav_filepath\n",
    "                    sample_dict['text'] = transcription\n",
    "                    sample_dict['tagged_text'] = transcription\n",
    "\n",
    "                    flac_tmp_audio_data = AudioSegment.from_file(filepath, filepath.suffix[1:])\n",
    "                    flac_tmp_audio_data.export(wav_filepath, format=\"wav\")\n",
    "                    sample_dict['instruction'] = \"transcribe speech\"\n",
    "\n",
    "                    json.dump(sample_dict, manifest)\n",
    "                    manifest.write(\"\\n\")\n",
    "\n",
    "\n",
    "                    tagged_transcription = tag_entities(transcription)\n",
    "                    sample_dict['text'] = transcription\n",
    "                    sample_dict['tagged_text'] = tagged_transcription\n",
    "                    sample_dict['instruction'] = \"transcribe and mark named entities\"\n",
    "                    json.dump(sample_dict, manifest)\n",
    "                    manifest.write(\"\\n\")\n",
    "\n",
    "\n",
    "                    emotion_labels = get_emotion_labels(audio_file=wav_filepath, sampling_rate=16000)\n",
    "                    print(\"Emotion Labels\", emotion_labels)\n",
    "                    emotion_labels = ' '.join(emotion_labels)\n",
    "\n",
    "                    final_transcription = tagged_transcription + \" \" + emotion_labels\n",
    "\n",
    "                    sample_dict['text'] = final_transcription\n",
    "                    sample_dict['tagged_text'] = transcription\n",
    "                    sample_dict['instruction'] = \"transcribe, mark named entitites and track speaker emotion\"\n",
    "                    json.dump(sample_dict, manifest)\n",
    "                    manifest.write(\"\\n\")\n",
    "\n",
    "                    sample_dict['prompt'] = final_transcription\n",
    "                    print(\"tagged transcription\", tagged_transcription)\n",
    "    \n",
    "    manifest.close()\n",
    "\n",
    "for datakey in allpath[1:2]:\n",
    "    #print(datapath)\n",
    "    print(datakey)\n",
    "    process_librispeech(datakey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
