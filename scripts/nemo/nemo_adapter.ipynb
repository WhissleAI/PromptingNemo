{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample_rate': 16000, 'log_prediction': True, 'ctc_reduction': 'mean_batch', 'train_ds': {'manifest_filepath': '/data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json', 'sample_rate': 16000, 'batch_size': 32, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'trim_silence': False, 'max_duration': 20.0, 'min_duration': 0.1, 'shuffle_n': 2048, 'is_tarred': True, 'tarred_audio_filepaths': '/data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar'}, 'validation_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'test_ds': {'manifest_filepath': ['/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json', '/data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json'], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True, 'use_start_end_token': False, 'is_tarred': False, 'tarred_audio_filepaths': 'na'}, 'tokenizer': {'dir': '/tokenizers/NeMo_ASR_SET/English/asr_set_2.0/tokenizer_spe_unigram_v128/', 'type': 'bpe', 'model_path': 'nemo:eba1b3eaeb954624b16408eb64adb85a_tokenizer.model', 'vocab_path': 'nemo:98a23bf202634dab96ede2f43de77994_vocab.txt', 'spe_tokenizer_vocab': 'nemo:b5858ae29b984021aed220772ca1ff19_tokenizer.vocab'}, 'preprocessor': {'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'sample_rate': 16000, 'normalize': 'per_feature', 'window_size': 0.025, 'window_stride': 0.01, 'window': 'hann', 'features': 80, 'n_fft': 512, 'log': True, 'frame_splicing': 1, 'dither': 1e-05, 'pad_to': 0, 'pad_value': 0.0}, 'spec_augment': {'_target_': 'nemo.collections.asr.modules.SpectrogramAugmentation', 'freq_masks': 2, 'time_masks': 10, 'freq_width': 27, 'time_width': 0.05}, 'encoder': {'_target_': 'nemo.collections.asr.modules.ConformerEncoder', 'feat_in': 80, 'feat_out': -1, 'n_layers': 18, 'd_model': 512, 'subsampling': 'striding', 'subsampling_factor': 4, 'subsampling_conv_channels': 512, 'ff_expansion_factor': 4, 'self_attention_model': 'rel_pos', 'n_heads': 8, 'att_context_size': [-1, -1], 'xscaling': True, 'untie_biases': True, 'pos_emb_max_len': 5000, 'conv_kernel_size': 31, 'dropout': 0.1, 'dropout_emb': 0.0, 'dropout_att': 0.1}, 'decoder': {'_target_': 'nemo.collections.asr.modules.ConvASRDecoder', 'feat_in': 512, 'num_classes': 128, 'vocabulary': ['<unk>', 's', '▁', 'e', 't', 'u', 'd', 'a', 'o', 'n', 'i', '▁the', '▁a', 'm', 'y', 'l', 'h', 'p', 're', '▁s', 'g', 'r', '▁to', '▁i', 'ing', '▁and', 'f', '▁p', 'an', 'c', 'w', 'er', 'ed', '▁of', '▁in', 'k', \"'\", '▁w', 'ar', 'or', '▁f', 'b', '▁b', 'en', '▁you', 'al', 'le', 'in', 'll', '▁that', '▁he', 'ro', '▁t', 'es', '▁it', '▁be', 've', 'v', 'ly', '▁c', 'th', '▁o', 'ent', 'ch', 'ur', '▁we', '▁re', '▁n', 'it', '▁so', '▁co', '▁g', '▁on', '▁for', 'on', 'ce', 'ri', '▁do', '▁is', '▁ha', '▁ma', 'ver', 'li', 'ra', '▁was', 'ic', 'la', '▁e', 'se', 'ter', 'ct', 'ion', '▁ca', '▁st', '▁me', 'ir', '▁mo', '▁with', '▁but', '▁have', '▁go', '▁de', '▁ho', '▁di', '▁not', '▁know', '▁lo', '▁this', 'ation', 'ther', 'ate', '▁com', '▁like', '▁uh', 'ck', '▁his', 'j', '▁yeah', '▁my', '▁ex', '▁what', '▁will', '▁mi', 'q', 'ight', 'x', 'z', '-']}, 'optim': {'name': 'adamw', 'lr': 2.0, 'betas': [0.9, 0.98], 'weight_decay': 0.001, 'sched': {'name': 'NoamAnnealing', 'd_model': 512, 'warmup_steps': 10000, 'warmup_ratio': None, 'min_lr': 1e-06}}, 'target': 'nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE'}\n"
     ]
    }
   ],
   "source": [
    "# Load the model from a local .nemo file\n",
    "\n",
    "MODEL_ROOT = \"/external2/models/hf/stt_en_conformer_ctc_large/\"\n",
    "MODEL_ROOT = Path(MODEL_ROOT)\n",
    "model_path = MODEL_ROOT / \"stt_en_conformer_ctc_large.nemo\"\n",
    "\n",
    "cfg = nemo_asr.models.ASRModel.restore_from(restore_path=model_path, return_config=True)\n",
    "\n",
    "# If you need to get the configuration, you can access it from the loaded model\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.core import adapter_mixins\n",
    "\n",
    "# Utility method to check and update the model config\n",
    "def update_model_config_to_support_adapter(model_cfg):\n",
    "    with open_dict(model_cfg):\n",
    "        adapter_metadata = adapter_mixins.get_registered_adapter(model_cfg.encoder._target_)\n",
    "        if adapter_metadata is not None:\n",
    "            model_cfg.encoder._target_ = adapter_metadata.adapter_class_path\n",
    "\n",
    "    print(\"Updated encoder _target_ model :\", model_cfg.encoder._target_)\n",
    "    return model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated encoder _target_ model : nemo.collections.asr.modules.conformer_encoder.ConformerEncoderAdapter\n"
     ]
    }
   ],
   "source": [
    "cfg = update_model_config_to_support_adapter(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:17 mixins:172] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-16 06:21:17 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/NeMo_ASR_SET/English/v2.0/train/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/NeMo_ASR_SET/English/v2.0/train/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2024-07-16 06:21:17 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2024-07-16 06:21:17 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:17 features:289] PADDING: 0\n",
      "[NeMo I 2024-07-16 06:21:19 save_restore_connector:249] Model EncDecCTCModelBPE was successfully restored from /external2/models/hf/stt_en_conformer_ctc_large/stt_en_conformer_ctc_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "model = nemo_asr.models.ASRModel.restore_from(model_path, override_config_path=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ksingla/workspace/PromptingNemo/data/synthetic/\"\n",
    "TRAIN_MANIFEST = os.path.join(data_dir, \"text_train_cleaned_manifest_v3.json\")\n",
    "TEST_MANIFEST = os.path.join(data_dir, \"text_valid_cleaned_manifest_v4.json\")\n",
    "ALL_TAGS = os.path.join(data_dir, \"alltags_v4.txt\")\n",
    "taglist = []\n",
    "with open(ALL_TAGS, 'r') as f:\n",
    "    for line in f:\n",
    "        word, tag = line.split()\n",
    "        taglist.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Token '-' already exists in the input model, skipping.\n",
      "Special Token ''' already exists in the input model, skipping.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "\n",
    "def generate_sentencepiece_model_pb2(script_dir, proto_file_path):\n",
    "    # Construct the command\n",
    "    command = [\n",
    "        'protoc',\n",
    "        f'--python_out={script_dir}',\n",
    "        proto_file_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Run the command\n",
    "        subprocess.run(command, check=True)\n",
    "        print(\"Successfully generated sentencepiece_model_pb2.py\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error generating sentencepiece_model_pb2.py: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def edit_spt_model(input_file, output_folder, tokens, vocab_file, vocab_txt_file, is_userdefined=False):\n",
    "    from sentencepiece_model_pb2 import ModelProto  # Ensure this import is after the proto generation\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    output_model_file = os.path.join(output_folder, 'tokenizer.model')\n",
    "    output_vocab_file = os.path.join(output_folder, 'tokenizer.vocab')\n",
    "    output_vocab_txt_file = os.path.join(output_folder, 'vocab.txt')\n",
    "\n",
    "    token_type = 3\n",
    "    if is_userdefined:\n",
    "        token_type = 4\n",
    "\n",
    "    model = ModelProto()\n",
    "    model.ParseFromString(open(input_file, 'rb').read())\n",
    "\n",
    "    existing_tokens = {piece.piece for piece in model.pieces}\n",
    "\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token in existing_tokens:\n",
    "            logging.warning(f\"Special Token '{token}' already exists in the input model, skipping.\")\n",
    "            continue\n",
    "        piece = model.SentencePiece(piece=token, score=0.0, type=token_type)\n",
    "        model.pieces.append(piece)\n",
    "        new_tokens.append(token)\n",
    "\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    try:\n",
    "        sp.LoadFromSerializedProto(model.SerializeToString())\n",
    "        for token in new_tokens:\n",
    "            id = sp.piece_to_id(token)\n",
    "            logging.info(f\"Created token '{token}' at ID {id}\")\n",
    "        logging.info(f\"New tokenizer vocab size: {sp.get_piece_size()}\")\n",
    "    except:\n",
    "        logging.error(\"Could not appropriately configure new tokenizer. Verify if the special tokens already exist.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(output_model_file, 'wb') as outf:\n",
    "        outf.write(model.SerializeToString())\n",
    "\n",
    "    logging.info(f\"Created new tokenizer at: {output_model_file}\")\n",
    "\n",
    "    # Read the original vocab file and append the new tokens\n",
    "    with open(vocab_file, 'r') as original_vocab_file:\n",
    "        original_vocab = original_vocab_file.readlines()\n",
    "\n",
    "    with open(output_vocab_file, 'w') as updated_vocab_file:\n",
    "        updated_vocab_file.writelines(original_vocab)\n",
    "        for token in new_tokens:\n",
    "            updated_vocab_file.write(f\"{token}\\n\")\n",
    "\n",
    "    # Update vocab.txt\n",
    "    with open(vocab_txt_file, 'r') as original_vocab_txt_file:\n",
    "        original_vocab_txt = original_vocab_txt_file.readlines()\n",
    "\n",
    "    with open(output_vocab_txt_file, 'w') as updated_vocab_txt_file:\n",
    "        updated_vocab_txt_file.writelines(original_vocab_txt)\n",
    "        for token in new_tokens:\n",
    "            updated_vocab_txt_file.write(f\"{token}\\n\")\n",
    "\n",
    "    logging.info(f\"Updated vocab files: {output_vocab_file}, {output_vocab_txt_file}\")\n",
    "\n",
    "def update_model_config(model, new_model_path):\n",
    "    model['cfg']['tokenizer']['model_path'] = new_model_path\n",
    "    logging.info(f\"Updated model configuration with new tokenizer model path: {new_model_path}\")\n",
    "\n",
    "\n",
    "# Define input and output paths\n",
    "input_folder = MODEL_ROOT / \"tokenizer\"\n",
    "output_folder = MODEL_ROOT / \"new_tokenizer\"\n",
    "\n",
    "\n",
    "#input_folder = '/external/ksingla/models/nemo/stt_en_conformer_ctc_small/tokenizer'\n",
    "#output_folder = '/external/ksingla/models/nemo/stt_en_conformer_ctc_small/new_tokenizer'\n",
    "#proto_dir = '/path/to/save/proto'  # Define the actual path where the proto file should be saved\n",
    "#proto_file = '/path/to/sentencepiece_model.proto'  # Define the actual path to the sentencepiece_model.proto file\n",
    "\n",
    "input_file = input_folder / 'tokenizer.model'\n",
    "vocab_file = input_folder / 'tokenizer.vocab'\n",
    "vocab_txt_file = input_folder / 'vocab.txt'\n",
    "\n",
    "# input_file = os.path.join(input_folder, 'tokenizer.model')\n",
    "# vocab_file = os.path.join(input_folder, 'tokenizer.vocab')\n",
    "# vocab_txt_file = os.path.join(input_folder, 'vocab.txt')\n",
    "\n",
    "# Include all single-digit integers in the tokens list\n",
    "punctuations = ['.', ',', '?', '!', ';', ':', '-', '(', ')', '[', ']', '{', '}', '<', '>', '/', '\\\\', '|', '@', '#', '$', '%', '^', '&', '*', '+', '=', '~', '`', '_', '\"', \"'\"]\n",
    "tokens = taglist + [str(i) for i in range(10)] + punctuations\n",
    "is_userdefined = True\n",
    "\n",
    "# Step 1: Generate the sentencepiece_model_pb2.py file\n",
    "#generate_sentencepiece_model_pb2(proto_dir, proto_file)\n",
    "\n",
    "# Step 2: Edit the SentencePiece model\n",
    "edit_spt_model(input_file, output_folder, tokens, vocab_file, vocab_txt_file, is_userdefined)\n",
    "\n",
    "# Step 3: Load the model configuration and update it\n",
    "# model_config_file = '/path/to/model/config.json'  # Define the actual path to the model config file\n",
    "# with open(model_config_file, 'r') as f:\n",
    "#     model = json.load(f)\n",
    "\n",
    "# new_model_path = os.path.join(output_folder, 'tokenizer.model')\n",
    "# update_model_config(model, new_model_path)\n",
    "\n",
    "# # Save the updated model configuration\n",
    "# with open(model_config_file, 'w') as f:\n",
    "#     json.dump(model, f, indent=4)\n",
    "\n",
    "#logging.info(f\"Updated model configuration saved to: {model_config_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-16 06:21:19 modelPT:258] You tried to register an artifact under config key=tokenizer.model_path but an artifact for it has already been registered.\n",
      "[NeMo W 2024-07-16 06:21:19 modelPT:258] You tried to register an artifact under config key=tokenizer.vocab_path but an artifact for it has already been registered.\n",
      "[NeMo W 2024-07-16 06:21:19 modelPT:258] You tried to register an artifact under config key=tokenizer.spe_tokenizer_vocab but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:19 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1206 tokens\n",
      "[NeMo I 2024-07-16 06:21:20 ctc_bpe_models:248] \n",
      "    Replacing old number of classes (128) with new number of classes - 1206\n",
      "[NeMo I 2024-07-16 06:21:20 ctc_bpe_models:290] Changed tokenizer to ['<unk>', 's', '▁', 'e', 't', 'u', 'd', 'a', 'o', 'n', 'i', '▁the', '▁a', 'm', 'y', 'l', 'h', 'p', 're', '▁s', 'g', 'r', '▁to', '▁i', 'ing', '▁and', 'f', '▁p', 'an', 'c', 'w', 'er', 'ed', '▁of', '▁in', 'k', \"'\", '▁w', 'ar', 'or', '▁f', 'b', '▁b', 'en', '▁you', 'al', 'le', 'in', 'll', '▁that', '▁he', 'ro', '▁t', 'es', '▁it', '▁be', 've', 'v', 'ly', '▁c', 'th', '▁o', 'ent', 'ch', 'ur', '▁we', '▁re', '▁n', 'it', '▁so', '▁co', '▁g', '▁on', '▁for', 'on', 'ce', 'ri', '▁do', '▁is', '▁ha', '▁ma', 'ver', 'li', 'ra', '▁was', 'ic', 'la', '▁e', 'se', 'ter', 'ct', 'ion', '▁ca', '▁st', '▁me', 'ir', '▁mo', '▁with', '▁but', '▁have', '▁go', '▁de', '▁ho', '▁di', '▁not', '▁know', '▁lo', '▁this', 'ation', 'ther', 'ate', '▁com', '▁like', '▁uh', 'ck', '▁his', 'j', '▁yeah', '▁my', '▁ex', '▁what', '▁will', '▁mi', 'q', 'ight', 'x', 'z', '-', 'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21', 'T22', 'T23', 'T24', 'T25', 'T26', 'T27', 'T28', 'T29', 'T30', 'T31', 'T32', 'T33', 'T34', 'T35', 'T36', 'T37', 'T38', 'T39', 'T40', 'T41', 'T42', 'T43', 'T44', 'T45', 'T46', 'T47', 'T48', 'T49', 'T50', 'T51', 'T52', 'T53', 'T54', 'T55', 'T56', 'T57', 'T58', 'T59', 'T60', 'T61', 'T62', 'T63', 'T64', 'T65', 'T66', 'T67', 'T68', 'T69', 'T70', 'T71', 'T72', 'T73', 'T74', 'T75', 'T76', 'T77', 'T78', 'T79', 'T80', 'T81', 'T82', 'T83', 'T84', 'T85', 'T86', 'T87', 'T88', 'T89', 'T90', 'T91', 'T92', 'T93', 'T94', 'T95', 'T96', 'T97', 'T98', 'T99', 'T100', 'T101', 'T102', 'T103', 'T104', 'T105', 'T106', 'T107', 'T108', 'T109', 'T110', 'T111', 'T112', 'T114', 'T115', 'T116', 'T117', 'T118', 'T119', 'T120', 'T121', 'T122', 'T123', 'T124', 'T125', 'T126', 'T127', 'T128', 'T129', 'T130', 'T131', 'T132', 'T133', 'T134', 'T135', 'T136', 'T137', 'T138', 'T139', 'T140', 'T141', 'T142', 'T143', 'T144', 'T145', 'T146', 'T147', 'T148', 'T149', 'T150', 'T151', 'T152', 'T153', 'T154', 'T155', 'T156', 'T157', 'T158', 'T159', 'T160', 'T161', 'T162', 'T163', 'T164', 'T165', 'T166', 'T167', 'T168', 'T169', 'T170', 'T171', 'T172', 'T173', 'T174', 'T175', 'T176', 'T177', 'T178', 'T179', 'T180', 'T181', 'T182', 'T183', 'T184', 'T185', 'T186', 'T187', 'T188', 'T189', 'T190', 'T191', 'T192', 'T193', 'T194', 'T195', 'T196', 'T197', 'T198', 'T199', 'T200', 'T201', 'T202', 'T203', 'T204', 'T205', 'T206', 'T207', 'T208', 'T209', 'T210', 'T211', 'T212', 'T213', 'T214', 'T215', 'T216', 'T217', 'T218', 'T219', 'T220', 'T221', 'T222', 'T223', 'T224', 'T225', 'T226', 'T227', 'T228', 'T229', 'T230', 'T231', 'T232', 'T233', 'T234', 'T235', 'T236', 'T237', 'T238', 'T239', 'T240', 'T241', 'T242', 'T243', 'T244', 'T245', 'T246', 'T247', 'T248', 'T249', 'T250', 'T251', 'T252', 'T253', 'T254', 'T255', 'T256', 'T257', 'T258', 'T259', 'T260', 'T261', 'T262', 'T263', 'T264', 'T265', 'T266', 'T267', 'T268', 'T269', 'T270', 'T271', 'T272', 'T273', 'T274', 'T275', 'T276', 'T277', 'T278', 'T279', 'T280', 'T281', 'T282', 'T283', 'T284', 'T285', 'T286', 'T287', 'T288', 'T289', 'T290', 'T291', 'T292', 'T293', 'T294', 'T295', 'T296', 'T297', 'T298', 'T299', 'T300', 'T301', 'T302', 'T303', 'T304', 'T305', 'T306', 'T307', 'T308', 'T309', 'T310', 'T311', 'T312', 'T313', 'T314', 'T315', 'T316', 'T317', 'T318', 'T319', 'T320', 'T321', 'T322', 'T323', 'T324', 'T325', 'T326', 'T327', 'T328', 'T329', 'T330', 'T331', 'T332', 'T333', 'T334', 'T335', 'T336', 'T337', 'T338', 'T339', 'T340', 'T341', 'T342', 'T343', 'T344', 'T345', 'T346', 'T347', 'T348', 'T349', 'T350', 'T351', 'T352', 'T353', 'T354', 'T355', 'T356', 'T357', 'T358', 'T359', 'T360', 'T361', 'T362', 'T363', 'T364', 'T365', 'T366', 'T367', 'T368', 'T369', 'T370', 'T371', 'T372', 'T373', 'T374', 'T375', 'T376', 'T377', 'T378', 'T379', 'T380', 'T381', 'T382', 'T383', 'T384', 'T385', 'T386', 'T387', 'T388', 'T389', 'T390', 'T391', 'T392', 'T393', 'T394', 'T395', 'T396', 'T397', 'T398', 'T399', 'T400', 'T401', 'T402', 'T403', 'T404', 'T405', 'T406', 'T407', 'T408', 'T409', 'T410', 'T411', 'T412', 'T413', 'T414', 'T415', 'T416', 'T417', 'T418', 'T419', 'T420', 'T421', 'T422', 'T423', 'T424', 'T425', 'T426', 'T427', 'T428', 'T429', 'T430', 'T431', 'T432', 'T433', 'T434', 'T435', 'T436', 'T437', 'T438', 'T439', 'T440', 'T441', 'T442', 'T443', 'T444', 'T445', 'T446', 'T447', 'T448', 'T449', 'T450', 'T451', 'T452', 'T453', 'T454', 'T455', 'T456', 'T457', 'T458', 'T459', 'T460', 'T461', 'T462', 'T463', 'T464', 'T465', 'T466', 'T467', 'T468', 'T469', 'T470', 'T471', 'T472', 'T473', 'T474', 'T475', 'T476', 'T477', 'T478', 'T479', 'T480', 'T481', 'T482', 'T483', 'T484', 'T485', 'T486', 'T488', 'T489', 'T490', 'T491', 'T492', 'T493', 'T494', 'T495', 'T496', 'T497', 'T498', 'T499', 'T500', 'T501', 'T502', 'T503', 'T504', 'T505', 'T506', 'T507', 'T508', 'T509', 'T510', 'T511', 'T512', 'T513', 'T514', 'T515', 'T516', 'T517', 'T518', 'T519', 'T520', 'T521', 'T522', 'T523', 'T524', 'T525', 'T526', 'T527', 'T528', 'T529', 'T530', 'T531', 'T532', 'T533', 'T534', 'T535', 'T536', 'T537', 'T538', 'T539', 'T540', 'T541', 'T542', 'T543', 'T544', 'T545', 'T546', 'T547', 'T548', 'T549', 'T550', 'T551', 'T552', 'T553', 'T554', 'T555', 'T556', 'T557', 'T558', 'T559', 'T560', 'T561', 'T562', 'T563', 'T564', 'T565', 'T566', 'T567', 'T568', 'T569', 'T570', 'T571', 'T572', 'T573', 'T574', 'T575', 'T576', 'T577', 'T578', 'T579', 'T580', 'T581', 'T582', 'T583', 'T584', 'T585', 'T586', 'T587', 'T588', 'T589', 'T590', 'T591', 'T592', 'T593', 'T594', 'T595', 'T596', 'T597', 'T598', 'T599', 'T600', 'T601', 'T602', 'T603', 'T604', 'T605', 'T606', 'T607', 'T608', 'T609', 'T610', 'T611', 'T612', 'T613', 'T614', 'T615', 'T616', 'T617', 'T618', 'T619', 'T620', 'T621', 'T622', 'T623', 'T624', 'T625', 'T626', 'T627', 'T628', 'T629', 'T630', 'T631', 'T632', 'T633', 'T634', 'T635', 'T636', 'T637', 'T638', 'T639', 'T640', 'T641', 'T642', 'T643', 'T644', 'T645', 'T646', 'T647', 'T648', 'T649', 'T650', 'T651', 'T652', 'T653', 'T654', 'T655', 'T656', 'T657', 'T658', 'T659', 'T660', 'T661', 'T662', 'T663', 'T664', 'T665', 'T666', 'T667', 'T668', 'T669', 'T670', 'T671', 'T672', 'T673', 'T674', 'T675', 'T676', 'T677', 'T678', 'T679', 'T680', 'T681', 'T682', 'T683', 'T684', 'T685', 'T686', 'T687', 'T688', 'T689', 'T690', 'T691', 'T692', 'T693', 'T694', 'T695', 'T696', 'T697', 'T698', 'T699', 'T700', 'T701', 'T702', 'T703', 'T704', 'T705', 'T706', 'T707', 'T708', 'T709', 'T710', 'T711', 'T712', 'T713', 'T714', 'T715', 'T716', 'T717', 'T718', 'T719', 'T720', 'T721', 'T722', 'T723', 'T724', 'T725', 'T726', 'T727', 'T728', 'T729', 'T730', 'T731', 'T732', 'T733', 'T734', 'T735', 'T736', 'T737', 'T738', 'T739', 'T740', 'T741', 'T742', 'T743', 'T744', 'T745', 'T746', 'T747', 'T748', 'T749', 'T750', 'T751', 'T752', 'T753', 'T754', 'T755', 'T756', 'T757', 'T758', 'T759', 'T760', 'T761', 'T762', 'T763', 'T764', 'T765', 'T766', 'T767', 'T768', 'T769', 'T770', 'T771', 'T772', 'T773', 'T774', 'T775', 'T776', 'T777', 'T778', 'T779', 'T780', 'T781', 'T782', 'T784', 'T785', 'T786', 'T787', 'T788', 'T789', 'T790', 'T791', 'T792', 'T793', 'T794', 'T795', 'T796', 'T797', 'T798', 'T799', 'T800', 'T801', 'T802', 'T803', 'T804', 'T805', 'T806', 'T807', 'T808', 'T809', 'T810', 'T811', 'T812', 'T813', 'T814', 'T815', 'T816', 'T817', 'T818', 'T819', 'T820', 'T821', 'T822', 'T823', 'T824', 'T825', 'T826', 'T827', 'T828', 'T829', 'T830', 'T831', 'T832', 'T833', 'T834', 'T835', 'T836', 'T837', 'T838', 'T839', 'T840', 'T841', 'T842', 'T843', 'T844', 'T845', 'T846', 'T847', 'T848', 'T849', 'T850', 'T851', 'T852', 'T853', 'T854', 'T855', 'T856', 'T857', 'T858', 'T859', 'T860', 'T861', 'T862', 'T863', 'T864', 'T865', 'T866', 'T867', 'T868', 'T869', 'T870', 'T871', 'T872', 'T873', 'T874', 'T875', 'T876', 'T877', 'T878', 'T879', 'T880', 'T881', 'T883', 'T884', 'T885', 'T886', 'T887', 'T888', 'T889', 'T890', 'T891', 'T892', 'T893', 'T894', 'T895', 'T896', 'T897', 'T898', 'T899', 'T900', 'T901', 'T902', 'T903', 'T904', 'T905', 'T906', 'T907', 'T908', 'T909', 'T910', 'T911', 'T912', 'T913', 'T914', 'T915', 'T916', 'T917', 'T918', 'T919', 'T920', 'T921', 'T922', 'T923', 'T924', 'T925', 'T926', 'T927', 'T928', 'T929', 'T930', 'T931', 'T932', 'T933', 'T934', 'T935', 'T936', 'T937', 'T938', 'T939', 'T940', 'T941', 'T942', 'T943', 'T944', 'T945', 'T946', 'T947', 'T948', 'T949', 'T950', 'T951', 'T952', 'T953', 'T954', 'T955', 'T956', 'T957', 'T958', 'T959', 'T960', 'T961', 'T962', 'T963', 'T964', 'T965', 'T966', 'T967', 'T968', 'T969', 'T970', 'T971', 'T972', 'T973', 'T974', 'T975', 'T976', 'T977', 'T978', 'T979', 'T980', 'T981', 'T982', 'T983', 'T984', 'T985', 'T986', 'T987', 'T988', 'T989', 'T990', 'T991', 'T992', 'T993', 'T994', 'T995', 'T996', 'T997', 'T998', 'T999', 'T1000', 'T1001', 'T1002', 'T1003', 'T1004', 'T1005', 'T1006', 'T1007', 'T1008', 'T1009', 'T1010', 'T1011', 'T1012', 'T1013', 'T1014', 'T1015', 'T1016', 'T1017', 'T1018', 'T1019', 'T1020', 'T1021', 'T1022', 'T1023', 'T1024', 'T1025', 'T1026', 'T1027', 'T1029', 'T1039', 'T1073', 'T1093', 'T1102', 'T1121', 'T1206', 'T1265', 'T1267', 'T1280', 'T1285', 'T1286', 'T1306', 'T1311', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', ',', '?', '!', ';', ':', '(', ')', '[', ']', '{', '}', '<', '>', '/', '\\\\', '|', '@', '#', '$', '%', '^', '&', '*', '+', '=', '~', '`', '_', '\"'] vocabulary.\n"
     ]
    }
   ],
   "source": [
    "model.change_vocabulary(output_folder, \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "max_steps = 30000\n",
    "\n",
    "trainer = Trainer(devices=1, accelerator=accelerator, max_steps=max_steps,\n",
    "                  enable_checkpointing=False, logger=False,\n",
    "                  log_every_n_steps=50, check_val_every_n_epoch=1)\n",
    "\n",
    "model.set_trainer(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method\n",
    "import json\n",
    "from nemo.collections.asr.parts.utils.manifest_utils import read_manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:21 collections:196] Dataset loaded with 32743 files totalling 38.38 hours\n",
      "[NeMo I 2024-07-16 06:21:21 collections:197] 2 files were filtered totalling 0.01 hours\n",
      "[NeMo I 2024-07-16 06:21:22 collections:196] Dataset loaded with 1650 files totalling 1.87 hours\n",
      "[NeMo I 2024-07-16 06:21:22 collections:197] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2024-07-16 06:21:22 collections:196] Dataset loaded with 1650 files totalling 1.87 hours\n",
      "[NeMo I 2024-07-16 06:21:22 collections:197] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "with open_dict(model.cfg):\n",
    "  # Train Dataloader\n",
    "  model.cfg.train_ds.manifest_filepath = TRAIN_MANIFEST\n",
    "  model.cfg.train_ds.batch_size = 16\n",
    "  model.cfg.train_ds.is_tarred = False\n",
    "  model.cfg.train_ds.tarred_audio_filepaths = None\n",
    "\n",
    "  model.cfg.validation_ds.manifest_filepath = TEST_MANIFEST\n",
    "  model.cfg.validation_ds.batch_size = 16\n",
    "\n",
    "model.setup_training_data(model.cfg.train_ds)\n",
    "model.setup_multiple_validation_data(model.cfg.validation_ds)\n",
    "model.setup_multiple_test_data(model.cfg.validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_dict(model.cfg):\n",
    "  # Spec Augment\n",
    "  model.cfg.spec_augment.freq_masks = model.cfg.spec_augment.freq_masks  # Can be changed\n",
    "  model.cfg.spec_augment.freq_width = model.cfg.spec_augment.freq_width  # Can be changed\n",
    "  model.cfg.spec_augment.time_masks = model.cfg.spec_augment.time_masks  # Can be changed\n",
    "  model.cfg.spec_augment.time_width = model.cfg.spec_augment.time_width  # Can be changed\n",
    "\n",
    "model.spec_augmentation = model.from_config_dict(model.cfg.spec_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: adamw\n",
      "lr: 2.0\n",
      "betas:\n",
      "- 0.9\n",
      "- 0.98\n",
      "weight_decay: 0.001\n",
      "sched:\n",
      "  name: NoamAnnealing\n",
      "  d_model: 512\n",
      "  warmup_steps: 10000\n",
      "  warmup_ratio: null\n",
      "  min_lr: 1.0e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'optim' in model.cfg:\n",
    "  print(OmegaConf.to_yaml(model.cfg.optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:22 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.1\n",
      "        maximize: False\n",
      "        weight_decay: 0.0\n",
      "    )\n",
      "[NeMo I 2024-07-16 06:21:22 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.NoamAnnealing object at 0x7c3af0cafa00>\" \n",
      "    will be used during training (effective maximum steps = 30000) - \n",
      "    Parameters : \n",
      "    (d_model: 512\n",
      "    warmup_steps: 100\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 30000\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "with open_dict(model.cfg):\n",
    "  model.cfg.optim.lr = 0.1\n",
    "  model.cfg.optim.weight_decay = 0.0\n",
    "  model.cfg.optim.sched.warmup_steps = 100\n",
    "\n",
    "model.setup_optimization(model.cfg.optim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'encoder', 'decoder', 'joint']\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'adapter_module_names'):\n",
    "  print(model.adapter_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module :  ConformerEncoderAdapter\n",
      "<class 'nemo.collections.asr.parts.submodules.adapters.multi_head_attention_adapter_module.MultiHeadAttentionAdapter'>\n",
      "<class 'nemo.collections.common.parts.adapter_modules.LinearAdapter'>\n",
      "<class 'nemo.collections.asr.parts.submodules.adapters.multi_head_attention_adapter_module.RelPositionMultiHeadAttentionAdapter'>\n",
      "\n",
      "Module :  ConvASRDecoder\n",
      "<class 'nemo.collections.common.parts.adapter_modules.LinearAdapter'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for module in model.children():\n",
    "  if hasattr(module, 'get_accepted_adapter_types'):\n",
    "    types = module.get_accepted_adapter_types()\n",
    "    print(\"Module : \", module.__class__.__name__)\n",
    "\n",
    "    for tp in types:\n",
    "      print(tp)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.common.parts.adapter_modules import LinearAdapterConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [code]\n",
    "#@title Adapter Setup { display-mode: \"form\" }\n",
    "adapter_name = \"AN4\" #@param {type:\"string\"}\n",
    "adapter_dim = 64 #@param {type:\"integer\"}\n",
    "adapter_activation = \"swish\" #@param {type:\"string\"}\n",
    "adapter_norm_position = \"pre\" #@param [\"pre\", \"post\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearAdapterConfig(in_features=512, dim=64, activation='swish', norm_position='pre', dropout=0.0, adapter_strategy=ResidualAddAdapterStrategyConfig(stochastic_depth=0.0, l2_lambda=0.0, _target_='nemo.core.classes.mixins.adapter_mixin_strategies.ResidualAddAdapterStrategy'), _target_='nemo.collections.common.parts.adapter_modules.LinearAdapter')\n"
     ]
    }
   ],
   "source": [
    "adapter_cfg = LinearAdapterConfig(\n",
    "    in_features=model.cfg.encoder.d_model,  # conformer specific model dim. Every layer emits this dim at its output.\n",
    "    dim=adapter_dim,  # the bottleneck dimension of the adapter\n",
    "    activation=adapter_activation,  # activation used in bottleneck block\n",
    "    norm_position=adapter_norm_position,  # whether to use LayerNorm at the beginning or the end of the adapter\n",
    ")\n",
    "print(adapter_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params\n",
       "------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
       "1 | encoder           | ConformerEncoderAdapter           | 121 M \n",
       "2 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
       "3 | wer               | WER                               | 0     \n",
       "4 | decoder           | ConvASRDecoder                    | 619 K \n",
       "5 | loss              | CTCLoss                           | 0     \n",
       "------------------------------------------------------------------------\n",
       "122 M     Trainable params\n",
       "0         Non-trainable params\n",
       "122 M     Total params\n",
       "488.217   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter(name=adapter_name, cfg=adapter_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params\n",
       "------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
       "1 | encoder           | ConformerEncoderAdapter           | 122 M \n",
       "2 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
       "3 | wer               | WER                               | 0     \n",
       "4 | decoder           | ConvASRDecoder                    | 619 K \n",
       "5 | loss              | CTCLoss                           | 0     \n",
       "------------------------------------------------------------------------\n",
       "123 M     Trainable params\n",
       "0         Non-trainable params\n",
       "123 M     Total params\n",
       "493.010   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:719] Setting adapter 'AN4' status : Enabled = False\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:734] Setting adapter 'AN4' status : Enabled = True\n"
     ]
    }
   ],
   "source": [
    "model.set_enabled_adapters(enabled=False)  # disable all adapters\n",
    "model.set_enabled_adapters(name=adapter_name, enabled=True)  # enable only the current adapter we want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.0.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.1.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.2.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.3.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.4.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.5.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.6.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.7.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.8.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.9.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.10.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.11.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.12.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.13.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.14.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.15.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.16.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:405] Froze module encoder.layers.17.conv.batch_norm: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "[NeMo I 2024-07-16 06:21:23 adapter_mixins:435] Unfrozen adapter : AN4\n"
     ]
    }
   ],
   "source": [
    "model.freeze()\n",
    "model.unfreeze_enabled_adapters()\n",
    "#model.unfreeze()\n",
    "model.decoder.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params\n",
       "------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
       "1 | encoder           | ConformerEncoderAdapter           | 122 M \n",
       "2 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
       "3 | wer               | WER                               | 0     \n",
       "4 | decoder           | ConvASRDecoder                    | 619 K \n",
       "5 | loss              | CTCLoss                           | 0     \n",
       "------------------------------------------------------------------------\n",
       "1.8 M     Trainable params\n",
       "121 M     Non-trainable params\n",
       "123 M     Total params\n",
       "493.010   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:24 exp_manager:396] Experiments will be logged at /external2/karan_exp/experiments/encoder:fixed-adapter64-decode:tune-multidomain-v4/2024-07-16_06-21-24\n",
      "[NeMo I 2024-07-16 06:21:24 exp_manager:842] TensorboardLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-16 06:21:24 exp_manager:952] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to 30000. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
     ]
    }
   ],
   "source": [
    "# Prepare NeMo's Experiment manager to handle checkpoint saving and logging for us\n",
    "from nemo.utils import exp_manager\n",
    "\n",
    "# Environment variable generally used for multi-node multi-gpu training.\n",
    "# In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n",
    "os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "\n",
    "exp_config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=f'/external2/karan_exp/experiments/',\n",
    "    name=f\"encoder:fixed-adapter64-decode:tune-multidomain-v4\",\n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor=\"val_wer\",\n",
    "        mode=\"min\",\n",
    "        always_save_nemo=True,\n",
    "        save_best_model=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "exp_config = OmegaConf.structured(exp_config)\n",
    "\n",
    "logdir = exp_manager.exp_manager(trainer, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dir': PosixPath('/external2/models/hf/stt_en_conformer_ctc_large/new_tokenizer'), 'type': 'bpe', 'model_path': '/external2/models/hf/stt_en_conformer_ctc_large/new_tokenizer/tokenizer.model', 'vocab_path': '/external2/models/hf/stt_en_conformer_ctc_large/new_tokenizer/vocab.txt', 'spe_tokenizer_vocab': '/external2/models/hf/stt_en_conformer_ctc_large/new_tokenizer/tokenizer.vocab'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg['tokenizer']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params\n",
       "------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
       "1 | encoder           | ConformerEncoderAdapter           | 122 M \n",
       "2 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
       "3 | wer               | WER                               | 0     \n",
       "4 | decoder           | ConvASRDecoder                    | 619 K \n",
       "5 | loss              | CTCLoss                           | 0     \n",
       "------------------------------------------------------------------------\n",
       "1.8 M     Trainable params\n",
       "121 M     Non-trainable params\n",
       "123 M     Total params\n",
       "493.010   Total estimated model params size (MB)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:24 modelPT:723] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.1\n",
      "        maximize: False\n",
      "        weight_decay: 0.0\n",
      "    )\n",
      "[NeMo I 2024-07-16 06:21:24 lr_scheduler:915] Scheduler \"<nemo.core.optim.lr_scheduler.NoamAnnealing object at 0x7c3af09af8b0>\" \n",
      "    will be used during training (effective maximum steps = 30000) - \n",
      "    Parameters : \n",
      "    (d_model: 512\n",
      "    warmup_steps: 100\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 30000\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoderAdapter           | 122 M \n",
      "2 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "3 | wer               | WER                               | 0     \n",
      "4 | decoder           | ConvASRDecoder                    | 619 K \n",
      "5 | loss              | CTCLoss                           | 0     \n",
      "------------------------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "121 M     Non-trainable params\n",
      "123 M     Total params\n",
      "493.010   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c52acd58e4e47a9847e4b9e55faaea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-07-16 06:21:25 wer:319] reference:T3-T826-T248 T1_T248_T668 i T0 T1_T201 am experiencing T0 T1_T667 shortness of breath T0 T1_T54 lately T0 T2_T667_T47\n",
      "[NeMo I 2024-07-16 06:21:25 wer:320] predicted:ent willT65T912T51T161T666 tcT161T94T1017T517T600T139T161T865T477ri tT867T161T1014T820T73T820T616T161T1006]T841T154T161T42T987T161T348T355T161T93T161T983T161T376\n",
      "[NeMo I 2024-07-16 06:21:25 wer:318] \n",
      "    \n",
      "[NeMo I 2024-07-16 06:21:25 wer:319] reference:T3-T826-T248 T1_T248_T668 i T0 T1_T201 was diagnosed with T0 T1_T12 fibromyalgia T0 T1_T623 three years ago T0 T2_T826_T689\n",
      "[NeMo I 2024-07-16 06:21:25 wer:320] predicted:entT376T3T161T1021T161edorT635T883T841T137terT354T40T161T31T39T831T161T457T161T133T1022wT303T346T161T258T529T1001T146T161laT1021entT452T619T146 t moT754T368T161T501T346T376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7751806b089d4958b21bd01ae29cf12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-16 06:21:26 preemption:56] Preemption requires torch distributed to be initialized, disabling preemption\n",
      "[NeMo I 2024-07-16 06:21:53 wer:318] \n",
      "    \n",
      "[NeMo I 2024-07-16 06:21:53 wer:319] reference:T3-T510-T511 T1_T201 change T0 T1_T988_T421 flight T0 to T1_T387 rome T0 on T1_T623 april 20th T0 T2_T334_T988\n",
      "[NeMo I 2024-07-16 06:21:53 wer:320] predicted:_T649\n"
     ]
    }
   ],
   "source": [
    "# Finally, train the adapters\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
