{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wellness Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download GCP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135ed16",
   "metadata": {},
   "source": [
    "### Annotate data using dataannotation server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using the Data Annotation Server to annotate an audio file\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set the base URL of your running Data Annotation Server (see routes.py for endpoints)\n",
    "DATA_ANNOTATION_SERVER = \"http://localhost:8000\"  # Change to your server's address if needed\n",
    "\n",
    "# 1. Initialize a user session (required for authentication)\n",
    "user_id = \"test_user\"\n",
    "api_keys = {\n",
    "    \"gemini\": \"YOUR_GEMINI_API_KEY\",      # Replace with your actual Gemini API key\n",
    "    \"whissle\": \"YOUR_WHISSLE_API_KEY\",    # Replace if using Whissle\n",
    "    \"deepgram\": \"YOUR_DEEPGRAM_API_KEY\"   # Replace if using Deepgram\n",
    "}\n",
    "init_session_payload = {\n",
    "    \"user_id\": user_id,\n",
    "    \"api_keys\": api_keys\n",
    "}\n",
    "resp = requests.post(f\"{DATA_ANNOTATION_SERVER}/init_session/\", json=init_session_payload)\n",
    "print(\"Session init:\", resp.json())\n",
    "\n",
    "# 2. Annotate an audio file (transcribe and annotate)\n",
    "# Example: Use the /trim_transcribe_annotate/ endpoint to trim, transcribe, and annotate a local audio file\n",
    "# (You can also use /create_transcription_manifest/ for transcription only)\n",
    "\n",
    "# Path to your local audio file directory (should contain .wav files)\n",
    "audio_dir = \"/path/to/your/audio_files\"  # Change to your directory\n",
    "output_jsonl = \"/tmp/annotated_manifest.jsonl\"  # Where to save the results\n",
    "\n",
    "process_payload = {\n",
    "    \"user_id\": user_id,\n",
    "    \"directory_path\": audio_dir,\n",
    "    \"output_jsonl_path\": output_jsonl,\n",
    "    \"model_choice\": \"gemini\",  # or \"whissle\" or \"deepgram\"\n",
    "    \"segment_length_sec\": 30,  # Split audio into 30s segments\n",
    "    \"annotations\": [\"entity\", \"intent\", \"age\", \"gender\", \"emotion\"],  # Request all annotation types\n",
    "    \"prompt\": None  # Optional: custom prompt for Gemini annotation\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{DATA_ANNOTATION_SERVER}/trim_transcribe_annotate/\", json=process_payload)\n",
    "print(\"Annotation response:\", resp.json())\n",
    "\n",
    "# 3. Inspect the output JSONL file for annotated results\n",
    "with open(output_jsonl, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        print(json.loads(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print sample samples to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50760bcc",
   "metadata": {},
   "source": [
    "### Push data to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55513a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417642a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edcdfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
